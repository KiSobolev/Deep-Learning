{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ANN regression example 2 - Housing data with preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv(\"Housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10850000</td>\n",
       "      <td>7500</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10150000</td>\n",
       "      <td>8580</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10150000</td>\n",
       "      <td>16200</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>unfurnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9870000</td>\n",
       "      <td>8100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9800000</td>\n",
       "      <td>5750</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>unfurnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price   area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000   7420         4          2        3      yes        no       no   \n",
       "1  12250000   8960         4          4        4      yes        no       no   \n",
       "2  12250000   9960         3          2        2      yes        no      yes   \n",
       "3  12215000   7500         4          2        2      yes        no      yes   \n",
       "4  11410000   7420         4          1        2      yes       yes      yes   \n",
       "5  10850000   7500         3          3        1      yes        no      yes   \n",
       "6  10150000   8580         4          3        4      yes        no       no   \n",
       "7  10150000  16200         5          3        2      yes        no       no   \n",
       "8   9870000   8100         4          1        2      yes       yes      yes   \n",
       "9   9800000   5750         3          2        4      yes       yes       no   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  \n",
       "5              no             yes        2      yes   semi-furnished  \n",
       "6              no             yes        2      yes   semi-furnished  \n",
       "7              no              no        0       no      unfurnished  \n",
       "8              no             yes        2      yes        furnished  \n",
       "9              no             yes        1      yes      unfurnished  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see what we have in the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can see in the data that we have many yes/no fields and one field with multiple text categories. We have to convert all of these correctly into numeric format.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price               0\n",
       "area                0\n",
       "bedrooms            0\n",
       "bathrooms           0\n",
       "stories             0\n",
       "mainroad            0\n",
       "guestroom           0\n",
       "basement            0\n",
       "hotwaterheating     0\n",
       "airconditioning     0\n",
       "parking             0\n",
       "prefarea            0\n",
       "furnishingstatus    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quickly check if we have missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convert no/yes -columns into 0/1</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this just converts the value of column to 0 or 1\n",
    "# factorize in pandas works too, but only one column at a time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "variables = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
    "encoder = LabelEncoder()\n",
    "df[variables] = df[variables].apply(encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories  mainroad  guestroom  \\\n",
       "0  13300000  7420         4          2        3         1          0   \n",
       "1  12250000  8960         4          4        4         1          0   \n",
       "2  12250000  9960         3          2        2         1          0   \n",
       "3  12215000  7500         4          2        2         1          0   \n",
       "4  11410000  7420         4          1        2         1          1   \n",
       "\n",
       "   basement  hotwaterheating  airconditioning  parking  prefarea  \\\n",
       "0         0                0                1        2         1   \n",
       "1         0                0                1        3         0   \n",
       "2         1                0                0        2         1   \n",
       "3         1                0                1        3         1   \n",
       "4         1                0                1        2         0   \n",
       "\n",
       "  furnishingstatus  \n",
       "0        furnished  \n",
       "1        furnished  \n",
       "2   semi-furnished  \n",
       "3        furnished  \n",
       "4        furnished  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# works nicely!\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convert text categories with multiple choices into multiple variables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_furnisahingrow(row):\n",
    "    if row[\"furnishingstatus\"] == \"unfurnished\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"furnishing\"]=df.apply(modify_furnisahingrow, axis=1)\n",
    "df= df.drop(\"furnishingstatus\", axis=1)\n",
    "df= df.drop(\"bedrooms\", axis=1)\n",
    "df= df.drop(\"mainroad\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10850000</td>\n",
       "      <td>7500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10150000</td>\n",
       "      <td>8580</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10150000</td>\n",
       "      <td>16200</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9870000</td>\n",
       "      <td>8100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9800000</td>\n",
       "      <td>5750</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price   area  bathrooms  stories  guestroom  basement  hotwaterheating  \\\n",
       "0  13300000   7420          2        3          0         0                0   \n",
       "1  12250000   8960          4        4          0         0                0   \n",
       "2  12250000   9960          2        2          0         1                0   \n",
       "3  12215000   7500          2        2          0         1                0   \n",
       "4  11410000   7420          1        2          1         1                0   \n",
       "5  10850000   7500          3        1          0         1                0   \n",
       "6  10150000   8580          3        4          0         0                0   \n",
       "7  10150000  16200          3        2          0         0                0   \n",
       "8   9870000   8100          1        2          1         1                0   \n",
       "9   9800000   5750          2        4          1         0                0   \n",
       "\n",
       "   airconditioning  parking  prefarea  furnishing  \n",
       "0                1        2         1           1  \n",
       "1                1        3         0           1  \n",
       "2                0        2         1           1  \n",
       "3                1        3         1           1  \n",
       "4                1        2         0           1  \n",
       "5                1        2         1           1  \n",
       "6                1        2         1           1  \n",
       "7                0        0         0           0  \n",
       "8                1        2         1           1  \n",
       "9                1        1         1           0  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# works nicely\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'area', 'bathrooms', 'stories', 'guestroom', 'basement',\n",
       "       'hotwaterheating', 'airconditioning', 'parking', 'prefarea',\n",
       "       'furnishing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing out the column names for easier copying for X/y\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>X/y -variables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you  have more than one independent variables, list them all here\n",
    "# leave out the target variable! (dependent variable)\n",
    "# in this case, everything else except the amount_paid\n",
    "X = df[['area', 'bathrooms', 'stories',\n",
    "       'guestroom', 'basement', 'hotwaterheating', 'airconditioning',\n",
    "       'parking', 'prefarea', 'furnishing']]\n",
    "\n",
    "# have only the target variable here (dependent variable)\n",
    "# in this case, amount_paid => how big is the electricity bill\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train/test/validation -split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfortunately the scikit-learn's train_test_split doesn't support validation\n",
    "# set split in itself.\n",
    "# if you want to split the test set into two for a validation set too, try this trick:\n",
    "\n",
    "# first, train/test split => 70% for training, 30% for other purposes (temp)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# now, split the 30% for other purposes by 50% (resulting in 2 x 15%)\n",
    "# so finally, we have:\n",
    "# 70% for training\n",
    "# 15% for testing\n",
    "# 15% for validation\n",
    "# => 70 + 15 +15 = 100%\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data amount: 381\n",
      "Test data amount: 82\n",
      "Validation data amount: 82\n"
     ]
    }
   ],
   "source": [
    "# just seeing how much data we have in each\n",
    "print(f\"Train data amount: {len(X_train)}\")\n",
    "print(f\"Test data amount: {len(X_test)}\")\n",
    "print(f\"Validation data amount: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           feature  VIF\n",
      "0             area 6.35\n",
      "1        bathrooms 7.80\n",
      "2          stories 5.82\n",
      "3        guestroom 1.46\n",
      "4         basement 1.91\n",
      "5  hotwaterheating 1.09\n",
      "6  airconditioning 1.72\n",
      "7          parking 1.95\n",
      "8         prefarea 1.47\n",
      "9       furnishing 3.12\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "\n",
    "# VIF dataframe \n",
    "# VIF = Variance Inflation Factor\n",
    "vif_data = pd.DataFrame() \n",
    "vif_data[\"feature\"] = X.columns \n",
    "  \n",
    "# calculating VIF for each feature \n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) \n",
    "                          for i in range(len(X.columns))] \n",
    "  \n",
    "\n",
    "# variables with high VIF-value \n",
    "# can mean multlicollinearity (variables providing same linear\n",
    "# relationships in the data, potentially confusing the ML algorithm\n",
    "# this might be good info when deciding if some variable needs to be removed\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAGdCAYAAACCbcL7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFFElEQVR4nO3de3RM9/7/8dckkUkkkwQJok2E0kjcCS1pJYoTPSjaU1pO0SrOF3UrDu1BQlWqKOVUXVoJR9GL21eLouISLXGtS6SENOk5qZxq5UJFJPP7w9f8OiQuRSeyn4+19lpm78/+7Peeade81uezPxOT1Wq1CgAAAIbh5OgCAAAA8MciAAIAABgMARAAAMBgCIAAAAAGQwAEAAAwGAIgAACAwRAAAQAADIYACAAAYDAuji4ApVNRUZH+85//yGKxyGQyObocAABwC6xWq3Jzc1WtWjU5OZU8zkcARLH+85//KCAgwNFlAACA3yEjI0MPPvhgiccJgCiWxWKRdOU/IC8vLwdXAwAAbkVOTo4CAgJs3+MlIQCiWFenfb28vAiAAADcZ272+BaLQAAAAAyGAAgAAGAwBEAAAACDIQACAAAYDAEQAADAYAiAAAAABsPPwOCG6k3YKCdzeUeXAdy30mI7OLoEALgOI4AAAAAGQwAEAAAwGAIgAACAwRgiAFqtVvXv318VK1aUyWTSwYMH79m1IiMjNWzYsLvW1mQyafXq1XdcFwAAwFWGWASyYcMGxcXFKSEhQTVr1pSvr+89u9bKlStVrly5u9ZfZmamKlSocNf6AwAAMEQATE1Nlb+/v1q2bPm7+ygoKLilYFexYsXffY3iVK1a9a72BwAAUOangPv06aNXXnlF6enpMplMCgoKUlBQkGbOnGnXrlGjRoqOjra9NplMmjt3rp566il5eHho8uTJio6OVqNGjbRkyRIFBQXJ29tbzz33nHJzc23nXTut+95776l27dpyc3NTlSpV9Je//MXuukVFRRo9erQqVqyoqlWr2tVwtY6rU8BpaWkymUxauXKlWrdurfLly6thw4b6+uuv7c5ZsGCBAgICVL58eXXt2lUzZsyQj4/P730LAQBAGVPmA+CsWbM0ceJEPfjgg8rMzFRSUtItnxsdHa2uXbvq8OHDeumllyRdGU1cvXq11q1bp3Xr1mnbtm2KjY0t9vy9e/dqyJAhmjhxolJSUrRhwwa1atXKrk18fLw8PDy0e/duTZ06VRMnTtSmTZtuWNfrr7+ukSNH6uDBg3r44Yf1/PPP6/Lly5KkxMRE/e1vf9PQoUN18OBBtWvXTpMnT77pvebn5ysnJ8duAwAAZVOZnwL29vaWxWKRs7PzbU+n9ujRQy+++KLdvqKiIsXFxclisUiSXnjhBW3ZsqXYkJWeni4PDw917NhRFotF1atXV+PGje3aNGjQQBMmTJAk1a5dW3PmzNGWLVvUrl27EusaOXKkOnS48uOyMTExqlu3rk6ePKk6depo9uzZevLJJzVy5EhJ0sMPP6xdu3Zp3bp1N7zXKVOmKCYm5ibvCAAAKAvK/AjgnQgLC7tuX1BQkC38SZK/v7+ysrKKPb9du3aqXr26atasqRdeeEFLly7VhQsX7No0aNDA7vWN+ivuHH9/f0mynZOSkqLmzZvbtb/2dXHGjh2r7Oxs25aRkXHTcwAAwP3JkAHQyclJVqvVbl9BQcF17Tw8PK7bd+1CEJPJpKKiomKvY7FYtH//fi1btkz+/v4aP368GjZsqHPnzv2u/oo7x2QySdJNz7kZs9ksLy8vuw0AAJRNhgyAfn5+yszMtL3OycnR6dOn78m1XFxc1LZtW02dOlXffvut0tLS9NVXX92Ta0lScHDwdc853s5zjwAAoOwr888AFueJJ55QXFycOnXqJB8fH40fP17Ozs53/Trr1q3TqVOn1KpVK1WoUEFffPGFioqKFBwcfNevddUrr7yiVq1aacaMGerUqZO++uorrV+/3jZSCAAAYMgRwLFjxyoiIkIdO3ZUhw4d1KVLFz300EN3/To+Pj5auXKlnnjiCYWEhOj999/XsmXLVLdu3bt+ravCw8P1/vvva8aMGWrYsKE2bNig4cOHy83N7Z5dEwAA3F9M1msfhkOZ069fPx0/flw7duy45XNycnLk7e2tgGEfy8lc/h5WB5RtabEdHF0CAAO5+v2dnZ19w+f5DTkFXNZNmzZN7dq1k4eHh9avX6/4+Hi99957ji4LAACUEgTAMmjPnj2aOnWqcnNzVbNmTb377rt6+eWXHV0WAAAoJZgCRrFudQgZAACUHrf6/W3IRSAAAABGRgAEAAAwGAIgAACAwRAAAQAADIYACAAAYDAEQAAAAIMhAAIAABgMARAAAMBgCIAAAAAGQwAEAAAwGAIgAACAwRAAAQAADIYACAAAYDAEQAAAAIMhAAIAABgMARAAAMBgCIAAAAAGQwAEAAAwGBdHF4DSrd6EjXIyl3d0GQBKibTYDo4uAcBdwAggAACAwRAAAQAADIYACAAAYDAEwD/AhQsX9Mwzz8jLy0smk0nnzp1zdEkAAMDAWATyB4iPj9eOHTu0a9cu+fr6ytvb29ElAQAAAyMA3oFLly7J1dX1pu1SU1MVEhKievXq/e5rWa1WFRYWysWFjwwAANwZpoB/IzIyUoMHD9bgwYPl7e0tX19fjRs3TlarVZIUFBSkSZMmqVevXvLy8lL//v0lSTt37tTjjz8ud3d3BQQEaMiQITp//rytz+nTp2v79u0ymUyKjIyUJC1ZskRhYWGyWCyqWrWqevTooaysLFstCQkJMplMWr9+vZo2bSqz2aydO3eqqKhIU6ZMUY0aNeTu7q6GDRvq008/tZ1XWFiovn372o4HBwdr1qxZf9A7CAAA7gcEwGvEx8fLxcVFe/bs0axZszRjxgwtXLjQdnzatGlq2LChDhw4oHHjxik1NVXt27fXM888o2+//VYrVqzQzp07NXjwYEnSypUr1a9fP7Vo0UKZmZlauXKlJKmgoECTJk3SoUOHtHr1aqWlpalPnz7X1TNmzBjFxsYqOTlZDRo00JQpU7R48WK9//77Onr0qIYPH66//vWv2rZtmySpqKhIDz74oD755BMdO3ZM48eP12uvvaaPP/74hvedn5+vnJwcuw0AAJRNJuvV4S0oMjJSWVlZOnr0qEwmk6QrAWzt2rU6duyYgoKC1LhxY61atcp2zssvvyxnZ2fNmzfPtm/nzp2KiIjQ+fPn5ebmpmHDhungwYNKSEgo8dp79+5Vs2bNlJubK09PTyUkJKh169ZavXq1OnfuLOlKSKtYsaI2b96sFi1a2NVw4cIFffTRR8X2PXjwYP344492I4XXio6OVkxMzHX7A4Z9zA9BA7Dhh6CB0i0nJ0fe3t7Kzs6Wl5dXie0YAbzGo48+agt/ktSiRQudOHFChYWFkqSwsDC79ocOHVJcXJw8PT1tW1RUlIqKinT69OkSr7Nv3z516tRJgYGBslgsioiIkCSlp6fbtfvt9U6ePKkLFy6oXbt2dtdbvHixUlNTbe3++c9/qmnTpvLz85Onp6fmz59/Xb/XGjt2rLKzs21bRkbGTd4pAABwv2JFwW3y8PCwe52Xl6cBAwZoyJAh17UNDAwsto/z588rKipKUVFRWrp0qfz8/JSenq6oqChdunSpxOvl5eVJkj7//HM98MADdu3MZrMkafny5Ro5cqSmT5+uFi1ayGKx6O2339bu3btveF9ms9nWBwAAKNsIgNe4Nih98803ql27tpydnYtt36RJEx07dky1atW65WscP35cZ8+eVWxsrAICAiRdmQK+mdDQUJnNZqWnp9tGDK+VmJioli1bauDAgbZ9vx0dBAAAYAr4Gunp6RoxYoRSUlK0bNkyzZ49W0OHDi2x/d///nft2rVLgwcP1sGDB3XixAmtWbPGtgikOIGBgXJ1ddXs2bN16tQprV27VpMmTbppbRaLRSNHjtTw4cMVHx+v1NRU7d+/X7Nnz1Z8fLwkqXbt2tq7d682btyo7777TuPGjVNSUtLtvxEAAKDMYgTwGr169dKvv/6q5s2by9nZWUOHDrX93EtxGjRooG3btun111/X448/LqvVqoceekjdu3cv8Rw/Pz/FxcXptdde07vvvqsmTZpo2rRpeuqpp25a36RJk+Tn56cpU6bo1KlT8vHxUZMmTfTaa69JkgYMGKADBw6oe/fuMplMev755zVw4ECtX7/+9t8MAABQJrEK+DciIyPVqFEjzZw509GlONzVVUSsAgbwW6wCBko3VgEDAACgWARAAAAAg2EKGMW61SFkAABQejAFDAAAgGIRAAEAAAyGAAgAAGAwBEAAAACDIQACAAAYDAEQAADAYAiAAAAABkMABAAAMBgCIAAAgMEQAAEAAAyGAAgAAGAwBEAAAACDIQACAAAYDAEQAADAYAiAAAAABkMABAAAMBgCIAAAgMEQAAEAAAzGxdEFoHSrN2GjnMzlHV0GSpAW28HRJQAA7kOMAAIAABgMARAAAMBgCIAAAAAGQwB0sOjoaDVq1KjE43FxcfLx8fnD6gEAAGUfAbCU6969u7777jtHlwEAAMoQVgE7iNVqVWFh4U3bubu7y93d/Q+oCAAAGAUjgLcoMjJSgwcP1uDBg+Xt7S1fX1+NGzdOVqtVkrRkyRKFhYXJYrGoatWq6tGjh7KysmznJyQkyGQyaf369WratKnMZrN27tx53XVSU1NVs2ZNDR48WFar9bop4KtTxkuWLFFQUJC8vb313HPPKTc319YmNzdXPXv2lIeHh/z9/fXOO+8oMjJSw4YNu2fvDwAAuH8QAG9DfHy8XFxctGfPHs2aNUszZszQwoULJUkFBQWaNGmSDh06pNWrVystLU19+vS5ro8xY8YoNjZWycnJatCggd2xb7/9Vo899ph69OihOXPmyGQyFVtHamqqVq9erXXr1mndunXatm2bYmNjbcdHjBihxMRErV27Vps2bdKOHTu0f//+G95bfn6+cnJy7DYAAFA2MQV8GwICAvTOO+/IZDIpODhYhw8f1jvvvKN+/frppZdesrWrWbOm3n33XTVr1kx5eXny9PS0HZs4caLatWt3Xd+7du1Sx44d9frrr+vVV1+9YR1FRUWKi4uTxWKRJL3wwgvasmWLJk+erNzcXMXHx+ujjz5SmzZtJEmLFi1StWrVbtjnlClTFBMTc8vvBQAAuH8xAngbHn30UbtRuRYtWujEiRMqLCzUvn371KlTJwUGBspisSgiIkKSlJ6ebtdHWFjYdf2mp6erXbt2Gj9+/E3DnyQFBQXZwp8k+fv726abT506pYKCAjVv3tx23NvbW8HBwTfsc+zYscrOzrZtGRkZN60DAADcnwiAd8HFixcVFRUlLy8vLV26VElJSVq1apUk6dKlS3ZtPTw8rjvfz89PzZs317Jly25p6rVcuXJ2r00mk4qKiu7gDiSz2SwvLy+7DQAAlE0EwNuwe/duu9fffPONateurePHj+vs2bOKjY3V448/rjp16tgtALkZd3d3rVu3Tm5uboqKirJb0HG7atasqXLlyikpKcm2Lzs7m5+SAQAANgTA25Cenq4RI0YoJSVFy5Yt0+zZszV06FAFBgbK1dVVs2fP1qlTp7R27VpNmjTptvr28PDQ559/LhcXFz355JPKy8v7XTVaLBb17t1bo0aN0tatW3X06FH17dtXTk5OJS4qAQAAxkIAvA29evXSr7/+qubNm2vQoEEaOnSo+vfvLz8/P8XFxemTTz5RaGioYmNjNW3atNvu39PTU+vXr5fValWHDh10/vz531XnjBkz1KJFC3Xs2FFt27ZVeHi4QkJC5Obm9rv6AwAAZYvJevWH7HBDkZGRatSokWbOnOnoUm7b+fPn9cADD2j69Onq27fvLZ2Tk5Mjb29vBQz7WE7m8ve4QvxeabEdHF0CAKAUufr9nZ2dfcPn+fkZmDLowIEDOn78uJo3b67s7GxNnDhRktS5c2cHVwYAAEoDAmAZNW3aNKWkpMjV1VVNmzbVjh075Ovr6+iyAABAKcAUMIp1q0PIAACg9LjV728WgQAAABgMARAAAMBgCIAAAAAGQwAEAAAwGAIgAACAwRAAAQAADIYACAAAYDAEQAAAAIMhAAIAABgMARAAAMBgCIAAAAAGQwAEAAAwGAIgAACAwRAAAQAADIYACAAAYDAEQAAAAIMhAAIAABgMARAAAMBgCIAAAAAGQwAEAAAwGAIgAACAwRAAAQAADMZhATAtLU0mk0kHDx50VAk3FBQUpJkzZ9pem0wmrV69+obn9OnTR126dLmrdURHR6tRo0Z3tU8AAGBsLo66cEBAgDIzM+Xr6+uoEm5LZmamKlSoIOlKeK1Ro4YOHDhgF85mzZolq9V6V687cuRIvfLKK3e1TwAAYGwOC4DOzs6qWrVqicetVqsKCwvl4uKwEu3cqNarvL297/p1PT095enpedf7BQAAxnVPp4A3bNigxx57TD4+PqpUqZI6duyo1NRUSddPASckJMhkMmn9+vVq2rSpzGazdu7cqaKiIk2dOlW1atWS2WxWYGCgJk+ebLvG4cOH9cQTT8jd3V2VKlVS//79lZeXZzt+dVp22rRp8vf3V6VKlTRo0CAVFBTY2mRlZalTp05yd3dXjRo1tHTp0uvu5bdTwDVq1JAkNW7cWCaTSZGRkXbXuio/P19DhgxR5cqV5ebmpscee0xJSUm241fvecuWLQoLC1P58uXVsmVLpaSk2NpcOwV8K/eTmZmpDh062O7no48+um5KGwAAGNc9DYDnz5/XiBEjtHfvXm3ZskVOTk7q2rWrioqKSjxnzJgxio2NVXJysho0aKCxY8cqNjZW48aN07Fjx/TRRx+pSpUqtv6joqJUoUIFJSUl6ZNPPtHmzZs1ePBguz63bt2q1NRUbd26VfHx8YqLi1NcXJzteJ8+fZSRkaGtW7fq008/1XvvvaesrKwSa9yzZ48kafPmzcrMzNTKlSuLbTd69Gh99tlnio+P1/79+1WrVi1FRUXp559/tmv3+uuva/r06dq7d69cXFz00ksv3fB9vdn99OrVS//5z3+UkJCgzz77TPPnz7/h/UhXwmpOTo7dBgAAyijrH+i///2vVZL18OHD1tOnT1slWQ8cOGC1Wq3WrVu3WiVZV69ebWufk5NjNZvN1gULFhTb3/z5860VKlSw5uXl2fZ9/vnnVicnJ+uPP/5otVqt1t69e1urV69uvXz5sq3Ns88+a+3evbvVarVaU1JSrJKse/bssR1PTk62SrK+8847tn2SrKtWrbJardbrar+qd+/e1s6dO1utVqs1Ly/PWq5cOevSpUttxy9dumStVq2aderUqXb3vHnzZrv6JVl//fVXq9VqtU6YMMHasGFDu2vc6H6u1p6UlGQ7fuLEievu51oTJkywSrpuy87OLvEcAABQumRnZ9/S9/c9HQE8ceKEnn/+edWsWVNeXl4KCgqSJKWnp5d4TlhYmO3fycnJys/PV5s2bYptm5ycrIYNG8rDw8O2Lzw8XEVFRXbTqHXr1pWzs7Pttb+/v21ELDk5WS4uLmratKnteJ06deTj43Nb93qt1NRUFRQUKDw83LavXLlyat68uZKTk+3aNmjQwK42STccsbvR/aSkpMjFxUVNmjSxHa9Vq5ZtAUtJxo4dq+zsbNuWkZFxC3cJAADuR/d0hUWnTp1UvXp1LViwQNWqVVNRUZHq1aunS5culXjOb8Ocu7v7XamjXLlydq9NJtMNp6H/aL+tz2QySdIN67sX92M2m2U2m++oDwAAcH+4ZyOAZ8+eVUpKiv7xj3+oTZs2CgkJ0S+//HJbfdSuXVvu7u7asmVLscdDQkJ06NAhnT9/3rYvMTFRTk5OCg4OvqVr1KlTR5cvX9a+ffts+1JSUnTu3LkSz3F1dZUkFRYWltjmoYcekqurqxITE237CgoKlJSUpNDQ0Fuq7fcIDg7W5cuXdeDAAdu+kydP3vZ7DwAAyq57FgArVKigSpUqaf78+Tp58qS++uorjRgx4rb6cHNz09///neNHj1aixcvVmpqqr755ht98MEHkqSePXvKzc1NvXv31pEjR7R161a98soreuGFF2wLRW4mODhY7du314ABA7R7927t27dPL7/88g1HHytXrix3d3dt2LBBZ86cUXZ29nVtPDw89D//8z8aNWqUNmzYoGPHjqlfv366cOGC+vbte1vvw+2oU6eO2rZtq/79+2vPnj06cOCA+vfvL3d3d9voIgAAMLZ7FgCdnJy0fPly7du3T/Xq1dPw4cP19ttv33Y/48aN06uvvqrx48crJCRE3bt3tz3vVr58eW3cuFE///yzmjVrpr/85S9q06aN5syZc1vXWLRokapVq6aIiAg9/fTT6t+/vypXrlxiexcXF7377ruaN2+eqlWrps6dOxfbLjY2Vs8884xeeOEFNWnSRCdPntTGjRtv+jzenVq8eLGqVKmiVq1aqWvXrurXr58sFovc3Nzu6XUBAMD9wWS13uU/XYFS54cfflBAQIA2b95c4oKaa+Xk5Mjb21vZ2dny8vK6xxUCAIC74Va/v0vHn9nAXfXVV18pLy9P9evXV2ZmpkaPHq2goCC1atXK0aUBAIBSgABYBhUUFOi1117TqVOnZLFY1LJlSy1duvS61cMAAMCYmAJGsZgCBgDg/nOr39/39IegAQAAUPoQAAEAAAyGAAgAAGAwBEAAAACDIQACAAAYDAEQAADAYAiAAAAABkMABAAAMBgCIAAAgMEQAAEAAAyGAAgAAGAwBEAAAACDIQACAAAYDAEQAADAYAiAAAAABkMABAAAMBgCIAAAgMEQAAEAAAzGxdEFoHSrN2GjnMzlHV0GDCIttoOjSwAAQ2AEEAAAwGAIgAAAAAZDAAQAADCY2wqAkZGRGjZs2D0qpXSKjo5Wo0aNHHLttLQ0mUwmHTx40CHXBwAAZdMfOgL4R4Upk8mk1atX3/Pr3E19+vRRly5d7PYFBAQoMzNT9erVc0xRAACgTGIV8A0UFBQ49PrOzs6qWrWqQ2sAAABlz22PABYVFWn06NGqWLGiqlatqujoaNux9PR0de7cWZ6envLy8lK3bt105swZSVJcXJxiYmJ06NAhmUwmmUwmxcXFaeTIkerYsaOtj5kzZ8pkMmnDhg22fbVq1dLChQslSUlJSWrXrp18fX3l7e2tiIgI7d+/39Y2KChIktS1a1eZTCbba0las2aNmjRpIjc3N9WsWVMxMTG6fPmy7bjJZNLcuXP11FNPycPDQ5MnT7YdW7JkiYKCguTt7a3nnntOubm5du/JlClTVKNGDbm7u6thw4b69NNPbccLCwvVt29f2/Hg4GDNmjXLdjw6Olrx8fFas2aN7b1JSEi4bgo4ISFBJpNJW7ZsUVhYmMqXL6+WLVsqJSXF7jN64403VLlyZVksFr388ssaM2aMw6axAQBA6XPbATA+Pl4eHh7avXu3pk6dqokTJ2rTpk0qKipS586d9fPPP2vbtm3atGmTTp06pe7du0uSunfvrldffVV169ZVZmamMjMz1b17d0VERGjnzp0qLCyUJG3btk2+vr5KSEiQJP373/9WamqqIiMjJUm5ubnq3bu3du7cqW+++Ua1a9fWn//8Z1sgS0pKkiQtWrRImZmZttc7duxQr169NHToUB07dkzz5s1TXFycXciTroSxrl276vDhw3rppZckSampqVq9erXWrVundevWadu2bYqNjbWdM2XKFC1evFjvv/++jh49quHDh+uvf/2rtm3bJulKQHzwwQf1ySef6NixYxo/frxee+01ffzxx5KkkSNHqlu3bmrfvr3tvWnZsmWJn8Hrr7+u6dOna+/evXJxcbHVKUlLly7V5MmT9dZbb2nfvn0KDAzU3Llzb/q55ufnKycnx24DAABl021PATdo0EATJkyQJNWuXVtz5szRli1bJEmHDx/W6dOnFRAQIElavHix6tatq6SkJDVr1kyenp5ycXGxm9Z8/PHHlZubqwMHDqhp06bavn27Ro0aZXuGLyEhQQ888IBq1aolSXriiSfs6pk/f758fHy0bds2dezYUX5+fpIkHx8fu+vExMRozJgx6t27tySpZs2amjRpkkaPHm27H0nq0aOHXnzxRbtrFBUVKS4uThaLRZL0wgsvaMuWLZo8ebLy8/P15ptvavPmzWrRooWt7507d2revHmKiIhQuXLlFBMTY+uvRo0a+vrrr/Xxxx+rW7du8vT0lLu7u/Lz829pynfy5MmKiIiQJI0ZM0YdOnTQxYsX5ebmptmzZ6tv3762exg/fry+/PJL5eXl3bDPKVOm2NUIAADKrtseAWzQoIHda39/f2VlZSk5OVkBAQG28CdJoaGh8vHxUXJycon9+fj4qGHDhkpISNDhw4fl6uqq/v3768CBA8rLy9O2bdtsYUeSzpw5o379+ql27dry9vaWl5eX8vLylJ6efsO6Dx06pIkTJ8rT09O29evXT5mZmbpw4YKtXVhY2HXnBgUF2cLfb+9Zkk6ePKkLFy6oXbt2dn0vXrxYqamptnP++c9/qmnTpvLz85Onp6fmz59/05pL8tvPwN/fX5Js9aSkpKh58+Z27a99XZyxY8cqOzvbtmVkZPyu2gAAQOl32yOA5cqVs3ttMplUVFR0R0VERkYqISFBZrNZERERqlixokJCQrRz505t27ZNr776qq1t7969dfbsWc2aNUvVq1eX2WxWixYtdOnSpRteIy8vTzExMXr66aevO+bm5mb7t4eHx3XHb3TPV0fWPv/8cz3wwAN27cxmsyRp+fLlGjlypKZPn64WLVrIYrHo7bff1u7du29Yc0l+W4/JZJKkO/4MzGazrV4AAFC23bVVwCEhIcrIyFBGRoZtFPDYsWM6d+6cQkNDJUmurq62Z/1+KyIiQh9++KFcXFzUvn17SVdC4bJly/Tdd9/Znv+TpMTERL333nv685//LEnKyMjQTz/9ZNdfuXLlrrtOkyZNlJKSYptKvltCQ0NlNpuVnp5uN1L5W4mJiWrZsqUGDhxo2/fb0UGp5PfmdgUHByspKUm9evWy7bv6HCQAAIB0FwNg27ZtVb9+ffXs2VMzZ87U5cuXNXDgQEVERNimVYOCgnT69GkdPHhQDz74oCwWi8xms1q1aqXc3FytW7fOtrgiMjJSf/nLX+Tv76+HH37Ydp3atWtryZIlCgsLU05OjkaNGiV3d3e7WoKCgrRlyxaFh4fLbDarQoUKGj9+vDp27KjAwED95S9/kZOTkw4dOqQjR47ojTfe+N33bbFYNHLkSA0fPlxFRUV67LHHlJ2drcTERHl5eal3796qXbu2Fi9erI0bN6pGjRpasmSJkpKSVKNGDbuaN27cqJSUFFWqVEne3t6/q55XXnlF/fr1U1hYmFq2bKkVK1bo22+/Vc2aNX/3PQIAgLLlrv0QtMlk0po1a1ShQgW1atVKbdu2Vc2aNbVixQpbm2eeeUbt27dX69at5efnp2XLlkmSKlSooPr168vPz0916tSRJLVq1UpFRUXXjap98MEH+uWXX9SkSRO98MILGjJkiCpXrmzXZvr06dq0aZMCAgLUuHFjSVJUVJTWrVunL7/8Us2aNdOjjz6qd955R9WrV7/je580aZLGjRunKVOmKCQkRO3bt9fnn39uC3gDBgzQ008/re7du+uRRx7R2bNn7UYDJalfv34KDg5WWFiY/Pz8lJiY+Ltq6dmzp8aOHauRI0eqSZMmOn36tPr06WM3zQ0AAIzNZLVarY4uAvdWu3btVLVqVS1ZsuSWz8nJyZG3t7cChn0sJ3P5e1gd8P+lxXZwdAkAcF+7+v2dnZ0tLy+vEtvxl0DKmAsXLuj9999XVFSUnJ2dtWzZMm3evFmbNm1ydGkAAKCUIACWMSaTSV988YUmT56sixcvKjg4WJ999pnatm3r6NIAAEApwRQwinWrQ8gAAKD0uNXv77u2CAQAAAD3BwIgAACAwRAAAQAADIYACAAAYDAEQAAAAIMhAAIAABgMARAAAMBgCIAAAAAGQwAEAAAwGAIgAACAwRAAAQAADIYACAAAYDAEQAAAAIMhAAIAABgMARAAAMBgCIAAAAAGQwAEAAAwGAIgAACAwbg4ugCUbvUmbJSTubyjy7gr0mI7OLoEAABKBUYAAQAADIYACAAAYDAEQAAAAIMxRACMjIzUsGHDHF0GAABAqWCIAGhkQUFBmjlzpqPLAAAApQgBEAAAwGAMEwAvX76swYMHy9vbW76+vho3bpysVqskacmSJQoLC5PFYlHVqlXVo0cPZWVl2c795Zdf1LNnT/n5+cnd3V21a9fWokWLbMczMjLUrVs3+fj4qGLFiurcubPS0tJsx/v06aMuXbrozTffVJUqVeTj46OJEyfq8uXLGjVqlCpWrKgHH3zQrs/b6XfatGny9/dXpUqVNGjQIBUUFEi6MvX9/fffa/jw4TKZTDKZTPfgnQUAAPcbwwTA+Ph4ubi4aM+ePZo1a5ZmzJihhQsXSpIKCgo0adIkHTp0SKtXr1ZaWpr69OljO3fcuHE6duyY1q9fr+TkZM2dO1e+vr62c6OiomSxWLRjxw4lJibK09NT7du316VLl2x9fPXVV/rPf/6j7du3a8aMGZowYYI6duyoChUqaPfu3frb3/6mAQMG6Icffritfrdu3arU1FRt3bpV8fHxiouLU1xcnCRp5cqVevDBBzVx4kRlZmYqMzOzxPcnPz9fOTk5dhsAACibTNarw2BlWGRkpLKysnT06FHbKNiYMWO0du1aHTt27Lr2e/fuVbNmzZSbmytPT0899dRT8vX11Ycffnhd23/961964403lJycbOv70qVL8vHx0erVq/WnP/1Jffr0UUJCgk6dOiUnpyuZu06dOqpcubK2b98uSSosLJS3t7cWLlyo55577rb6TU1NlbOzsySpW7ducnJy0vLlyyVdeQZw2LBhN10EEx0drZiYmOv2Bwz7mB+CBgDgPpGTkyNvb29lZ2fLy8urxHaGGQF89NFH7aZAW7RooRMnTqiwsFD79u1Tp06dFBgYKIvFooiICElSenq6JOl//ud/tHz5cjVq1EijR4/Wrl27bP0cOnRIJ0+elMVikaenpzw9PVWxYkVdvHhRqamptnZ169a1hT9JqlKliurXr2977ezsrEqVKtmmnm+n36vhT5L8/f3tpq9v1dixY5WdnW3bMjIybrsPAABwfzD8n4K7ePGioqKiFBUVpaVLl8rPz0/p6emKioqyTbU++eST+v777/XFF19o06ZNatOmjQYNGqRp06YpLy9PTZs21dKlS6/r28/Pz/bvcuXK2R0zmUzF7isqKpKkO+r3ah+3w2w2y2w23/Z5AADg/mOYALh792671998841q166t48eP6+zZs4qNjVVAQICkK1PA1/Lz81Pv3r3Vu3dvPf744xo1apSmTZumJk2aaMWKFapcufINh1pv193q19XVVYWFhXetLgAAcP8zzBRwenq6RowYoZSUFC1btkyzZ8/W0KFDFRgYKFdXV82ePVunTp3S2rVrNWnSJLtzx48frzVr1ujkyZM6evSo1q1bp5CQEElSz5495evrq86dO2vHjh06ffq0EhISNGTIENuCjt/jbvUbFBSk7du369///rd++umn310PAAAoOwwTAHv16qVff/1VzZs316BBgzR06FD1799ffn5+iouL0yeffKLQ0FDFxsZq2rRpdue6urpq7NixatCggVq1aiVnZ2fbIovy5ctr+/btCgwM1NNPP62QkBD17dtXFy9evKORu7vV78SJE5WWlqaHHnrIbuoYAAAYlyFWAeP2XV1FxCpgAADuH6wCBgAAQLEIgAAAAAZjmFXA+H2OxETd1dXNAADA8RgBBAAAMBgCIAAAgMEQAAEAAAyGAAgAAGAwBEAAAACDIQACAAAYDAEQAADAYAiAAAAABkMABAAAMBgCIAAAgMEQAAEAAAyGAAgAAGAwBEAAAACDIQACAAAYDAEQAADAYAiAAAAABkMABAAAMBgCIAAAgMG4OLoAlG71JmyUk7m8o8sAgHsmLbaDo0sA/nCMAAIAABgMARAAAMBgCIAAAAAGQwAEAAAwGALgXRYdHa1GjRo5ugwAAIASEQAdpKCgwNElAAAAgypzATA3N1c9e/aUh4eH/P399c477ygyMlLDhg2TJJlMJq1evdruHB8fH8XFxdleZ2RkqFu3bvLx8VHFihXVuXNnpaWl2Y4nJCSoefPm8vDwkI+Pj8LDw/X9998rLi5OMTExOnTokEwmk0wmk61fk8mkuXPn6qmnnpKHh4cmT54sSZo7d64eeughubq6Kjg4WEuWLLGrLT09XZ07d5anp6e8vLzUrVs3nTlzxnb86ojjhx9+qMDAQHl6emrgwIEqLCzU1KlTVbVqVVWuXNl2PQAAgDIXAEeMGKHExEStXbtWmzZt0o4dO7R///5bPr+goEBRUVGyWCzasWOHEhMT5enpqfbt2+vSpUu6fPmyunTpooiICH377bf6+uuv1b9/f5lMJnXv3l2vvvqq6tatq8zMTGVmZqp79+62vqOjo9W1a1cdPnxYL730klatWqWhQ4fq1Vdf1ZEjRzRgwAC9+OKL2rp1qySpqKhInTt31s8//6xt27Zp06ZNOnXqlF2fkpSamqr169drw4YNWrZsmT744AN16NBBP/zwg7Zt26a33npL//jHP7R79+4S7zs/P185OTl2GwAAKJvK1A9B5+bmKj4+Xh999JHatGkjSVq0aJGqVat2y32sWLFCRUVFWrhwoUwmk60PHx8fJSQkKCwsTNnZ2erYsaMeeughSVJISIjtfE9PT7m4uKhq1arX9d2jRw+9+OKLttfPP/+8+vTpo4EDB0q6El6/+eYbTZs2Ta1bt9aWLVt0+PBhnT59WgEBAZKkxYsXq27dukpKSlKzZs0kXQmKH374oSwWi0JDQ9W6dWulpKToiy++kJOTk4KDg/XWW29p69ateuSRR4q97ylTpigmJuaW3ycAAHD/KlMjgKdOnVJBQYGaN29u2+ft7a3g4OBb7uPQoUM6efKkLBaLPD095enpqYoVK+rixYtKTU1VxYoV1adPH0VFRalTp06aNWuWMjMzb6nvsLAwu9fJyckKDw+32xceHq7k5GTb8YCAAFv4k6TQ0FD5+PjY2khSUFCQLBaL7XWVKlUUGhoqJycnu31ZWVkl1jZ27FhlZ2fbtoyMjFu6JwAAcP8pUyOAt8JkMslqtdrt++2CjLy8PDVt2lRLly697lw/Pz9JV0YEhwwZog0bNmjFihX6xz/+oU2bNunRRx+94bU9PDzuwh1cr1y5cnavTSZTsfuKiopK7MNsNstsNt+T+gAAQOlSpkYAa9asqXLlyikpKcm2Lzs7W999953ttZ+fn92I3YkTJ3ThwgXb6yZNmujEiROqXLmyatWqZbd5e3vb2jVu3Fhjx47Vrl27VK9ePX300UeSJFdXVxUWFt5SvSEhIUpMTLTbl5iYqNDQUNvxjIwMu9G4Y8eO6dy5c7Y2AAAAt6tMBUCLxaLevXtr1KhR2rp1q44ePaq+ffvKycnJ9jzfE088oTlz5ujAgQPau3ev/va3v9mNlvXs2VO+vr7q3LmzduzYodOnTyshIUFDhgzRDz/8oNOnT2vs2LH6+uuv9f333+vLL7/UiRMnbM8BBgUF6fTp0zp48KB++ukn5efnl1jvqFGjFBcXp7lz5+rEiROaMWOGVq5cqZEjR0qS2rZtq/r166tnz57av3+/9uzZo169eikiIuK66WQAAIBbVaYCoCTNmDFDLVq0UMeOHdW2bVuFh4crJCREbm5ukqTp06crICBAjz/+uHr06KGRI0eqfPnytvPLly+v7du3KzAwUE8//bRCQkLUt29fXbx4UV5eXipfvryOHz+uZ555Rg8//LD69++vQYMGacCAAZKkZ555Ru3bt1fr1q3l5+enZcuWlVhrly5dNGvWLE2bNk1169bVvHnztGjRIkVGRkq6Mm27Zs0aVahQQa1atVLbtm1Vs2ZNrVix4t69gQAAoMwzWa99IK6MOX/+vB544AFNnz5dffv2dXQ5942cnBx5e3srYNjHcjKXv/kJAHCfSovt4OgSgLvm6vd3dna2vLy8SmxX5haBHDhwQMePH1fz5s2VnZ2tiRMnSpI6d+7s4MoAAABKhzIXACVp2rRpSklJkaurq5o2baodO3bI19fX0WUBAACUCmV+Chi/z60OIQMAgNLjVr+/y9wiEAAAANwYARAAAMBgCIAAAAAGQwAEAAAwGAIgAACAwRAAAQAADIYACAAAYDAEQAAAAIMhAAIAABgMARAAAMBgCIAAAAAGQwAEAAAwGAIgAACAwRAAAQAADIYACAAAYDAEQAAAAIMhAAIAABgMARAAAMBgXBxdAEq3ehM2yslc3tFlAABQZqTFdnB0CYwAAgAAGA0BEAAAwGAIgAAAAAZDALxPBAUFaebMmY4uAwAAlAEsArlH+vTpo3Pnzmn16tV3pb+kpCR5eHjclb4AAICxEQBLuUuXLsnV1VV+fn6OLgUAAJQRTAHfoU8//VT169eXu7u7KlWqpLZt22rUqFGKj4/XmjVrZDKZZDKZlJCQIEk6fPiwnnjiCVv7/v37Ky8vz9Zfnz591KVLF02ePFnVqlVTcHCwpOungM+dO6eXX35Zfn5+8vLy0hNPPKFDhw7Zjh86dEitW7eWxWKRl5eXmjZtqr179/4h7wkAACjdGAG8A5mZmXr++ec1depUde3aVbm5udqxY4d69eql9PR05eTkaNGiRZKkihUr6vz584qKilKLFi2UlJSkrKwsvfzyyxo8eLDi4uJs/W7ZskVeXl7atGlTidd+9tln5e7urvXr18vb21vz5s1TmzZt9N1336lixYrq2bOnGjdurLlz58rZ2VkHDx5UuXLlSuwvPz9f+fn5ttc5OTl3/gYBAIBSiQB4BzIzM3X58mU9/fTTql69uiSpfv36kiR3d3fl5+eratWqtvbx8fG6ePGiFi9ebHueb86cOerUqZPeeustValSRZLk4eGhhQsXytXVtdjr7ty5U3v27FFWVpbMZrMkadq0aVq9erU+/fRT9e/fX+np6Ro1apTq1KkjSapdu/YN72XKlCmKiYm5g3cDAADcL5gCvgMNGzZUmzZtVL9+fT377LNasGCBfvnllxLbJycnq2HDhnaLOcLDw1VUVKSUlBTbvvr165cY/qQr07t5eXmqVKmSPD09bdvp06eVmpoqSRoxYoRefvlltW3bVrGxsbb9JRk7dqyys7NtW0ZGxq2+DQAA4D5DALwDzs7O2rRpk9avX6/Q0FDNnj1bwcHBOn369B31e7PVvnl5efL399fBgwfttpSUFI0aNUqSFB0draNHj6pDhw766quvFBoaqlWrVpXYp9lslpeXl90GAADKJgLgHTKZTAoPD1dMTIwOHDggV1dXrVq1Sq6uriosLLRrGxISokOHDun8+fO2fYmJiXJycrIt9rgVTZo00Y8//igXFxfVqlXLbvP19bW1e/jhhzV8+HB9+eWXevrpp23PIwIAAGMjAN6B3bt3680339TevXuVnp6ulStX6r///a9CQkIUFBSkb7/9VikpKfrpp59UUFCgnj17ys3NTb1799aRI0e0detWvfLKK3rhhRdsz//dirZt26pFixbq0qWLvvzyS6WlpWnXrl16/fXXtXfvXv36668aPHiwEhIS9P333ysxMVFJSUkKCQm5h+8GAAC4X7AI5A54eXlp+/btmjlzpnJyclS9enVNnz5dTz75pMLCwpSQkKCwsDDl5eVp69atioyM1MaNGzV06FA1a9ZM5cuX1zPPPKMZM2bc1nVNJpO++OILvf7663rxxRf13//+V1WrVlWrVq1UpUoVOTs76+zZs+rVq5fOnDkjX19fPf300yzyAAAAkiST1Wq1OroIlD45OTny9vZWwLCP5WQu7+hyAAAoM9JiO9yzvq9+f2dnZ9/weX6mgAEAAAyGAAgAAGAwPAOIGzoSE8VPwgAAUMYwAggAAGAwBEAAAACDIQACAAAYDAEQAADAYAiAAAAABkMABAAAMBgCIAAAgMEQAAEAAAyGAAgAAGAwBEAAAACDIQACAAAYDAEQAADAYAiAAAAABkMABAAAMBgCIAAAgMEQAAEAAAyGAAgAAGAwBEAAAACDcXF0ASjd6k3YKCdzeUeXAQC4RWmxHRxdAu4DjAACAAAYDAEQAADAYAiAAAAABlPmAmBkZKSGDRt23/QLAADwRytzAfBOJSQkyGQy6dy5c44uBQAA4J4gAN5DBQUFji4BAADgOmUyAF6+fFmDBw+Wt7e3fH19NW7cOFmtVknSkiVLFBYWJovFoqpVq6pHjx7KysqSJKWlpal169aSpAoVKshkMqlPnz62fouKijR69GhVrFhRVatWVXR0tN11TSaT5s6dq6eeekoeHh6aPHmyJGnu3Ll66KGH5OrqquDgYC1ZssTuvPT0dHXu3Fmenp7y8vJSt27ddObMGdvx6OhoNWrUSB9++KECAwPl6empgQMHqrCwUFOnTlXVqlVVuXJl2/UkyWq1Kjo6WoGBgTKbzapWrZqGDBly195jAABw/yqTATA+Pl4uLi7as2ePZs2apRkzZmjhwoWSrozKTZo0SYcOHdLq1auVlpZmC3kBAQH67LPPJEkpKSnKzMzUrFmz7Pr18PDQ7t27NXXqVE2cOFGbNm2yu3Z0dLS6du2qw4cP66WXXtKqVas0dOhQvfrqqzpy5IgGDBigF198UVu3bpV0JVR27txZP//8s7Zt26ZNmzbp1KlT6t69u12/qampWr9+vTZs2KBly5bpgw8+UIcOHfTDDz9o27Zteuutt/SPf/xDu3fvliR99tlneueddzRv3jydOHFCq1evVv369Ut8z/Lz85WTk2O3AQCAsslkvTo0VkZERkYqKytLR48elclkkiSNGTNGa9eu1bFjx65rv3fvXjVr1ky5ubny9PRUQkKCWrdurV9++UU+Pj52/RYWFmrHjh22fc2bN9cTTzyh2NhYSVdGAIcNG6Z33nnH1iY8PFx169bV/Pnzbfu6deum8+fP6/PPP9emTZv05JNP6vTp0woICJAkHTt2THXr1tWePXvUrFkzRUdH6+2339aPP/4oi8UiSWrfvr1SUlKUmpoqJ6crOb5OnTrq06ePxowZoxkzZmjevHk6cuSIypUrd9P3LTo6WjExMdftDxj2MT8EDQD3EX4I2thycnLk7e2t7OxseXl5ldiuTI4APvroo7bwJ0ktWrTQiRMnVFhYqH379qlTp04KDAyUxWJRRESEpCvTsDfToEEDu9f+/v626eOrwsLC7F4nJycrPDzcbl94eLiSk5NtxwMCAmzhT5JCQ0Pl4+NjayNJQUFBtvAnSVWqVFFoaKgt/F3dd7WeZ599Vr/++qtq1qypfv36adWqVbp8+XKJ9zZ27FhlZ2fbtoyMjBu+FwAA4P5VJgNgSS5evKioqCh5eXlp6dKlSkpK0qpVqyRJly5duun5146kmUwmFRUV2e3z8PC4ewXf5No3qicgIEApKSl677335O7uroEDB6pVq1YlLkwxm83y8vKy2wAAQNlUJgPg1efgrvrmm29Uu3ZtHT9+XGfPnlVsbKwef/xx1alT57oRPFdXV0lSYWHhXaklJCREiYmJdvsSExMVGhpqO56RkWE34nbs2DGdO3fO1ub3cnd3V6dOnfTuu+8qISFBX3/9tQ4fPnxHfQIAgPufi6MLuBfS09M1YsQIDRgwQPv379fs2bM1ffp0BQYGytXVVbNnz9bf/vY3HTlyRJMmTbI7t3r16jKZTFq3bp3+/Oc/y93dXZ6enr+7llGjRqlbt25q3Lix2rZtq//93//VypUrtXnzZklS27ZtVb9+ffXs2VMzZ87U5cuXNXDgQEVERFw3nXw74uLiVFhYqEceeUTly5fXv/71L7m7u6t69eq/u08AAFA2lMkRwF69eunXX39V8+bNNWjQIA0dOlT9+/eXn5+f4uLi9Mknnyg0NFSxsbGaNm2a3bkPPPCAYmJiNGbMGFWpUkWDBw++o1q6dOmiWbNmadq0aapbt67mzZunRYsWKTIyUtKVads1a9aoQoUKatWqldq2bauaNWtqxYoVd3RdHx8fLViwQOHh4WrQoIE2b96s//3f/1WlSpXuqF8AAHD/K3OrgHF3XF1FxCpgALi/sArY2Ay9ChgAAAAlIwACAAAYTJlcBIK750hMFD8JAwBAGcMIIAAAgMEQAAEAAAyGAAgAAGAwBEAAAACDIQACAAAYDAEQAADAYAiAAAAABkMABAAAMBgCIAAAgMEQAAEAAAyGAAgAAGAwBEAAAACDIQACAAAYDAEQAADAYAiAAAAABkMABAAAMBgCIAAAgMEQAAEAAAzGxdEFoHSrN2GjnMzlHV0GAMDA0mI7OLqEMocRQAAAAIMhAAIAABgMARAAAMBgCIAAAAAGQwAEAAAwGALgfaagoMDRJQAAgPscAdDBNmzYoMcee0w+Pj6qVKmSOnbsqNTUVElSWlqaTCaTVqxYoYiICLm5uWnp0qWSpIULFyokJERubm6qU6eO3nvvPbt+//73v+vhhx9W+fLlVbNmTY0bN47wCAAAJPE7gA53/vx5jRgxQg0aNFBeXp7Gjx+vrl276uDBg7Y2Y8aM0fTp09W4cWNbCBw/frzmzJmjxo0b68CBA+rXr588PDzUu3dvSZLFYlFcXJyqVaumw4cPq1+/frJYLBo9enSxdeTn5ys/P9/2Oicn557eNwAAcByT1Wq1OroI/H8//fST/Pz8dPjwYXl6eqpGjRqaOXOmhg4damtTq1YtTZo0Sc8//7xt3xtvvKEvvvhCu3btKrbfadOmafny5dq7d2+xx6OjoxUTE3Pd/oBhH/ND0AAAh+KHoG9dTk6OvL29lZ2dLS8vrxLbEQAd7MSJExo/frx2796tn376SUVFRTp//rw+//xzhYaGqkaNGtq5c6fCw8MlXRkx9PT0lLu7u5yc/v8M/uXLl+Xt7a0zZ85IklasWKF3331XqampysvL0+XLl+Xl5aWsrKxi6yhuBDAgIIAACABwOALgrbvVAMgUsIN16tRJ1atX14IFC1StWjUVFRWpXr16unTpkq2Nh4eH7d95eXmSpAULFuiRRx6x68vZ2VmS9PXXX6tnz56KiYlRVFSUvL29tXz5ck2fPr3EOsxms8xm8928NQAAUEoRAB3o7NmzSklJ0YIFC/T4449Lknbu3HnDc6pUqaJq1arp1KlT6tmzZ7Ftdu3aperVq+v111+37fv+++/vXuEAAOC+RgB0oAoVKqhSpUqaP3++/P39lZ6erjFjxtz0vJiYGA0ZMkTe3t5q37698vPztXfvXv3yyy8aMWKEateurfT0dC1fvlzNmjXT559/rlWrVv0BdwQAAO4H/AyMAzk5OWn58uXat2+f6tWrp+HDh+vtt9++6Xkvv/yyFi5cqEWLFql+/fqKiIhQXFycatSoIUl66qmnNHz4cA0ePFiNGjXSrl27NG7cuHt9OwAA4D7BIhAU6+pDpCwCAQA4GotAbt2tLgJhBBAAAMBgCIAAAAAGwyIQ3NCRmKgbDiEDAID7DyOAAAAABkMABAAAMBgCIAAAgMEQAAEAAAyGAAgAAGAwBEAAAACDIQACAAAYDL8DiGJd/QuBOTk5Dq4EAADcqqvf2zf7S78EQBTr7NmzkqSAgAAHVwIAAG5Xbm6uvL29SzxOAESxKlasKElKT0+/4X9AcJycnBwFBAQoIyODv9ZSSvEZlX58RqUfn9HtsVqtys3NVbVq1W7YjgCIYjk5XXk81Nvbm//hSjkvLy8+o1KOz6j04zMq/fiMbt2tDNywCAQAAMBgCIAAAAAGQwBEscxmsyZMmCCz2ezoUlACPqPSj8+o9OMzKv34jO4Nk/Vm64QBAABQpjACCAAAYDAEQAAAAIMhAAIAABgMARAAAMBgCIC4zj//+U8FBQXJzc1NjzzyiPbs2ePokvB/pkyZombNmslisahy5crq0qWLUlJSHF0WbiA2NlYmk0nDhg1zdCn4jX//+9/661//qkqVKsnd3V3169fX3r17HV0W/k9hYaHGjRunGjVqyN3dXQ899JAmTZp0079vi1tHAISdFStWaMSIEZowYYL279+vhg0bKioqSllZWY4uDZK2bdumQYMG6ZtvvtGmTZtUUFCgP/3pTzp//ryjS0MxkpKSNG/ePDVo0MDRpeA3fvnlF4WHh6tcuXJav369jh07punTp6tChQqOLg3/56233tLcuXM1Z84cJScn66233tLUqVM1e/ZsR5dWZvAzMLDzyCOPqFmzZpozZ44kqaioSAEBAXrllVc0ZswYB1eHa/33v/9V5cqVtW3bNrVq1crR5eA38vLy1KRJE7333nt644031KhRI82cOdPRZUHSmDFjlJiYqB07dji6FJSgY8eOqlKlij744APbvmeeeUbu7u7617/+5cDKyg5GAGFz6dIl7du3T23btrXtc3JyUtu2bfX11187sDKUJDs7W5JUsWJFB1eCaw0aNEgdOnSw+/8JpcPatWsVFhamZ599VpUrV1bjxo21YMECR5eF32jZsqW2bNmi7777TpJ06NAh7dy5U08++aSDKys7XBxdAEqPn376SYWFhapSpYrd/ipVquj48eMOqgolKSoq0rBhwxQeHq569eo5uhz8xvLly7V//34lJSU5uhQU49SpU5o7d65GjBih1157TUlJSRoyZIhcXV3Vu3dvR5cHXRmlzcnJUZ06deTs7KzCwkJNnjxZPXv2dHRpZQYBELhPDRo0SEeOHNHOnTsdXQp+IyMjQ0OHDtWmTZvk5ubm6HJQjKKiIoWFhenNN9+UJDVu3FhHjhzR+++/TwAsJT7++GMtXbpUH330kerWrauDBw9q2LBhqlatGp/RXUIAhI2vr6+cnZ115swZu/1nzpxR1apVHVQVijN48GCtW7dO27dv14MPPujocvAb+/btU1ZWlpo0aWLbV1hYqO3bt2vOnDnKz8+Xs7OzAyuEv7+/QkND7faFhITos88+c1BFuNaoUaM0ZswYPffcc5Kk+vXr6/vvv9eUKVMIgHcJzwDCxtXVVU2bNtWWLVts+4qKirRlyxa1aNHCgZXhKqvVqsGDB2vVqlX66quvVKNGDUeXhGu0adNGhw8f1sGDB21bWFiYevbsqYMHDxL+SoHw8PDrfj7pu+++U/Xq1R1UEa514cIFOTnZRxRnZ2cVFRU5qKKyhxFA2BkxYoR69+6tsLAwNW/eXDNnztT58+f14osvOro06Mq070cffaQ1a9bIYrHoxx9/lCR5e3vL3d3dwdVBkiwWy3XPZHp4eKhSpUo8q1lKDB8+XC1bttSbb76pbt26ac+ePZo/f77mz5/v6NLwfzp16qTJkycrMDBQdevW1YEDBzRjxgy99NJLji6tzOBnYHCdOXPm6O2339aPP/6oRo0a6d1339Ujjzzi6LIgyWQyFbt/0aJF6tOnzx9bDG5ZZGQkPwNTyqxbt05jx47ViRMnVKNGDY0YMUL9+vVzdFn4P7m5uRo3bpxWrVqlrKwsVatWTc8//7zGjx8vV1dXR5dXJhAAAQAADIZnAAEAAAyGAAgAAGAwBEAAAACDIQACAAAYDAEQAADAYAiAAAAABkMABAAAMBgCIAAAgMEQAAEAAAyGAAgAAGAwBEAAAACDIQACAAAYzP8DxbEq4+SWYG8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skfeature.function.similarity_based import fisher_score\n",
    "\n",
    "# get the fisher's score rankings \n",
    "ranks = fisher_score.fisher_score(X.values, y.values)\n",
    "\n",
    "# create a pandas DataFrame for easier interpretation\n",
    "feat_importances = pd.Series(ranks, X.columns)\n",
    "feat_importances.plot(kind='barh')\n",
    "\n",
    "# how to interpret -> low score means the effect of this field is not large in the dataset\n",
    "# => typically means other columns in the dataset have similar correlations, \n",
    "# therefore making this particular column not so useful since other columns \n",
    "# already fill this role for this correlation\n",
    "\n",
    "# Fisher's score studies the variance of the data -> statistical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>area</td>\n",
       "      <td>279446.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>parking</td>\n",
       "      <td>282.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>guestroom</td>\n",
       "      <td>248.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hotwaterheating</td>\n",
       "      <td>224.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prefarea</td>\n",
       "      <td>223.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>airconditioning</td>\n",
       "      <td>198.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>basement</td>\n",
       "      <td>171.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stories</td>\n",
       "      <td>128.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>furnishing</td>\n",
       "      <td>90.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>64.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Features     Score\n",
       "0             area 279446.07\n",
       "7          parking    282.83\n",
       "3        guestroom    248.50\n",
       "5  hotwaterheating    224.40\n",
       "8         prefarea    223.95\n",
       "6  airconditioning    198.96\n",
       "4         basement    171.89\n",
       "2          stories    128.58\n",
       "9       furnishing     90.89\n",
       "1        bathrooms     64.33"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# convert all continuous variables to integer,\n",
    "# and convert all negative numbers to 0\n",
    "X_cat = X.astype(int)\n",
    "X_cat = X_cat.clip(lower=0)\n",
    "\n",
    "# initialize chi2 and SelectKBest\n",
    "# Note: chi2 -test is a very common test\n",
    "# in statistics and quantitative analysis\n",
    "# basically it studies the data whether variables are related\n",
    "# or independent of each other\n",
    "chi_2_features = SelectKBest(chi2, k=len(X_cat.columns))\n",
    "\n",
    "# fit our data to the SelectKBest\n",
    "best_features = chi_2_features.fit(X_cat,y.astype(int))\n",
    "\n",
    "# use decimal format in table print later\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# wrap it up, and show the results\n",
    "# the higher the score, the more effect that column has on price\n",
    "df_features = pd.DataFrame(best_features.scores_)\n",
    "df_columns = pd.DataFrame(X_cat.columns)\n",
    "f_scores = pd.concat([df_columns,df_features],axis=1)\n",
    "f_scores.columns = ['Features','Score']\n",
    "f_scores.sort_values(by='Score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create neural network structure</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/layers/normalization/batch_normalization.py:143: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m40\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │           \u001b[38;5;34m180\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m19\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">338</span> (1.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m338\u001b[0m (1.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">318</span> (1.24 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m318\u001b[0m (1.24 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> (80.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20\u001b[0m (80.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "variable_amount = len(X.columns)\n",
    "\n",
    "# Define Sequential neural network model\n",
    "# modify the input shape to match your training column count\n",
    "# remember, one of the columns is removed from training columns\n",
    "# to be the target value. so if your data originally had 10 columns\n",
    "# the input shape is 9 ... (10 - 1 => 9)\n",
    "# the input layer itself can have a different number of nodes\n",
    "# Tip: have at least the same number of nodes as in the input shape\n",
    "# output layer in regression is always 1 node without activation function\n",
    "\n",
    "# create a model checkpoint to a file, and only save the best one\n",
    "mc = ModelCheckpoint('best_model.keras', monitor='val_loss', mode='min', save_best_only=True)\n",
    "callback_list = [mc]\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.BatchNormalization(input_shape=(variable_amount,)),\n",
    "        layers.Dense(9, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2=0.1)),\n",
    "        layers.Dense(18, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# select the optimizer and loss function\n",
    "# you can try rmsprop also as optimizer, or stochastic gradient descent\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# common tips on how to change neural network structure if your metrics are not good:\n",
    "\n",
    "# make wider (or narrower) layers (for example, 64 or 128 nodes)\n",
    "# make a longer or shorter network (add or remove layers)\n",
    "# use Dropout -layers (e.g. layers.Dropout(0.1))\n",
    "\n",
    "# remember: there's no process or mathematical formula\n",
    "# in order to figure out the optimal neural network structure\n",
    "# it's mostly all about trial and error => EXPERIMENTATION!\n",
    "\n",
    "# remember to have enough \"decision-space\" for your data!\n",
    "# it's highly unlikely a dataset with 20 different variables is going\n",
    "# to work well with only 8 nodes in each layer etc.\n",
    "\n",
    "# print out the summary of your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train the neural network with our data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 24387306651648.0000 - val_loss: 25236883898368.0000\n",
      "Epoch 2/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387304554496.0000 - val_loss: 25236881801216.0000\n",
      "Epoch 3/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387300360192.0000 - val_loss: 25236879704064.0000\n",
      "Epoch 4/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387300360192.0000 - val_loss: 25236879704064.0000\n",
      "Epoch 5/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387296165888.0000 - val_loss: 25236875509760.0000\n",
      "Epoch 6/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387291971584.0000 - val_loss: 25236871315456.0000\n",
      "Epoch 7/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387287777280.0000 - val_loss: 25236867121152.0000\n",
      "Epoch 8/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24387281485824.0000 - val_loss: 25236860829696.0000\n",
      "Epoch 9/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387275194368.0000 - val_loss: 25236854538240.0000\n",
      "Epoch 10/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24387266805760.0000 - val_loss: 25236846149632.0000\n",
      "Epoch 11/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387258417152.0000 - val_loss: 25236835663872.0000\n",
      "Epoch 12/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387245834240.0000 - val_loss: 25236820983808.0000\n",
      "Epoch 13/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387229057024.0000 - val_loss: 25236806303744.0000\n",
      "Epoch 14/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387212279808.0000 - val_loss: 25236785332224.0000\n",
      "Epoch 15/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387189211136.0000 - val_loss: 25236762263552.0000\n",
      "Epoch 16/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387161948160.0000 - val_loss: 25236730806272.0000\n",
      "Epoch 17/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387130490880.0000 - val_loss: 25236695154688.0000\n",
      "Epoch 18/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387094839296.0000 - val_loss: 25236651114496.0000\n",
      "Epoch 19/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24387048701952.0000 - val_loss: 25236598685696.0000\n",
      "Epoch 20/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24386994176000.0000 - val_loss: 25236533673984.0000\n",
      "Epoch 21/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24386927067136.0000 - val_loss: 25236458176512.0000\n",
      "Epoch 22/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24386851569664.0000 - val_loss: 25236365901824.0000\n",
      "Epoch 23/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24386759294976.0000 - val_loss: 25236254752768.0000\n",
      "Epoch 24/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24386646048768.0000 - val_loss: 25236124729344.0000\n",
      "Epoch 25/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24386516025344.0000 - val_loss: 25235967442944.0000\n",
      "Epoch 26/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24386362933248.0000 - val_loss: 25235784990720.0000\n",
      "Epoch 27/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24386180481024.0000 - val_loss: 25235573178368.0000\n",
      "Epoch 28/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24385972862976.0000 - val_loss: 25235325714432.0000\n",
      "Epoch 29/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24385729593344.0000 - val_loss: 25235040501760.0000\n",
      "Epoch 30/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24385452769280.0000 - val_loss: 25234713346048.0000\n",
      "Epoch 31/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24385131905024.0000 - val_loss: 25234342150144.0000\n",
      "Epoch 32/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24384771194880.0000 - val_loss: 25233920622592.0000\n",
      "Epoch 33/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24384355958784.0000 - val_loss: 25233440374784.0000\n",
      "Epoch 34/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24383894585344.0000 - val_loss: 25232903503872.0000\n",
      "Epoch 35/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24383374491648.0000 - val_loss: 25232303718400.0000\n",
      "Epoch 36/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24382787289088.0000 - val_loss: 25231632629760.0000\n",
      "Epoch 37/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24382139269120.0000 - val_loss: 25230888140800.0000\n",
      "Epoch 38/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24381417848832.0000 - val_loss: 25230066057216.0000\n",
      "Epoch 39/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24380614639616.0000 - val_loss: 25229157990400.0000\n",
      "Epoch 40/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24379731738624.0000 - val_loss: 25228159746048.0000\n",
      "Epoch 41/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24378769145856.0000 - val_loss: 25227069227008.0000\n",
      "Epoch 42/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24377705889792.0000 - val_loss: 25225882238976.0000\n",
      "Epoch 43/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24376550359040.0000 - val_loss: 25224586199040.0000\n",
      "Epoch 44/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24375294164992.0000 - val_loss: 25223183204352.0000\n",
      "Epoch 45/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24373924724736.0000 - val_loss: 25221673254912.0000\n",
      "Epoch 46/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24372448329728.0000 - val_loss: 25220037476352.0000\n",
      "Epoch 47/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24370850299904.0000 - val_loss: 25218282160128.0000\n",
      "Epoch 48/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24369128538112.0000 - val_loss: 25216394723328.0000\n",
      "Epoch 49/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24367278850048.0000 - val_loss: 25214368874496.0000\n",
      "Epoch 50/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24365299138560.0000 - val_loss: 25212210905088.0000\n",
      "Epoch 51/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24363181015040.0000 - val_loss: 25209904037888.0000\n",
      "Epoch 52/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24360918188032.0000 - val_loss: 25207448272896.0000\n",
      "Epoch 53/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24358506463232.0000 - val_loss: 25204835221504.0000\n",
      "Epoch 54/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24355941646336.0000 - val_loss: 25202062786560.0000\n",
      "Epoch 55/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24353217445888.0000 - val_loss: 25199126773760.0000\n",
      "Epoch 56/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24350329667584.0000 - val_loss: 25196012503040.0000\n",
      "Epoch 57/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24347269922816.0000 - val_loss: 25192724168704.0000\n",
      "Epoch 58/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24344034017280.0000 - val_loss: 25189249187840.0000\n",
      "Epoch 59/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24340613562368.0000 - val_loss: 25185583366144.0000\n",
      "Epoch 60/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24337004363776.0000 - val_loss: 25181726703616.0000\n",
      "Epoch 61/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24333204324352.0000 - val_loss: 25177664520192.0000\n",
      "Epoch 62/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24329202958336.0000 - val_loss: 25173403107328.0000\n",
      "Epoch 63/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24324996071424.0000 - val_loss: 25168923590656.0000\n",
      "Epoch 64/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24320577372160.0000 - val_loss: 25164225970176.0000\n",
      "Epoch 65/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24315942666240.0000 - val_loss: 25159303954432.0000\n",
      "Epoch 66/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24311087759360.0000 - val_loss: 25154151251968.0000\n",
      "Epoch 67/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24306002165760.0000 - val_loss: 25148765765632.0000\n",
      "Epoch 68/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24300683788288.0000 - val_loss: 25143134912512.0000\n",
      "Epoch 69/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24295124238336.0000 - val_loss: 25137258692608.0000\n",
      "Epoch 70/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24289321418752.0000 - val_loss: 25131126620160.0000\n",
      "Epoch 71/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24283264843776.0000 - val_loss: 25124736598016.0000\n",
      "Epoch 72/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24276954513408.0000 - val_loss: 25118082334720.0000\n",
      "Epoch 73/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24270373650432.0000 - val_loss: 25111155441664.0000\n",
      "Epoch 74/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24263526449152.0000 - val_loss: 25103951724544.0000\n",
      "Epoch 75/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24256402423808.0000 - val_loss: 25096462794752.0000\n",
      "Epoch 76/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24249001574400.0000 - val_loss: 25088684457984.0000\n",
      "Epoch 77/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24241309220864.0000 - val_loss: 25080612519936.0000\n",
      "Epoch 78/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24233323266048.0000 - val_loss: 25072238592000.0000\n",
      "Epoch 79/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24225039515648.0000 - val_loss: 25063556382720.0000\n",
      "Epoch 80/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24216451678208.0000 - val_loss: 25054561697792.0000\n",
      "Epoch 81/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24207549267968.0000 - val_loss: 25045248245760.0000\n",
      "Epoch 82/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24198330187776.0000 - val_loss: 25035607638016.0000\n",
      "Epoch 83/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24188788146176.0000 - val_loss: 25025637777408.0000\n",
      "Epoch 84/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24178918948864.0000 - val_loss: 25015332372480.0000\n",
      "Epoch 85/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24168714207232.0000 - val_loss: 25004680937472.0000\n",
      "Epoch 86/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24158169726976.0000 - val_loss: 24993685569536.0000\n",
      "Epoch 87/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24147277119488.0000 - val_loss: 24982329491456.0000\n",
      "Epoch 88/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24136030093312.0000 - val_loss: 24970614800384.0000\n",
      "Epoch 89/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24124424454144.0000 - val_loss: 24958535204864.0000\n",
      "Epoch 90/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24112453910528.0000 - val_loss: 24946080219136.0000\n",
      "Epoch 91/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24100116365312.0000 - val_loss: 24933249843200.0000\n",
      "Epoch 92/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24087401332736.0000 - val_loss: 24920035688448.0000\n",
      "Epoch 93/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24074302521344.0000 - val_loss: 24906431463424.0000\n",
      "Epoch 94/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24060815736832.0000 - val_loss: 24892432973824.0000\n",
      "Epoch 95/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24046938882048.0000 - val_loss: 24878031831040.0000\n",
      "Epoch 96/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24032661471232.0000 - val_loss: 24863219646464.0000\n",
      "Epoch 97/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24017977212928.0000 - val_loss: 24848000614400.0000\n",
      "Epoch 98/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24002884009984.0000 - val_loss: 24832360054784.0000\n",
      "Epoch 99/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23987373473792.0000 - val_loss: 24816297967616.0000\n",
      "Epoch 100/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23971441410048.0000 - val_loss: 24799805964288.0000\n",
      "Epoch 101/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23955081527296.0000 - val_loss: 24782877753344.0000\n",
      "Epoch 102/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23938289631232.0000 - val_loss: 24765507043328.0000\n",
      "Epoch 103/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 23921057333248.0000 - val_loss: 24747693834240.0000\n",
      "Epoch 104/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23903382536192.0000 - val_loss: 24729425543168.0000\n",
      "Epoch 105/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23885256851456.0000 - val_loss: 24710704267264.0000\n",
      "Epoch 106/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23866676084736.0000 - val_loss: 24691517423616.0000\n",
      "Epoch 107/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23847636041728.0000 - val_loss: 24671860817920.0000\n",
      "Epoch 108/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23828128333824.0000 - val_loss: 24651736547328.0000\n",
      "Epoch 109/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23808152961024.0000 - val_loss: 24631129931776.0000\n",
      "Epoch 110/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23787699437568.0000 - val_loss: 24610040971264.0000\n",
      "Epoch 111/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23766763569152.0000 - val_loss: 24588463374336.0000\n",
      "Epoch 112/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23745339064320.0000 - val_loss: 24566390849536.0000\n",
      "Epoch 113/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23723425923072.0000 - val_loss: 24543819202560.0000\n",
      "Epoch 114/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23701015756800.0000 - val_loss: 24520748433408.0000\n",
      "Epoch 115/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23678102274048.0000 - val_loss: 24497161764864.0000\n",
      "Epoch 116/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23654681280512.0000 - val_loss: 24473063391232.0000\n",
      "Epoch 117/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23630748581888.0000 - val_loss: 24448449118208.0000\n",
      "Epoch 118/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23606304178176.0000 - val_loss: 24423308460032.0000\n",
      "Epoch 119/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23581333389312.0000 - val_loss: 24397639319552.0000\n",
      "Epoch 120/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23555836215296.0000 - val_loss: 24371435405312.0000\n",
      "Epoch 121/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23529808461824.0000 - val_loss: 24344694620160.0000\n",
      "Epoch 122/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23503243837440.0000 - val_loss: 24317414866944.0000\n",
      "Epoch 123/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23476138147840.0000 - val_loss: 24289583562752.0000\n",
      "Epoch 124/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23448491393024.0000 - val_loss: 24261200707584.0000\n",
      "Epoch 125/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23420295184384.0000 - val_loss: 24232262107136.0000\n",
      "Epoch 126/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23391541133312.0000 - val_loss: 24202765664256.0000\n",
      "Epoch 127/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23362233434112.0000 - val_loss: 24172702990336.0000\n",
      "Epoch 128/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23332359503872.0000 - val_loss: 24142071988224.0000\n",
      "Epoch 129/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23301921439744.0000 - val_loss: 24110866366464.0000\n",
      "Epoch 130/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23270912950272.0000 - val_loss: 24079086125056.0000\n",
      "Epoch 131/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23239329841152.0000 - val_loss: 24046720778240.0000\n",
      "Epoch 132/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 23207161626624.0000 - val_loss: 24013774520320.0000\n",
      "Epoch 133/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23174418792448.0000 - val_loss: 23980236865536.0000\n",
      "Epoch 134/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23141086658560.0000 - val_loss: 23946105716736.0000\n",
      "Epoch 135/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23107163127808.0000 - val_loss: 23911378976768.0000\n",
      "Epoch 136/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23072646103040.0000 - val_loss: 23876052451328.0000\n",
      "Epoch 137/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23037529292800.0000 - val_loss: 23840119848960.0000\n",
      "Epoch 138/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23001814794240.0000 - val_loss: 23803579072512.0000\n",
      "Epoch 139/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22965492121600.0000 - val_loss: 23766428024832.0000\n",
      "Epoch 140/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22928563372032.0000 - val_loss: 23728662511616.0000\n",
      "Epoch 141/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22891020156928.0000 - val_loss: 23690282532864.0000\n",
      "Epoch 142/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22852864573440.0000 - val_loss: 23651277602816.0000\n",
      "Epoch 143/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22814088232960.0000 - val_loss: 23611651915776.0000\n",
      "Epoch 144/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22774693232640.0000 - val_loss: 23571394985984.0000\n",
      "Epoch 145/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22734671183872.0000 - val_loss: 23530511007744.0000\n",
      "Epoch 146/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22694024183808.0000 - val_loss: 23488993689600.0000\n",
      "Epoch 147/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22652745940992.0000 - val_loss: 23446838837248.0000\n",
      "Epoch 148/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22610834358272.0000 - val_loss: 23404048547840.0000\n",
      "Epoch 149/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22568289435648.0000 - val_loss: 23360614432768.0000\n",
      "Epoch 150/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22525104881664.0000 - val_loss: 23316536492032.0000\n",
      "Epoch 151/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22481278599168.0000 - val_loss: 23271814725632.0000\n",
      "Epoch 152/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22436812685312.0000 - val_loss: 23226440744960.0000\n",
      "Epoch 153/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22391700848640.0000 - val_loss: 23180418744320.0000\n",
      "Epoch 154/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22345936797696.0000 - val_loss: 23133744529408.0000\n",
      "Epoch 155/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22299528921088.0000 - val_loss: 23086413905920.0000\n",
      "Epoch 156/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22252466733056.0000 - val_loss: 23038424776704.0000\n",
      "Epoch 157/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22204752330752.0000 - val_loss: 22989781336064.0000\n",
      "Epoch 158/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22156379422720.0000 - val_loss: 22940475195392.0000\n",
      "Epoch 159/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22107352203264.0000 - val_loss: 22890502160384.0000\n",
      "Epoch 160/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22057664380928.0000 - val_loss: 22839870619648.0000\n",
      "Epoch 161/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22007318052864.0000 - val_loss: 22788570087424.0000\n",
      "Epoch 162/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21956311121920.0000 - val_loss: 22736604758016.0000\n",
      "Epoch 163/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21904635199488.0000 - val_loss: 22683968339968.0000\n",
      "Epoch 164/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21852300771328.0000 - val_loss: 22630662930432.0000\n",
      "Epoch 165/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21799299448832.0000 - val_loss: 22576688529408.0000\n",
      "Epoch 166/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21745629134848.0000 - val_loss: 22522045136896.0000\n",
      "Epoch 167/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21691294023680.0000 - val_loss: 22466724364288.0000\n",
      "Epoch 168/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21636289921024.0000 - val_loss: 22410732503040.0000\n",
      "Epoch 169/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21580616826880.0000 - val_loss: 22354067456000.0000\n",
      "Epoch 170/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21524272644096.0000 - val_loss: 22296722931712.0000\n",
      "Epoch 171/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21467259469824.0000 - val_loss: 22238709415936.0000\n",
      "Epoch 172/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21409577304064.0000 - val_loss: 22180018520064.0000\n",
      "Epoch 173/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21351224049664.0000 - val_loss: 22120652341248.0000\n",
      "Epoch 174/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21292199706624.0000 - val_loss: 22060610879488.0000\n",
      "Epoch 175/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21232502177792.0000 - val_loss: 21999892037632.0000\n",
      "Epoch 176/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21172135657472.0000 - val_loss: 21938495815680.0000\n",
      "Epoch 177/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21111098048512.0000 - val_loss: 21876428505088.0000\n",
      "Epoch 178/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21049389350912.0000 - val_loss: 21813681717248.0000\n",
      "Epoch 179/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20987011661824.0000 - val_loss: 21750261743616.0000\n",
      "Epoch 180/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20923962884096.0000 - val_loss: 21686166487040.0000\n",
      "Epoch 181/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20860249309184.0000 - val_loss: 21621400141824.0000\n",
      "Epoch 182/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20795862548480.0000 - val_loss: 21555960610816.0000\n",
      "Epoch 183/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20730810990592.0000 - val_loss: 21489847894016.0000\n",
      "Epoch 184/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20665092538368.0000 - val_loss: 21423064088576.0000\n",
      "Epoch 185/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20598707191808.0000 - val_loss: 21355611291648.0000\n",
      "Epoch 186/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20531663339520.0000 - val_loss: 21287489503232.0000\n",
      "Epoch 187/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20463952592896.0000 - val_loss: 21218700820480.0000\n",
      "Epoch 188/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20395581243392.0000 - val_loss: 21149243146240.0000\n",
      "Epoch 189/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20326551388160.0000 - val_loss: 21079122771968.0000\n",
      "Epoch 190/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20256863027200.0000 - val_loss: 21008341794816.0000\n",
      "Epoch 191/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20186518257664.0000 - val_loss: 20936898117632.0000\n",
      "Epoch 192/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20115519176704.0000 - val_loss: 20864795934720.0000\n",
      "Epoch 193/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20043867881472.0000 - val_loss: 20792039440384.0000\n",
      "Epoch 194/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19971568566272.0000 - val_loss: 20718624440320.0000\n",
      "Epoch 195/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19898621231104.0000 - val_loss: 20644559323136.0000\n",
      "Epoch 196/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19825027973120.0000 - val_loss: 20569844088832.0000\n",
      "Epoch 197/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19750790889472.0000 - val_loss: 20494480834560.0000\n",
      "Epoch 198/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19675914174464.0000 - val_loss: 20418471657472.0000\n",
      "Epoch 199/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19600402022400.0000 - val_loss: 20341822849024.0000\n",
      "Epoch 200/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19524256530432.0000 - val_loss: 20264536506368.0000\n",
      "Epoch 201/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19447479795712.0000 - val_loss: 20186610532352.0000\n",
      "Epoch 202/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19370073915392.0000 - val_loss: 20108055412736.0000\n",
      "Epoch 203/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19292045180928.0000 - val_loss: 20028869050368.0000\n",
      "Epoch 204/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19213393592320.0000 - val_loss: 19949057736704.0000\n",
      "Epoch 205/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19134125441024.0000 - val_loss: 19868625666048.0000\n",
      "Epoch 206/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19054242824192.0000 - val_loss: 19787570741248.0000\n",
      "Epoch 207/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18973752033280.0000 - val_loss: 19705903448064.0000\n",
      "Epoch 208/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18892655165440.0000 - val_loss: 19623625883648.0000\n",
      "Epoch 209/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18810954317824.0000 - val_loss: 19540740145152.0000\n",
      "Epoch 210/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18728659976192.0000 - val_loss: 19457252524032.0000\n",
      "Epoch 211/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18645767946240.0000 - val_loss: 19373165117440.0000\n",
      "Epoch 212/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18562290810880.0000 - val_loss: 19288486313984.0000\n",
      "Epoch 213/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18478226472960.0000 - val_loss: 19203214016512.0000\n",
      "Epoch 214/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18393583321088.0000 - val_loss: 19117360807936.0000\n",
      "Epoch 215/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18308369743872.0000 - val_loss: 19030926688256.0000\n",
      "Epoch 216/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18222581547008.0000 - val_loss: 18943915851776.0000\n",
      "Epoch 217/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18136229216256.0000 - val_loss: 18856336687104.0000\n",
      "Epoch 218/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18049319043072.0000 - val_loss: 18768193388544.0000\n",
      "Epoch 219/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17961855221760.0000 - val_loss: 18679492247552.0000\n",
      "Epoch 220/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17873841946624.0000 - val_loss: 18590233264128.0000\n",
      "Epoch 221/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17785287606272.0000 - val_loss: 18500429021184.0000\n",
      "Epoch 222/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17696196395008.0000 - val_loss: 18410081615872.0000\n",
      "Epoch 223/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17606570409984.0000 - val_loss: 18319195242496.0000\n",
      "Epoch 224/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17516421185536.0000 - val_loss: 18227778289664.0000\n",
      "Epoch 225/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17425755013120.0000 - val_loss: 18135839145984.0000\n",
      "Epoch 226/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17334576087040.0000 - val_loss: 18043379908608.0000\n",
      "Epoch 227/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17242889650176.0000 - val_loss: 17950411063296.0000\n",
      "Epoch 228/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17150704091136.0000 - val_loss: 17856934707200.0000\n",
      "Epoch 229/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17058024652800.0000 - val_loss: 17762957131776.0000\n",
      "Epoch 230/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16964860772352.0000 - val_loss: 17668488822784.0000\n",
      "Epoch 231/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16871216644096.0000 - val_loss: 17573536071680.0000\n",
      "Epoch 232/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16777099608064.0000 - val_loss: 17478104121344.0000\n",
      "Epoch 233/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16682518052864.0000 - val_loss: 17382199263232.0000\n",
      "Epoch 234/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16587479318528.0000 - val_loss: 17285830934528.0000\n",
      "Epoch 235/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16491988647936.0000 - val_loss: 17189005426688.0000\n",
      "Epoch 236/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16396056526848.0000 - val_loss: 17091731128320.0000\n",
      "Epoch 237/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16299688198144.0000 - val_loss: 16994013282304.0000\n",
      "Epoch 238/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16202892050432.0000 - val_loss: 16895862374400.0000\n",
      "Epoch 239/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16105676472320.0000 - val_loss: 16797284696064.0000\n",
      "Epoch 240/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16008049852416.0000 - val_loss: 16698287587328.0000\n",
      "Epoch 241/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15910019530752.0000 - val_loss: 16598879436800.0000\n",
      "Epoch 242/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15811593895936.0000 - val_loss: 16499070730240.0000\n",
      "Epoch 243/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15712780288000.0000 - val_loss: 16398864613376.0000\n",
      "Epoch 244/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15613587095552.0000 - val_loss: 16298274717696.0000\n",
      "Epoch 245/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15514027950080.0000 - val_loss: 16197308383232.0000\n",
      "Epoch 246/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15414103900160.0000 - val_loss: 16095970852864.0000\n",
      "Epoch 247/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15313828577280.0000 - val_loss: 15994274709504.0000\n",
      "Epoch 248/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15213210370048.0000 - val_loss: 15892227293184.0000\n",
      "Epoch 249/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15112257667072.0000 - val_loss: 15789836992512.0000\n",
      "Epoch 250/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15010979905536.0000 - val_loss: 15687114293248.0000\n",
      "Epoch 251/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14909386522624.0000 - val_loss: 15584067584000.0000\n",
      "Epoch 252/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14807486955520.0000 - val_loss: 15480705253376.0000\n",
      "Epoch 253/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14705288544256.0000 - val_loss: 15377038835712.0000\n",
      "Epoch 254/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14602803871744.0000 - val_loss: 15273073573888.0000\n",
      "Epoch 255/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14500041326592.0000 - val_loss: 15168826245120.0000\n",
      "Epoch 256/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14397011394560.0000 - val_loss: 15064299995136.0000\n",
      "Epoch 257/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14293722464256.0000 - val_loss: 14959505309696.0000\n",
      "Epoch 258/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14190187118592.0000 - val_loss: 14854455820288.0000\n",
      "Epoch 259/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14086411649024.0000 - val_loss: 14749157818368.0000\n",
      "Epoch 260/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13982409687040.0000 - val_loss: 14643623886848.0000\n",
      "Epoch 261/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13878190669824.0000 - val_loss: 14537863462912.0000\n",
      "Epoch 262/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13773761937408.0000 - val_loss: 14431885983744.0000\n",
      "Epoch 263/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13669140267008.0000 - val_loss: 14325700886528.0000\n",
      "Epoch 264/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13564328804352.0000 - val_loss: 14219322851328.0000\n",
      "Epoch 265/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13459344326656.0000 - val_loss: 14112758169600.0000\n",
      "Epoch 266/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13354195222528.0000 - val_loss: 14006019424256.0000\n",
      "Epoch 267/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13248891977728.0000 - val_loss: 13899115003904.0000\n",
      "Epoch 268/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13143444029440.0000 - val_loss: 13792058540032.0000\n",
      "Epoch 269/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13037866057728.0000 - val_loss: 13684860518400.0000\n",
      "Epoch 270/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12932168548352.0000 - val_loss: 13577529327616.0000\n",
      "Epoch 271/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12826358841344.0000 - val_loss: 13470078599168.0000\n",
      "Epoch 272/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12720451616768.0000 - val_loss: 13362518818816.0000\n",
      "Epoch 273/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12614457360384.0000 - val_loss: 13254861520896.0000\n",
      "Epoch 274/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12508387606528.0000 - val_loss: 13147116142592.0000\n",
      "Epoch 275/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12402252840960.0000 - val_loss: 13039296315392.0000\n",
      "Epoch 276/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12296066695168.0000 - val_loss: 12931412525056.0000\n",
      "Epoch 277/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12189837557760.0000 - val_loss: 12823476305920.0000\n",
      "Epoch 278/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12083580108800.0000 - val_loss: 12715498143744.0000\n",
      "Epoch 279/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11977302736896.0000 - val_loss: 12607488524288.0000\n",
      "Epoch 280/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11871020122112.0000 - val_loss: 12499463176192.0000\n",
      "Epoch 281/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11764743798784.0000 - val_loss: 12391431536640.0000\n",
      "Epoch 282/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11658485301248.0000 - val_loss: 12283404091392.0000\n",
      "Epoch 283/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11552255115264.0000 - val_loss: 12175393423360.0000\n",
      "Epoch 284/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11446067920896.0000 - val_loss: 12067413164032.0000\n",
      "Epoch 285/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11339933155328.0000 - val_loss: 11959471702016.0000\n",
      "Epoch 286/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11233864450048.0000 - val_loss: 11851584765952.0000\n",
      "Epoch 287/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11127872290816.0000 - val_loss: 11743761793024.0000\n",
      "Epoch 288/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11021970309120.0000 - val_loss: 11636014317568.0000\n",
      "Epoch 289/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10916170039296.0000 - val_loss: 11528358068224.0000\n",
      "Epoch 290/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10810484064256.0000 - val_loss: 11420799336448.0000\n",
      "Epoch 291/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10704923918336.0000 - val_loss: 11313355948032.0000\n",
      "Epoch 292/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10599503233024.0000 - val_loss: 11206036291584.0000\n",
      "Epoch 293/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10494231445504.0000 - val_loss: 11098853998592.0000\n",
      "Epoch 294/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10389123235840.0000 - val_loss: 10991819554816.0000\n",
      "Epoch 295/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10284191186944.0000 - val_loss: 10884947640320.0000\n",
      "Epoch 296/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10179446833152.0000 - val_loss: 10778248740864.0000\n",
      "Epoch 297/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10074900660224.0000 - val_loss: 10671735439360.0000\n",
      "Epoch 298/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9970568396800.0000 - val_loss: 10565420318720.0000\n",
      "Epoch 299/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9866460528640.0000 - val_loss: 10459313864704.0000\n",
      "Epoch 300/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9762588590080.0000 - val_loss: 10353430757376.0000\n",
      "Epoch 301/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9658967261184.0000 - val_loss: 10247782531072.0000\n",
      "Epoch 302/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9555607027712.0000 - val_loss: 10142378622976.0000\n",
      "Epoch 303/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9452520472576.0000 - val_loss: 10037234761728.0000\n",
      "Epoch 304/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9349720178688.0000 - val_loss: 9932361433088.0000\n",
      "Epoch 305/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9247217680384.0000 - val_loss: 9827770171392.0000\n",
      "Epoch 306/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9145025560576.0000 - val_loss: 9723476705280.0000\n",
      "Epoch 307/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9043156402176.0000 - val_loss: 9619489423360.0000\n",
      "Epoch 308/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8941623836672.0000 - val_loss: 9515820908544.0000\n",
      "Epoch 309/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8840438349824.0000 - val_loss: 9412483743744.0000\n",
      "Epoch 310/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8739610951680.0000 - val_loss: 9309490511872.0000\n",
      "Epoch 311/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8639155273728.0000 - val_loss: 9206851698688.0000\n",
      "Epoch 312/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8539082850304.0000 - val_loss: 9104579887104.0000\n",
      "Epoch 313/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8439406788608.0000 - val_loss: 9002688708608.0000\n",
      "Epoch 314/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8340137574400.0000 - val_loss: 8901186551808.0000\n",
      "Epoch 315/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8241287266304.0000 - val_loss: 8800087048192.0000\n",
      "Epoch 316/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8142866874368.0000 - val_loss: 8699403304960.0000\n",
      "Epoch 317/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8044891602944.0000 - val_loss: 8599144759296.0000\n",
      "Epoch 318/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7947368792064.0000 - val_loss: 8499322945536.0000\n",
      "Epoch 319/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7850313646080.0000 - val_loss: 8399950970880.0000\n",
      "Epoch 320/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7753735077888.0000 - val_loss: 8301039845376.0000\n",
      "Epoch 321/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7657645670400.0000 - val_loss: 8202600054784.0000\n",
      "Epoch 322/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7562056433664.0000 - val_loss: 8104643133440.0000\n",
      "Epoch 323/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7466979426304.0000 - val_loss: 8007180615680.0000\n",
      "Epoch 324/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7372424085504.0000 - val_loss: 7910223511552.0000\n",
      "Epoch 325/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7278402469888.0000 - val_loss: 7813782306816.0000\n",
      "Epoch 326/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7184926638080.0000 - val_loss: 7717869060096.0000\n",
      "Epoch 327/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7092006551552.0000 - val_loss: 7622493208576.0000\n",
      "Epoch 328/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6999652696064.0000 - val_loss: 7527666810880.0000\n",
      "Epoch 329/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6907875557376.0000 - val_loss: 7433399828480.0000\n",
      "Epoch 330/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6816685621248.0000 - val_loss: 7339701174272.0000\n",
      "Epoch 331/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6726094422016.0000 - val_loss: 7246583955456.0000\n",
      "Epoch 332/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6636111396864.0000 - val_loss: 7154056036352.0000\n",
      "Epoch 333/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6546745982976.0000 - val_loss: 7062129999872.0000\n",
      "Epoch 334/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6458009190400.0000 - val_loss: 6970812137472.0000\n",
      "Epoch 335/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6369911504896.0000 - val_loss: 6880117129216.0000\n",
      "Epoch 336/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6282460266496.0000 - val_loss: 6790048645120.0000\n",
      "Epoch 337/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6195666485248.0000 - val_loss: 6700623462400.0000\n",
      "Epoch 338/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6109541695488.0000 - val_loss: 6611844202496.0000\n",
      "Epoch 339/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6024090615808.0000 - val_loss: 6523722399744.0000\n",
      "Epoch 340/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5939324256256.0000 - val_loss: 6436267491328.0000\n",
      "Epoch 341/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5855251529728.0000 - val_loss: 6349489438720.0000\n",
      "Epoch 342/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5771882397696.0000 - val_loss: 6263395581952.0000\n",
      "Epoch 343/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5689224724480.0000 - val_loss: 6177996406784.0000\n",
      "Epoch 344/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5607286374400.0000 - val_loss: 6093297680384.0000\n",
      "Epoch 345/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5526076260352.0000 - val_loss: 6009307267072.0000\n",
      "Epoch 346/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5445600673792.0000 - val_loss: 5926036176896.0000\n",
      "Epoch 347/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5365869051904.0000 - val_loss: 5843489652736.0000\n",
      "Epoch 348/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5286887161856.0000 - val_loss: 5761677131776.0000\n",
      "Epoch 349/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5208664965120.0000 - val_loss: 5680603332608.0000\n",
      "Epoch 350/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5131207704576.0000 - val_loss: 5600279265280.0000\n",
      "Epoch 351/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5054523244544.0000 - val_loss: 5520709124096.0000\n",
      "Epoch 352/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4978617876480.0000 - val_loss: 5441900773376.0000\n",
      "Epoch 353/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4903497891840.0000 - val_loss: 5363860504576.0000\n",
      "Epoch 354/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4829170106368.0000 - val_loss: 5286595133440.0000\n",
      "Epoch 355/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4755640811520.0000 - val_loss: 5210110427136.0000\n",
      "Epoch 356/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4682915250176.0000 - val_loss: 5134411628544.0000\n",
      "Epoch 357/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4610999189504.0000 - val_loss: 5059507126272.0000\n",
      "Epoch 358/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4539897872384.0000 - val_loss: 4985399017472.0000\n",
      "Epoch 359/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4469616541696.0000 - val_loss: 4912094642176.0000\n",
      "Epoch 360/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4400159916032.0000 - val_loss: 4839598718976.0000\n",
      "Epoch 361/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4331533762560.0000 - val_loss: 4767914393600.0000\n",
      "Epoch 362/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4263739916288.0000 - val_loss: 4697049006080.0000\n",
      "Epoch 363/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4196785717248.0000 - val_loss: 4627005177856.0000\n",
      "Epoch 364/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4130671951872.0000 - val_loss: 4557787103232.0000\n",
      "Epoch 365/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4065404387328.0000 - val_loss: 4489398976512.0000\n",
      "Epoch 366/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4000986169344.0000 - val_loss: 4421843419136.0000\n",
      "Epoch 367/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3937419395072.0000 - val_loss: 4355124625408.0000\n",
      "Epoch 368/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3874707472384.0000 - val_loss: 4289246265344.0000\n",
      "Epoch 369/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3812854071296.0000 - val_loss: 4224209649664.0000\n",
      "Epoch 370/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3751858929664.0000 - val_loss: 4160018710528.0000\n",
      "Epoch 371/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3691726241792.0000 - val_loss: 4096673710080.0000\n",
      "Epoch 372/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3632456007680.0000 - val_loss: 4034179104768.0000\n",
      "Epoch 373/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3574051373056.0000 - val_loss: 3972534632448.0000\n",
      "Epoch 374/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3516512337920.0000 - val_loss: 3911742652416.0000\n",
      "Epoch 375/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3459840475136.0000 - val_loss: 3851804213248.0000\n",
      "Epoch 376/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3404036308992.0000 - val_loss: 3792719577088.0000\n",
      "Epoch 377/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3349099053056.0000 - val_loss: 3734489530368.0000\n",
      "Epoch 378/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3295029493760.0000 - val_loss: 3677114859520.0000\n",
      "Epoch 379/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3241827893248.0000 - val_loss: 3620596088832.0000\n",
      "Epoch 380/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3189493727232.0000 - val_loss: 3564933218304.0000\n",
      "Epoch 381/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3138026209280.0000 - val_loss: 3510124675072.0000\n",
      "Epoch 382/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3087423504384.0000 - val_loss: 3456170721280.0000\n",
      "Epoch 383/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3037685088256.0000 - val_loss: 3403069521920.0000\n",
      "Epoch 384/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2988808077312.0000 - val_loss: 3350818717696.0000\n",
      "Epoch 385/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2940790898688.0000 - val_loss: 3299419619328.0000\n",
      "Epoch 386/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2893632241664.0000 - val_loss: 3248867770368.0000\n",
      "Epoch 387/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2847328698368.0000 - val_loss: 3199162908672.0000\n",
      "Epoch 388/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2801877909504.0000 - val_loss: 3150300839936.0000\n",
      "Epoch 389/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2757276467200.0000 - val_loss: 3102280253440.0000\n",
      "Epoch 390/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2713520701440.0000 - val_loss: 3055098265600.0000\n",
      "Epoch 391/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2670608777216.0000 - val_loss: 3008751730688.0000\n",
      "Epoch 392/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2628535451648.0000 - val_loss: 2963237765120.0000\n",
      "Epoch 393/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2587296530432.0000 - val_loss: 2918550077440.0000\n",
      "Epoch 394/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2546887294976.0000 - val_loss: 2874687356928.0000\n",
      "Epoch 395/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2507304075264.0000 - val_loss: 2831644622848.0000\n",
      "Epoch 396/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2468540841984.0000 - val_loss: 2789416632320.0000\n",
      "Epoch 397/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2430593400832.0000 - val_loss: 2748000239616.0000\n",
      "Epoch 398/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2393455722496.0000 - val_loss: 2707389153280.0000\n",
      "Epoch 399/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2357122039808.0000 - val_loss: 2667579441152.0000\n",
      "Epoch 400/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2321586585600.0000 - val_loss: 2628564287488.0000\n",
      "Epoch 401/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2286843068416.0000 - val_loss: 2590338711552.0000\n",
      "Epoch 402/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2252884934656.0000 - val_loss: 2552896946176.0000\n",
      "Epoch 403/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2219705106432.0000 - val_loss: 2516232175616.0000\n",
      "Epoch 404/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2187297292288.0000 - val_loss: 2480338370560.0000\n",
      "Epoch 405/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2155654152192.0000 - val_loss: 2445209763840.0000\n",
      "Epoch 406/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2124768608256.0000 - val_loss: 2410837966848.0000\n",
      "Epoch 407/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2094632534016.0000 - val_loss: 2377217736704.0000\n",
      "Epoch 408/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2065238458368.0000 - val_loss: 2344341209088.0000\n",
      "Epoch 409/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2036577992704.0000 - val_loss: 2312200257536.0000\n",
      "Epoch 410/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2008643141632.0000 - val_loss: 2280788066304.0000\n",
      "Epoch 411/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1981425778688.0000 - val_loss: 2250096771072.0000\n",
      "Epoch 412/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1954917253120.0000 - val_loss: 2220118245376.0000\n",
      "Epoch 413/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1929108258816.0000 - val_loss: 2190844624896.0000\n",
      "Epoch 414/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1903990931456.0000 - val_loss: 2162267652096.0000\n",
      "Epoch 415/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1879555440640.0000 - val_loss: 2134378151936.0000\n",
      "Epoch 416/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1855792480256.0000 - val_loss: 2107168391168.0000\n",
      "Epoch 417/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1832692350976.0000 - val_loss: 2080629325824.0000\n",
      "Epoch 418/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1810246533120.0000 - val_loss: 2054751518720.0000\n",
      "Epoch 419/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1788444672000.0000 - val_loss: 2029527105536.0000\n",
      "Epoch 420/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1767277068288.0000 - val_loss: 2004946518016.0000\n",
      "Epoch 421/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1746733891584.0000 - val_loss: 1981000450048.0000\n",
      "Epoch 422/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1726805311488.0000 - val_loss: 1957678940160.0000\n",
      "Epoch 423/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1707480449024.0000 - val_loss: 1934973206528.0000\n",
      "Epoch 424/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1688749998080.0000 - val_loss: 1912873156608.0000\n",
      "Epoch 425/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1670602686464.0000 - val_loss: 1891370008576.0000\n",
      "Epoch 426/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1653029208064.0000 - val_loss: 1870453407744.0000\n",
      "Epoch 427/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1636018683904.0000 - val_loss: 1850114310144.0000\n",
      "Epoch 428/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1619560628224.0000 - val_loss: 1830342361088.0000\n",
      "Epoch 429/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1603644686336.0000 - val_loss: 1811127468032.0000\n",
      "Epoch 430/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1588259454976.0000 - val_loss: 1792459800576.0000\n",
      "Epoch 431/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1573394972672.0000 - val_loss: 1774329659392.0000\n",
      "Epoch 432/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1559040229376.0000 - val_loss: 1756726296576.0000\n",
      "Epoch 433/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1545184739328.0000 - val_loss: 1739640799232.0000\n",
      "Epoch 434/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1531817885696.0000 - val_loss: 1723062288384.0000\n",
      "Epoch 435/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1518928920576.0000 - val_loss: 1706980933632.0000\n",
      "Epoch 436/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1506506571776.0000 - val_loss: 1691386380288.0000\n",
      "Epoch 437/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1494540877824.0000 - val_loss: 1676268797952.0000\n",
      "Epoch 438/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1483020828672.0000 - val_loss: 1661618356224.0000\n",
      "Epoch 439/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1471935807488.0000 - val_loss: 1647424831488.0000\n",
      "Epoch 440/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1461275328512.0000 - val_loss: 1633677344768.0000\n",
      "Epoch 441/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1451028250624.0000 - val_loss: 1620367638528.0000\n",
      "Epoch 442/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1441184743424.0000 - val_loss: 1607484440576.0000\n",
      "Epoch 443/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1431734452224.0000 - val_loss: 1595018313728.0000\n",
      "Epoch 444/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1422666235904.0000 - val_loss: 1582959427584.0000\n",
      "Epoch 445/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1413970526208.0000 - val_loss: 1571298344960.0000\n",
      "Epoch 446/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1405636968448.0000 - val_loss: 1560025628672.0000\n",
      "Epoch 447/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1397655076864.0000 - val_loss: 1549130792960.0000\n",
      "Epoch 448/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1390015283200.0000 - val_loss: 1538604269568.0000\n",
      "Epoch 449/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1382707101696.0000 - val_loss: 1528436883456.0000\n",
      "Epoch 450/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1375720964096.0000 - val_loss: 1518619852800.0000\n",
      "Epoch 451/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1369046908928.0000 - val_loss: 1509142953984.0000\n",
      "Epoch 452/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1362676023296.0000 - val_loss: 1499998978048.0000\n",
      "Epoch 453/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1356598738944.0000 - val_loss: 1491175997440.0000\n",
      "Epoch 454/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1350804701184.0000 - val_loss: 1482667196416.0000\n",
      "Epoch 455/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1345285652480.0000 - val_loss: 1474463006720.0000\n",
      "Epoch 456/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1340032024576.0000 - val_loss: 1466554515456.0000\n",
      "Epoch 457/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1335035166720.0000 - val_loss: 1458933727232.0000\n",
      "Epoch 458/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1330286034944.0000 - val_loss: 1451591335936.0000\n",
      "Epoch 459/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1325776109568.0000 - val_loss: 1444520132608.0000\n",
      "Epoch 460/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1321496739840.0000 - val_loss: 1437711335424.0000\n",
      "Epoch 461/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1317439668224.0000 - val_loss: 1431156817920.0000\n",
      "Epoch 462/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1313596899328.0000 - val_loss: 1424848846848.0000\n",
      "Epoch 463/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1309960175616.0000 - val_loss: 1418779426816.0000\n",
      "Epoch 464/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1306521763840.0000 - val_loss: 1412941479936.0000\n",
      "Epoch 465/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1303274192896.0000 - val_loss: 1407327404032.0000\n",
      "Epoch 466/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1300209598464.0000 - val_loss: 1401929465856.0000\n",
      "Epoch 467/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1297320771584.0000 - val_loss: 1396740456448.0000\n",
      "Epoch 468/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1294600503296.0000 - val_loss: 1391753297920.0000\n",
      "Epoch 469/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1292041584640.0000 - val_loss: 1386961960960.0000\n",
      "Epoch 470/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1289637724160.0000 - val_loss: 1382359367680.0000\n",
      "Epoch 471/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1287381843968.0000 - val_loss: 1377938571264.0000\n",
      "Epoch 472/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1285267652608.0000 - val_loss: 1373693542400.0000\n",
      "Epoch 473/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1283288727552.0000 - val_loss: 1369617727488.0000\n",
      "Epoch 474/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1281439170560.0000 - val_loss: 1365705228288.0000\n",
      "Epoch 475/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1279712559104.0000 - val_loss: 1361950670848.0000\n",
      "Epoch 476/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1278103650304.0000 - val_loss: 1358347501568.0000\n",
      "Epoch 477/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1276606283776.0000 - val_loss: 1354890346496.0000\n",
      "Epoch 478/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1275215609856.0000 - val_loss: 1351573569536.0000\n",
      "Epoch 479/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1273925861376.0000 - val_loss: 1348391796736.0000\n",
      "Epoch 480/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1272732450816.0000 - val_loss: 1345340440576.0000\n",
      "Epoch 481/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1271629479936.0000 - val_loss: 1342413602816.0000\n",
      "Epoch 482/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1270613409792.0000 - val_loss: 1339607089152.0000\n",
      "Epoch 483/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1269679128576.0000 - val_loss: 1336916049920.0000\n",
      "Epoch 484/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1268821917696.0000 - val_loss: 1334336028672.0000\n",
      "Epoch 485/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1268037582848.0000 - val_loss: 1331862306816.0000\n",
      "Epoch 486/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1267322454016.0000 - val_loss: 1329490690048.0000\n",
      "Epoch 487/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1266672074752.0000 - val_loss: 1327216852992.0000\n",
      "Epoch 488/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1266083037184.0000 - val_loss: 1325037256704.0000\n",
      "Epoch 489/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1265551147008.0000 - val_loss: 1322947444736.0000\n",
      "Epoch 490/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1265073258496.0000 - val_loss: 1320944271360.0000\n",
      "Epoch 491/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264645963776.0000 - val_loss: 1319023673344.0000\n",
      "Epoch 492/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264265854976.0000 - val_loss: 1317181849600.0000\n",
      "Epoch 493/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263929786368.0000 - val_loss: 1315416309760.0000\n",
      "Epoch 494/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1263635136512.0000 - val_loss: 1313723121664.0000\n",
      "Epoch 495/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263378628608.0000 - val_loss: 1312099270656.0000\n",
      "Epoch 496/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263157903360.0000 - val_loss: 1310541873152.0000\n",
      "Epoch 497/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262970339328.0000 - val_loss: 1309048176640.0000\n",
      "Epoch 498/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262813184000.0000 - val_loss: 1307614904320.0000\n",
      "Epoch 499/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262684340224.0000 - val_loss: 1306239696896.0000\n",
      "Epoch 500/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262581317632.0000 - val_loss: 1304919801856.0000\n",
      "Epoch 501/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262502281216.0000 - val_loss: 1303653122048.0000\n",
      "Epoch 502/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262445264896.0000 - val_loss: 1302436904960.0000\n",
      "Epoch 503/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262408040448.0000 - val_loss: 1301269053440.0000\n",
      "Epoch 504/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262388641792.0000 - val_loss: 1300147339264.0000\n",
      "Epoch 505/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262385758208.0000 - val_loss: 1299069272064.0000\n",
      "Epoch 506/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262397816832.0000 - val_loss: 1298033410048.0000\n",
      "Epoch 507/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262422982656.0000 - val_loss: 1297037524992.0000\n",
      "Epoch 508/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262460076032.0000 - val_loss: 1296080044032.0000\n",
      "Epoch 509/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262507261952.0000 - val_loss: 1295159132160.0000\n",
      "Epoch 510/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262563491840.0000 - val_loss: 1294272823296.0000\n",
      "Epoch 511/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262627848192.0000 - val_loss: 1293419413504.0000\n",
      "Epoch 512/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262698889216.0000 - val_loss: 1292597592064.0000\n",
      "Epoch 513/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1262775828480.0000 - val_loss: 1291806048256.0000\n",
      "Epoch 514/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262857224192.0000 - val_loss: 1291043209216.0000\n",
      "Epoch 515/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262942420992.0000 - val_loss: 1290307633152.0000\n",
      "Epoch 516/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263030370304.0000 - val_loss: 1289598140416.0000\n",
      "Epoch 517/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263120678912.0000 - val_loss: 1288913551360.0000\n",
      "Epoch 518/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263212036096.0000 - val_loss: 1288252686336.0000\n",
      "Epoch 519/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263304572928.0000 - val_loss: 1287614103552.0000\n",
      "Epoch 520/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263396716544.0000 - val_loss: 1286997147648.0000\n",
      "Epoch 521/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263488466944.0000 - val_loss: 1286400770048.0000\n",
      "Epoch 522/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263578644480.0000 - val_loss: 1285823660032.0000\n",
      "Epoch 523/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263667773440.0000 - val_loss: 1285265293312.0000\n",
      "Epoch 524/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263754674176.0000 - val_loss: 1284724883456.0000\n",
      "Epoch 525/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263838953472.0000 - val_loss: 1284201119744.0000\n",
      "Epoch 526/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263920611328.0000 - val_loss: 1283693477888.0000\n",
      "Epoch 527/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263998861312.0000 - val_loss: 1283201433600.0000\n",
      "Epoch 528/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264073441280.0000 - val_loss: 1282723676160.0000\n",
      "Epoch 529/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264144482304.0000 - val_loss: 1282260336640.0000\n",
      "Epoch 530/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264211066880.0000 - val_loss: 1281810235392.0000\n",
      "Epoch 531/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264273457152.0000 - val_loss: 1281372323840.0000\n",
      "Epoch 532/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1264331522048.0000 - val_loss: 1280947388416.0000\n",
      "Epoch 533/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264384868352.0000 - val_loss: 1280533331968.0000\n",
      "Epoch 534/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264433627136.0000 - val_loss: 1280130809856.0000\n",
      "Epoch 535/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264477143040.0000 - val_loss: 1279738511360.0000\n",
      "Epoch 536/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264515940352.0000 - val_loss: 1279356436480.0000\n",
      "Epoch 537/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264549232640.0000 - val_loss: 1278984060928.0000\n",
      "Epoch 538/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264577544192.0000 - val_loss: 1278620729344.0000\n",
      "Epoch 539/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264600743936.0000 - val_loss: 1278266572800.0000\n",
      "Epoch 540/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264618831872.0000 - val_loss: 1277920280576.0000\n",
      "Epoch 541/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264631676928.0000 - val_loss: 1277582508032.0000\n",
      "Epoch 542/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264639016960.0000 - val_loss: 1277252468736.0000\n",
      "Epoch 543/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1264640983040.0000 - val_loss: 1276929638400.0000\n",
      "Epoch 544/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264637706240.0000 - val_loss: 1276614148096.0000\n",
      "Epoch 545/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264629579776.0000 - val_loss: 1276305080320.0000\n",
      "Epoch 546/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264616210432.0000 - val_loss: 1276002566144.0000\n",
      "Epoch 547/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264597860352.0000 - val_loss: 1275706474496.0000\n",
      "Epoch 548/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264574136320.0000 - val_loss: 1275416281088.0000\n",
      "Epoch 549/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264545693696.0000 - val_loss: 1275131854848.0000\n",
      "Epoch 550/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264512401408.0000 - val_loss: 1274852933632.0000\n",
      "Epoch 551/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264474128384.0000 - val_loss: 1274578993152.0000\n",
      "Epoch 552/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264431005696.0000 - val_loss: 1274310426624.0000\n",
      "Epoch 553/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264383164416.0000 - val_loss: 1274047102976.0000\n",
      "Epoch 554/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264330604544.0000 - val_loss: 1273788104704.0000\n",
      "Epoch 555/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1264273850368.0000 - val_loss: 1273533562880.0000\n",
      "Epoch 556/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264212639744.0000 - val_loss: 1273283477504.0000\n",
      "Epoch 557/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264147234816.0000 - val_loss: 1273037717504.0000\n",
      "Epoch 558/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264077766656.0000 - val_loss: 1272795889664.0000\n",
      "Epoch 559/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264004104192.0000 - val_loss: 1272558125056.0000\n",
      "Epoch 560/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263926247424.0000 - val_loss: 1272324292608.0000\n",
      "Epoch 561/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263844458496.0000 - val_loss: 1272093736960.0000\n",
      "Epoch 562/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263758999552.0000 - val_loss: 1271866982400.0000\n",
      "Epoch 563/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263670001664.0000 - val_loss: 1271643766784.0000\n",
      "Epoch 564/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263576940544.0000 - val_loss: 1271423827968.0000\n",
      "Epoch 565/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263480602624.0000 - val_loss: 1271206641664.0000\n",
      "Epoch 566/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263381250048.0000 - val_loss: 1270992732160.0000\n",
      "Epoch 567/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263278489600.0000 - val_loss: 1270782099456.0000\n",
      "Epoch 568/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263172583424.0000 - val_loss: 1270573957120.0000\n",
      "Epoch 569/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1263063400448.0000 - val_loss: 1270368960512.0000\n",
      "Epoch 570/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262951333888.0000 - val_loss: 1270166454272.0000\n",
      "Epoch 571/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262836908032.0000 - val_loss: 1269966831616.0000\n",
      "Epoch 572/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1262719336448.0000 - val_loss: 1269769699328.0000\n",
      "Epoch 573/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262599143424.0000 - val_loss: 1269575057408.0000\n",
      "Epoch 574/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262476460032.0000 - val_loss: 1269382905856.0000\n",
      "Epoch 575/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262351417344.0000 - val_loss: 1269192851456.0000\n",
      "Epoch 576/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262223491072.0000 - val_loss: 1269005418496.0000\n",
      "Epoch 577/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262093991936.0000 - val_loss: 1268820082688.0000\n",
      "Epoch 578/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1261961871360.0000 - val_loss: 1268636975104.0000\n",
      "Epoch 579/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1261827784704.0000 - val_loss: 1268456095744.0000\n",
      "Epoch 580/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1261691469824.0000 - val_loss: 1268276920320.0000\n",
      "Epoch 581/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1261553844224.0000 - val_loss: 1268100104192.0000\n",
      "Epoch 582/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1261413859328.0000 - val_loss: 1267924992000.0000\n",
      "Epoch 583/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1261272432640.0000 - val_loss: 1267751976960.0000\n",
      "Epoch 584/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1261129039872.0000 - val_loss: 1267580928000.0000\n",
      "Epoch 585/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1260983943168.0000 - val_loss: 1267411451904.0000\n",
      "Epoch 586/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1260837797888.0000 - val_loss: 1267243941888.0000\n",
      "Epoch 587/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1260690210816.0000 - val_loss: 1267078135808.0000\n",
      "Epoch 588/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1260541181952.0000 - val_loss: 1266914426880.0000\n",
      "Epoch 589/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1260390187008.0000 - val_loss: 1266751766528.0000\n",
      "Epoch 590/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1260238667776.0000 - val_loss: 1266591072256.0000\n",
      "Epoch 591/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1260085313536.0000 - val_loss: 1266431950848.0000\n",
      "Epoch 592/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1259931303936.0000 - val_loss: 1266274140160.0000\n",
      "Epoch 593/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1259776376832.0000 - val_loss: 1266118164480.0000\n",
      "Epoch 594/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1259620270080.0000 - val_loss: 1265963368448.0000\n",
      "Epoch 595/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1259463507968.0000 - val_loss: 1265810276352.0000\n",
      "Epoch 596/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1259305566208.0000 - val_loss: 1265658494976.0000\n",
      "Epoch 597/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1259146838016.0000 - val_loss: 1265508024320.0000\n",
      "Epoch 598/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1258987454464.0000 - val_loss: 1265358995456.0000\n",
      "Epoch 599/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1258827415552.0000 - val_loss: 1265211408384.0000\n",
      "Epoch 600/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1258666721280.0000 - val_loss: 1265065132032.0000\n",
      "Epoch 601/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1258505109504.0000 - val_loss: 1264920297472.0000\n",
      "Epoch 602/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1258343366656.0000 - val_loss: 1264776380416.0000\n",
      "Epoch 603/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1258180968448.0000 - val_loss: 1264634036224.0000\n",
      "Epoch 604/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1258017652736.0000 - val_loss: 1264492609536.0000\n",
      "Epoch 605/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1257854205952.0000 - val_loss: 1264352886784.0000\n",
      "Epoch 606/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1257690234880.0000 - val_loss: 1264214212608.0000\n",
      "Epoch 607/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1257526132736.0000 - val_loss: 1264076193792.0000\n",
      "Epoch 608/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1257361637376.0000 - val_loss: 1263939747840.0000\n",
      "Epoch 609/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1257196748800.0000 - val_loss: 1263804350464.0000\n",
      "Epoch 610/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1257031729152.0000 - val_loss: 1263669870592.0000\n",
      "Epoch 611/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1256866447360.0000 - val_loss: 1263536963584.0000\n",
      "Epoch 612/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1256700903424.0000 - val_loss: 1263404843008.0000\n",
      "Epoch 613/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1256535097344.0000 - val_loss: 1263273771008.0000\n",
      "Epoch 614/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1256369291264.0000 - val_loss: 1263143747584.0000\n",
      "Epoch 615/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1256203091968.0000 - val_loss: 1263014903808.0000\n",
      "Epoch 616/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1256036761600.0000 - val_loss: 1262886977536.0000\n",
      "Epoch 617/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1255870562304.0000 - val_loss: 1262760099840.0000\n",
      "Epoch 618/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1255704231936.0000 - val_loss: 1262634270720.0000\n",
      "Epoch 619/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1255537508352.0000 - val_loss: 1262509359104.0000\n",
      "Epoch 620/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1255370784768.0000 - val_loss: 1262385364992.0000\n",
      "Epoch 621/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1255204585472.0000 - val_loss: 1262262157312.0000\n",
      "Epoch 622/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1255038386176.0000 - val_loss: 1262139998208.0000\n",
      "Epoch 623/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1254872317952.0000 - val_loss: 1262018625536.0000\n",
      "Epoch 624/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1254706118656.0000 - val_loss: 1261898563584.0000\n",
      "Epoch 625/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1254540443648.0000 - val_loss: 1261778894848.0000\n",
      "Epoch 626/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1254374244352.0000 - val_loss: 1261660405760.0000\n",
      "Epoch 627/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1254208700416.0000 - val_loss: 1261542703104.0000\n",
      "Epoch 628/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1254043287552.0000 - val_loss: 1261425655808.0000\n",
      "Epoch 629/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1253877743616.0000 - val_loss: 1261309657088.0000\n",
      "Epoch 630/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1253712855040.0000 - val_loss: 1261194444800.0000\n",
      "Epoch 631/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1253547573248.0000 - val_loss: 1261080150016.0000\n",
      "Epoch 632/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1253382553600.0000 - val_loss: 1260966641664.0000\n",
      "Epoch 633/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1253218058240.0000 - val_loss: 1260853657600.0000\n",
      "Epoch 634/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1253053693952.0000 - val_loss: 1260741853184.0000\n",
      "Epoch 635/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1252889329664.0000 - val_loss: 1260630704128.0000\n",
      "Epoch 636/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1252725751808.0000 - val_loss: 1260520472576.0000\n",
      "Epoch 637/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1252561911808.0000 - val_loss: 1260410503168.0000\n",
      "Epoch 638/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1252398596096.0000 - val_loss: 1260301582336.0000\n",
      "Epoch 639/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1252235804672.0000 - val_loss: 1260193447936.0000\n",
      "Epoch 640/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1252073013248.0000 - val_loss: 1260086231040.0000\n",
      "Epoch 641/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1251910615040.0000 - val_loss: 1259979538432.0000\n",
      "Epoch 642/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1251748478976.0000 - val_loss: 1259873501184.0000\n",
      "Epoch 643/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1251586867200.0000 - val_loss: 1259768250368.0000\n",
      "Epoch 644/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1251425255424.0000 - val_loss: 1259664048128.0000\n",
      "Epoch 645/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1251264036864.0000 - val_loss: 1259559976960.0000\n",
      "Epoch 646/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1251103342592.0000 - val_loss: 1259456954368.0000\n",
      "Epoch 647/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1250942779392.0000 - val_loss: 1259354456064.0000\n",
      "Epoch 648/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1250782478336.0000 - val_loss: 1259252875264.0000\n",
      "Epoch 649/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1250622701568.0000 - val_loss: 1259151687680.0000\n",
      "Epoch 650/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1250463318016.0000 - val_loss: 1259051548672.0000\n",
      "Epoch 651/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1250304196608.0000 - val_loss: 1258951802880.0000\n",
      "Epoch 652/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1250145075200.0000 - val_loss: 1258852581376.0000\n",
      "Epoch 653/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1249986871296.0000 - val_loss: 1258754277376.0000\n",
      "Epoch 654/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1249829191680.0000 - val_loss: 1258656366592.0000\n",
      "Epoch 655/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1249671643136.0000 - val_loss: 1258559242240.0000\n",
      "Epoch 656/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1249514225664.0000 - val_loss: 1258462511104.0000\n",
      "Epoch 657/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1249357594624.0000 - val_loss: 1258366435328.0000\n",
      "Epoch 658/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1249201225728.0000 - val_loss: 1258271277056.0000\n",
      "Epoch 659/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1249045381120.0000 - val_loss: 1258176643072.0000\n",
      "Epoch 660/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1248889667584.0000 - val_loss: 1258082140160.0000\n",
      "Epoch 661/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1248734478336.0000 - val_loss: 1257988816896.0000\n",
      "Epoch 662/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1248579551232.0000 - val_loss: 1257895886848.0000\n",
      "Epoch 663/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1248425148416.0000 - val_loss: 1257803481088.0000\n",
      "Epoch 664/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1248271138816.0000 - val_loss: 1257711861760.0000\n",
      "Epoch 665/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1248117260288.0000 - val_loss: 1257620766720.0000\n",
      "Epoch 666/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1247964168192.0000 - val_loss: 1257530195968.0000\n",
      "Epoch 667/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1247811338240.0000 - val_loss: 1257440149504.0000\n",
      "Epoch 668/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1247659294720.0000 - val_loss: 1257350496256.0000\n",
      "Epoch 669/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1247507120128.0000 - val_loss: 1257261891584.0000\n",
      "Epoch 670/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1247355731968.0000 - val_loss: 1257173417984.0000\n",
      "Epoch 671/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1247204605952.0000 - val_loss: 1257085468672.0000\n",
      "Epoch 672/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1247054004224.0000 - val_loss: 1256998305792.0000\n",
      "Epoch 673/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1246903795712.0000 - val_loss: 1256911536128.0000\n",
      "Epoch 674/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1246753849344.0000 - val_loss: 1256825290752.0000\n",
      "Epoch 675/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1246604296192.0000 - val_loss: 1256739962880.0000\n",
      "Epoch 676/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1246455136256.0000 - val_loss: 1256654766080.0000\n",
      "Epoch 677/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1246306500608.0000 - val_loss: 1256570093568.0000\n",
      "Epoch 678/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1246158258176.0000 - val_loss: 1256486207488.0000\n",
      "Epoch 679/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1246010277888.0000 - val_loss: 1256402583552.0000\n",
      "Epoch 680/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1245862690816.0000 - val_loss: 1256319614976.0000\n",
      "Epoch 681/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1245715890176.0000 - val_loss: 1256237039616.0000\n",
      "Epoch 682/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1245569482752.0000 - val_loss: 1256154988544.0000\n",
      "Epoch 683/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1245423599616.0000 - val_loss: 1256073461760.0000\n",
      "Epoch 684/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1245277847552.0000 - val_loss: 1255992459264.0000\n",
      "Epoch 685/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1245132619776.0000 - val_loss: 1255911849984.0000\n",
      "Epoch 686/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1244987785216.0000 - val_loss: 1255831896064.0000\n",
      "Epoch 687/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1244843343872.0000 - val_loss: 1255752335360.0000\n",
      "Epoch 688/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1244699557888.0000 - val_loss: 1255673298944.0000\n",
      "Epoch 689/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1244556034048.0000 - val_loss: 1255594524672.0000\n",
      "Epoch 690/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1244412903424.0000 - val_loss: 1255516405760.0000\n",
      "Epoch 691/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1244270166016.0000 - val_loss: 1255438680064.0000\n",
      "Epoch 692/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1244127952896.0000 - val_loss: 1255361347584.0000\n",
      "Epoch 693/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1243985870848.0000 - val_loss: 1255284932608.0000\n",
      "Epoch 694/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1243844444160.0000 - val_loss: 1255208648704.0000\n",
      "Epoch 695/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1243703279616.0000 - val_loss: 1255132758016.0000\n",
      "Epoch 696/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1243562639360.0000 - val_loss: 1255057522688.0000\n",
      "Epoch 697/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1243422130176.0000 - val_loss: 1254982811648.0000\n",
      "Epoch 698/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1243281752064.0000 - val_loss: 1254908231680.0000\n",
      "Epoch 699/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1243142160384.0000 - val_loss: 1254834438144.0000\n",
      "Epoch 700/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1243002830848.0000 - val_loss: 1254760906752.0000\n",
      "Epoch 701/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1242864025600.0000 - val_loss: 1254687637504.0000\n",
      "Epoch 702/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1242725744640.0000 - val_loss: 1254615285760.0000\n",
      "Epoch 703/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1242587856896.0000 - val_loss: 1254542934016.0000\n",
      "Epoch 704/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1242450231296.0000 - val_loss: 1254471368704.0000\n",
      "Epoch 705/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1242313261056.0000 - val_loss: 1254399934464.0000\n",
      "Epoch 706/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1242176815104.0000 - val_loss: 1254328893440.0000\n",
      "Epoch 707/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1242040631296.0000 - val_loss: 1254258376704.0000\n",
      "Epoch 708/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1241904578560.0000 - val_loss: 1254188253184.0000\n",
      "Epoch 709/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1241768919040.0000 - val_loss: 1254118522880.0000\n",
      "Epoch 710/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1241633390592.0000 - val_loss: 1254049447936.0000\n",
      "Epoch 711/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1241498648576.0000 - val_loss: 1253980504064.0000\n",
      "Epoch 712/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1241364561920.0000 - val_loss: 1253912084480.0000\n",
      "Epoch 713/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1241230737408.0000 - val_loss: 1253844058112.0000\n",
      "Epoch 714/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1241097437184.0000 - val_loss: 1253776293888.0000\n",
      "Epoch 715/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1240964530176.0000 - val_loss: 1253708922880.0000\n",
      "Epoch 716/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1240832147456.0000 - val_loss: 1253642076160.0000\n",
      "Epoch 717/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1240700026880.0000 - val_loss: 1253575622656.0000\n",
      "Epoch 718/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1240568037376.0000 - val_loss: 1253509431296.0000\n",
      "Epoch 719/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1240436834304.0000 - val_loss: 1253443764224.0000\n",
      "Epoch 720/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1240306024448.0000 - val_loss: 1253378228224.0000\n",
      "Epoch 721/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1240175476736.0000 - val_loss: 1253313216512.0000\n",
      "Epoch 722/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1240045322240.0000 - val_loss: 1253248598016.0000\n",
      "Epoch 723/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1239915692032.0000 - val_loss: 1253184110592.0000\n",
      "Epoch 724/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1239786455040.0000 - val_loss: 1253120540672.0000\n",
      "Epoch 725/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1239657218048.0000 - val_loss: 1253057101824.0000\n",
      "Epoch 726/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1239528505344.0000 - val_loss: 1252993794048.0000\n",
      "Epoch 727/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1239400448000.0000 - val_loss: 1252931272704.0000\n",
      "Epoch 728/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1239272521728.0000 - val_loss: 1252868882432.0000\n",
      "Epoch 729/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1239144988672.0000 - val_loss: 1252806623232.0000\n",
      "Epoch 730/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1239017979904.0000 - val_loss: 1252745019392.0000\n",
      "Epoch 731/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1238891495424.0000 - val_loss: 1252683677696.0000\n",
      "Epoch 732/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1238764879872.0000 - val_loss: 1252622729216.0000\n",
      "Epoch 733/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1238639050752.0000 - val_loss: 1252562173952.0000\n",
      "Epoch 734/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1238513614848.0000 - val_loss: 1252501880832.0000\n",
      "Epoch 735/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1238388441088.0000 - val_loss: 1252442243072.0000\n",
      "Epoch 736/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1238263529472.0000 - val_loss: 1252382736384.0000\n",
      "Epoch 737/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1238139273216.0000 - val_loss: 1252323360768.0000\n",
      "Epoch 738/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1238015279104.0000 - val_loss: 1252264509440.0000\n",
      "Epoch 739/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1237891547136.0000 - val_loss: 1252206182400.0000\n",
      "Epoch 740/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1237768077312.0000 - val_loss: 1252148117504.0000\n",
      "Epoch 741/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1237644869632.0000 - val_loss: 1252090445824.0000\n",
      "Epoch 742/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1237522317312.0000 - val_loss: 1252032905216.0000\n",
      "Epoch 743/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1237400551424.0000 - val_loss: 1251975495680.0000\n",
      "Epoch 744/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1237278654464.0000 - val_loss: 1251918872576.0000\n",
      "Epoch 745/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1237157150720.0000 - val_loss: 1251862118400.0000\n",
      "Epoch 746/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1237036171264.0000 - val_loss: 1251805757440.0000\n",
      "Epoch 747/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1236915585024.0000 - val_loss: 1251749920768.0000\n",
      "Epoch 748/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1236795523072.0000 - val_loss: 1251694215168.0000\n",
      "Epoch 749/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1236675592192.0000 - val_loss: 1251639033856.0000\n",
      "Epoch 750/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1236556185600.0000 - val_loss: 1251583983616.0000\n",
      "Epoch 751/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1236437172224.0000 - val_loss: 1251529326592.0000\n",
      "Epoch 752/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1236318683136.0000 - val_loss: 1251474931712.0000\n",
      "Epoch 753/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1236200325120.0000 - val_loss: 1251420930048.0000\n",
      "Epoch 754/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1236082491392.0000 - val_loss: 1251367190528.0000\n",
      "Epoch 755/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1235964788736.0000 - val_loss: 1251313844224.0000\n",
      "Epoch 756/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1235847348224.0000 - val_loss: 1251260628992.0000\n",
      "Epoch 757/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1235730563072.0000 - val_loss: 1251207938048.0000\n",
      "Epoch 758/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1235613908992.0000 - val_loss: 1251155247104.0000\n",
      "Epoch 759/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1235497648128.0000 - val_loss: 1251103211520.0000\n",
      "Epoch 760/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1235381649408.0000 - val_loss: 1251051175936.0000\n",
      "Epoch 761/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1235266174976.0000 - val_loss: 1250999533568.0000\n",
      "Epoch 762/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1235150962688.0000 - val_loss: 1250948153344.0000\n",
      "Epoch 763/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1235036405760.0000 - val_loss: 1250897166336.0000\n",
      "Epoch 764/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1234922110976.0000 - val_loss: 1250846441472.0000\n",
      "Epoch 765/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1234807947264.0000 - val_loss: 1250795847680.0000\n",
      "Epoch 766/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1234694045696.0000 - val_loss: 1250745647104.0000\n",
      "Epoch 767/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1234580668416.0000 - val_loss: 1250695970816.0000\n",
      "Epoch 768/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1234467553280.0000 - val_loss: 1250646556672.0000\n",
      "Epoch 769/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1234354438144.0000 - val_loss: 1250597404672.0000\n",
      "Epoch 770/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1234241716224.0000 - val_loss: 1250548252672.0000\n",
      "Epoch 771/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1234129256448.0000 - val_loss: 1250499756032.0000\n",
      "Epoch 772/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1234017452032.0000 - val_loss: 1250451259392.0000\n",
      "Epoch 773/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1233906171904.0000 - val_loss: 1250403024896.0000\n",
      "Epoch 774/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1233795022848.0000 - val_loss: 1250354921472.0000\n",
      "Epoch 775/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1233684398080.0000 - val_loss: 1250307473408.0000\n",
      "Epoch 776/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1233573642240.0000 - val_loss: 1250260025344.0000\n",
      "Epoch 777/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1233463410688.0000 - val_loss: 1250213101568.0000\n",
      "Epoch 778/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1233353834496.0000 - val_loss: 1250166177792.0000\n",
      "Epoch 779/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1233244651520.0000 - val_loss: 1250119254016.0000\n",
      "Epoch 780/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1233135730688.0000 - val_loss: 1250072854528.0000\n",
      "Epoch 781/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1233027334144.0000 - val_loss: 1250026586112.0000\n",
      "Epoch 782/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1232919068672.0000 - val_loss: 1249980710912.0000\n",
      "Epoch 783/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1232811196416.0000 - val_loss: 1249935097856.0000\n",
      "Epoch 784/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1232703848448.0000 - val_loss: 1249889746944.0000\n",
      "Epoch 785/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1232596631552.0000 - val_loss: 1249844527104.0000\n",
      "Epoch 786/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1232489807872.0000 - val_loss: 1249799700480.0000\n",
      "Epoch 787/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1232383246336.0000 - val_loss: 1249754873856.0000\n",
      "Epoch 788/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1232276815872.0000 - val_loss: 1249710440448.0000\n",
      "Epoch 789/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1232170909696.0000 - val_loss: 1249666400256.0000\n",
      "Epoch 790/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1232065134592.0000 - val_loss: 1249622491136.0000\n",
      "Epoch 791/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1231959883776.0000 - val_loss: 1249578713088.0000\n",
      "Epoch 792/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1231855157248.0000 - val_loss: 1249535328256.0000\n",
      "Epoch 793/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1231750692864.0000 - val_loss: 1249492205568.0000\n",
      "Epoch 794/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1231646359552.0000 - val_loss: 1249449345024.0000\n",
      "Epoch 795/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1231542157312.0000 - val_loss: 1249407008768.0000\n",
      "Epoch 796/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1231438086144.0000 - val_loss: 1249364541440.0000\n",
      "Epoch 797/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1231334408192.0000 - val_loss: 1249322205184.0000\n",
      "Epoch 798/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1231230861312.0000 - val_loss: 1249280393216.0000\n",
      "Epoch 799/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1231128363008.0000 - val_loss: 1249238450176.0000\n",
      "Epoch 800/800\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1231025995776.0000 - val_loss: 1249196769280.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x176d113f0>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using validation again for better metrics and optimization\n",
    "model.fit(x=X_train, y=y_train, epochs=800, validation_data=(X_val, y_val), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training metrics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data evaluation:\n",
      "1343154814976.0\n",
      "\n",
      "Train data evaluation:\n",
      "1102091386880.0\n"
     ]
    }
   ],
   "source": [
    "# compare test error values to training error values\n",
    "# the model is often good when these error values are similar\n",
    "# even if you training metrics above didn't overlap\n",
    "# you might still get very close values in evaluation => more important\n",
    "\n",
    "# compare the final model loss/evaluation values\n",
    "print(\"Test data evaluation:\")\n",
    "print(model.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"\\nTrain data evaluation:\")\n",
    "print(model.evaluate(X_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Make some test predictions to see what kind of mistakes the model makes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test True Y</th>\n",
       "      <th>Model Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7140000</td>\n",
       "      <td>5635887.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4620000</td>\n",
       "      <td>4670689.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8855000</td>\n",
       "      <td>7030397.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2100000</td>\n",
       "      <td>2765856.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4095000</td>\n",
       "      <td>3997377.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3773000</td>\n",
       "      <td>4920238.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4480000</td>\n",
       "      <td>4432650.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4305000</td>\n",
       "      <td>5789048.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4375000</td>\n",
       "      <td>2979678.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>8043000</td>\n",
       "      <td>8124490.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test True Y  Model Predictions\n",
       "0       7140000         5635887.50\n",
       "1       4620000         4670689.00\n",
       "2       8855000         7030397.00\n",
       "3       2100000         2765856.00\n",
       "4       4095000         3997377.25\n",
       "..          ...                ...\n",
       "77      3773000         4920238.00\n",
       "78      4480000         4432650.50\n",
       "79      4305000         5789048.00\n",
       "80      4375000         2979678.00\n",
       "81      8043000         8124490.50\n",
       "\n",
       "[82 rows x 2 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# reshape the data for easier comparison table\n",
    "test_predictions = pd.Series(test_predictions.reshape(len(y_test),))\n",
    "pred_df = pd.DataFrame(np.asarray(y_test), columns=['Test True Y'])\n",
    "pred_df = pd.concat([pred_df, test_predictions], axis=1)\n",
    "pred_df.columns = ['Test True Y', 'Model Predictions']\n",
    "\n",
    "# print the comparison table - true values vs. model predicted values\n",
    "# we can nicely see here how far off our model is in some cases\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Test True Y', ylabel='Model Predictions'>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# these values follow a linear line = good predictions\n",
    "# we basically compare the predicted values \n",
    "# to true test values and see the differences\n",
    "sns.scatterplot(x='Test True Y', y='Model Predictions', data=pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regression error metrics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "842890.25 $\n",
      "\n",
      "MSE\n",
      "1343154791763.14 $^2\n",
      "\n",
      "RMSE:\n",
      "1158945.55 $\n",
      "\n",
      "R-squared:\n",
      "0.6\n",
      "\n",
      "Explained variance score:\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "# MAE - Mean average error\n",
    "print(\"MAE\")\n",
    "print(round(metrics.mean_absolute_error(y_test, test_predictions), 2), \"$\")\n",
    "\n",
    "# MSE - Mean square error\n",
    "print(\"\\nMSE\")\n",
    "print(round(metrics.mean_squared_error(y_test, test_predictions), 2), \"$^2\")\n",
    "\n",
    "# RMSE - Root mean square error\n",
    "print('\\nRMSE:')\n",
    "print(round(np.sqrt(metrics.mean_squared_error(y_test, test_predictions)), 2), \"$\")\n",
    "\n",
    "# R-squared. 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "print('\\nR-squared:')\n",
    "print(round(metrics.r2_score(y_test, test_predictions), 2))\n",
    "\n",
    "# Explained Variance Score => 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "# high variance score = model is a good fit for the data \n",
    "# low variance score = model is not a good fit for the data\n",
    "# the higher the score, the model is more able to explain the variation in the data\n",
    "# if score is low, we might need more and better data\n",
    "print(\"\\nExplained variance score:\")\n",
    "print(round(metrics.explained_variance_score(y_test, test_predictions), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/19/0ldx1bc54jx5tvjkrsbcv4040000gn/T/ipykernel_23057/3124900743.py:5: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot((y_test - test_predictions))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAG+CAYAAAB76rvCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABhoklEQVR4nO3deVzUdf4H8NfMwMxwDjcDCIKomBeQB+GRWRSimXaYWZvHdmytthW5rbaltblZ/bK1w82tPNvMajMzM9MwNBU1DzzxQLlluJmB4RiY+f7+GJkiQbm/c7yej8f3set3PvPl/U0ZXnw+n+/nIxEEQQARERGRA5GKXQARERFRT2MAIiIiIofDAEREREQOhwGIiIiIHA4DEBERETkcBiAiIiJyOAxARERE5HAYgIiIiMjhMAARERGRw2EAIiIiIofDAHQde/bsweTJkxEcHAyJRILNmzd369cLDw+HRCK56pg7d263fl0iIiJHwgB0HXq9HtHR0VixYkWPfL1ffvkFhYWFlmPnzp0AgGnTpvXI1yciInIEDEDXkZSUhCVLluDuu+9u8fX6+nrMnz8fISEhcHNzQ1xcHFJTUzv89fz9/aFWqy3H1q1bERkZiXHjxnX4mkRERNQcA1AnzZs3D2lpadi4cSNOnDiBadOmYcKECbhw4UKnr20wGPDf//4Xf/zjHyGRSLqgWiIiIgIAiSAIgthF2AqJRIKvv/4aU6dOBQDk5uaiT58+yM3NRXBwsKVdQkICRo4ciddee61TX++LL77Agw8+eNX1iYiIqHPYA9QJJ0+ehNFoRP/+/eHu7m45du/ejYsXLwIAzp492+Kk5t8eCxYsaPH6q1atQlJSEsMPERFRF3MSuwBbVl1dDZlMhiNHjkAmkzV7zd3dHQDQp08fZGRkXPM6vr6+V53LycnBjz/+iE2bNnVdwURERASAAahTYmNjYTQaUVxcjLFjx7bYRi6XY8CAAe2+9po1axAQEIBJkyZ1tkwiIiL6HQag66iurkZmZqblz1lZWUhPT4ePjw/69++Phx56CDNnzsSyZcsQGxuLkpISpKSkYOjQoR0OLyaTCWvWrMGsWbPg5MS/IiIioq7GSdDXkZqaivHjx191ftasWVi7di0aGhqwZMkSrF+/HgUFBfDz88NNN92EV155BUOGDOnQ19yxYwcSExNx7tw59O/fv7O3QERERL/DAEREREQOh0+BERERkcNhACIiIiKHwxm2LTCZTLh8+TI8PDy4AjMREZGNEAQBVVVVCA4OhlR67T4eBqAWXL58GaGhoWKXQURERB2Ql5eHXr16XbMNA1ALPDw8AJj/A3p6eopcDREREbWFTqdDaGio5ef4tTAAtaBp2MvT05MBiIiIyMa0ZfoKJ0ETERGRw2EAIiIiIofDAEREREQOhwGIiIiIHA4DEBERETkcBiAiIiJyOAxARERE5HAYgIiIiMjhMAARERGRw2EAIiIiIofDAEREREQOhwGIiIiIHA4DEBERETkcBiAiIiJyOE5iF0BEZI82HMwVu4Qu8WBcmNglEHUL9gARERGRw2EAIiIiIofDAEREREQOhwGIiIiIHA4DEBERETkcBiAiIiJyOAxARERE5HAYgIiIiMjhMAARERGRw2EAIiIiIofDAEREREQOhwGIiIiIHI6oAWjp0qUYMWIEPDw8EBAQgKlTp+LcuXPXfd+XX36JAQMGQKlUYsiQIdi2bVuz1wVBwKJFixAUFAQXFxckJCTgwoUL3XUbREREZGNEDUC7d+/G3LlzceDAAezcuRMNDQ244447oNfrW33P/v37MWPGDDzyyCM4duwYpk6diqlTp+LUqVOWNm+++SbeffddrFy5EgcPHoSbmxsSExNRV1fXE7dFREREVk4iCIIgdhFNSkpKEBAQgN27d+Pmm29usc306dOh1+uxdetWy7mbbroJMTExWLlyJQRBQHBwMJ577jnMnz8fAKDVahEYGIi1a9figQceuG4dOp0OKpUKWq0Wnp6eXXNzRORQNhzMFbuELvFgXJjYJRC1WXt+flvVHCCtVgsA8PHxabVNWloaEhISmp1LTExEWloaACArKwsajaZZG5VKhbi4OEub36uvr4dOp2t2EBERkf2ymgBkMpnwzDPPYPTo0Rg8eHCr7TQaDQIDA5udCwwMhEajsbzedK61Nr+3dOlSqFQqyxEaGtqZWyEiIiIrZzUBaO7cuTh16hQ2btzY41974cKF0Gq1liMvL6/HayAiIqKe4yR2AQAwb948bN26FXv27EGvXr2u2VatVqOoqKjZuaKiIqjVasvrTeeCgoKatYmJiWnxmgqFAgqFohN3QERERLZE1B4gQRAwb948fP3119i1axciIiKu+574+HikpKQ0O7dz507Ex8cDACIiIqBWq5u10el0OHjwoKUNEREROTZRe4Dmzp2LDRs24JtvvoGHh4dljo5KpYKLiwsAYObMmQgJCcHSpUsBAE8//TTGjRuHZcuWYdKkSdi4cSMOHz6MDz/8EAAgkUjwzDPPYMmSJejXrx8iIiLw0ksvITg4GFOnThXlPomIiMi6iBqAPvjgAwDALbfc0uz8mjVrMHv2bABAbm4upNJfO6pGjRqFDRs24MUXX8QLL7yAfv36YfPmzc0mTj///PPQ6/V4/PHHUVlZiTFjxmD79u1QKpXdfk9ERERk/axqHSBrwXWAiKizuA4QUc+z2XWAiIiIiHoCAxARERE5HAYgIiIicjhWsQ4QEZGtaTSa8GNGMfZmliC3vBZF2joEqpTo4+eGsf38YBIESCUSscskolYwABERtYOh0YSP917Cuv3ZKNLVN3vtXFEV9pwvwdr92fBzl+Pmfv4Y1tsbEgYhIqvDAERE1EanCrSY/+VxnNVUAQB83eSYEhOCAWoPBHgqoNHW4UyhDl8fK0BptQGbjhUgo1CH+4aFwkUuE7l6IvotBiAiojb46kg+/vbVCTSaBPi4yfHCxBtwV3Qw5E5XT6X824QBeO6L49iZUYQMTRXe++kCZseHI8CTa5ERWQtOgiYiuo7/7L6I5748jkaTgDsGBmLHszfjvmG9Wgw/AOCmcMLN/f3xxLhI+LjJUVnTgNX7slCuN/Rw5UTUGgYgIqJreC/lApZ+fxYA8OiYCKz8wzD4ubdt8+QQLxf8eVwkAjwU0NU1YtXeS9DVNnRnuUTURgxARESt+PJwHpbtPA/APKz14p0DIZW2b0Kzq8IJfxwTAR83OSpqGvDpwRwYTVyAn0hsDEBERC3Yc74ECzedBAA8eUsknrwlssPX8lQ644+jI6B0liKvohY/ZhR1VZlE1EEMQEREv5NfUYN5G46i0SRgakww/npHVKev6eMmx92xvQCYw1VmcXWnr0lEHccARET0Gw1GE/7y2THo6hoRHeqFN+4b2u5hr9YMCVFhRLgPBAD/O5KH+gZjl1yXiNqPAYiI6DeW7TiPo7mV8FA64f0ZsVA4de36PZOGBMHHTQ5dXSN+OlfcpdcmorZjACIiuuJQVjlW7r4IAHjj3qEI9XHt8q8hd5LiziFBAIB9mWUoqaq/zjuIqDswABERAahrMGLBVycAANOG9cLEKyGlOwwI8kRUoAeMgoCtJy5DEPhUGFFPYwAiIgLw3q4LuFSqh7+HAi9OGtjtX+/OoUGQSSW4UFyNC5wQTdTjGICIyOFlFOqwcvclAMCrUwZD5erc7V/T112BmyJ8AAApGUXsBSLqYQxAROTQBEHAy1tOw2gSMGGQGhMGq3vsa9/c3x9OUgnyKmrZC0TUwxiAiMihbTupwcGsciicpHhpcvcPff2Wh9IZcewFIhIFAxAROay6BiNe25YBAHhiXCRCvFx6vIab+/vDWcZeIKKexgBERA7roz2XUFBZi2CVEk+M6/hWF53hoXTGyHBzL9DezFJRaiByRAxAROSQyvUG/GePeeLzgok3wEXetQsetkd8pB8kADKLq1GkqxOtDiJHwgBERA7pg9RMVNc3YlCwp2VhQrH4uMlxQ5AnAGD/xTJRayFyFAxARORwLlfWYl1aDgDgr4lRXbbXV2eM6usLAEjPq0CNoVHkaojsHwMQETmcd1MuwNBoQlyED8b19xe7HABAhK8bglRKNBgF/JJdIXY5RHaPAYiIHEpeeQ2+PJIPAHh+QhQkEvF7fwBAIpFgVKS5F+hQVhlMfCSeqFsxABGRQ/l3aiaMJgFj+/lhWG8fsctpZkiIFxROUlTUNCCrVC92OUR2jQGIiBxGQWUt/nel9+fp2/qJXM3V5E5SDO3lBQA4ksNhMKLuxABERA5jZepFNBgFxPfxxfBw6+r9aTK8tzcA4FSBFrUGo8jVENkvBiAicgjFujp8/kseAOAvVtj706SXtwsCPRVoNAk4nl8pdjlEdkvUALRnzx5MnjwZwcHBkEgk2Lx58zXbz549GxKJ5Kpj0KBBljYvv/zyVa8PGDCgm++EiKzdurRsGIwm3BjmhZv6WGfvD2CeDN00N4nDYETdR9QApNfrER0djRUrVrSp/TvvvIPCwkLLkZeXBx8fH0ybNq1Zu0GDBjVrt3fv3u4on4hsRI2hEf89kAsAePzmPlbz5FdrYkO9IJWY5ywVV3FlaKLu4CTmF09KSkJSUlKb26tUKqhUKsufN2/ejIqKCsyZM6dZOycnJ6jV6i6rk4hs2/+O5ENb24Devq64faD1fza4KZzQL8AD54qqcCJfi4QblGKXRGR3bHoO0KpVq5CQkIDevXs3O3/hwgUEBwejT58+eOihh5Cbm3vN69TX10On0zU7iMg+GE0CVu3NAgD8cXQEZFaw6nNbDO1l/mXvRH4lBK4JRNTlRO0B6ozLly/j+++/x4YNG5qdj4uLw9q1axEVFYXCwkK88sorGDt2LE6dOgUPD48Wr7V06VK88sorPVE2EV3HhoPX/oWlvc5c1iKnrAYuzjIIQtdfv7sMDPKEk1SC0moDLmvrEOLlInZJRHbFZnuA1q1bBy8vL0ydOrXZ+aSkJEybNg1Dhw5FYmIitm3bhsrKSnzxxRetXmvhwoXQarWWIy8vr5urJ6Ke8nNmKQBgZIQP5E6285GncJZhwJUNUk/waTCiLmc7nwa/IQgCVq9ejYcffhhyufyabb28vNC/f39kZma22kahUMDT07PZQUS2L6+8BjllNZBJJIjv4yt2Oe02NKRpGEzLrTGIuphNBqDdu3cjMzMTjzzyyHXbVldX4+LFiwgKCuqByojImuy90vsTHaqCp4uzyNW0X5TaAwonKbS1DcgrrxG7HCK7ImoAqq6uRnp6OtLT0wEAWVlZSE9Pt0xaXrhwIWbOnHnV+1atWoW4uDgMHjz4qtfmz5+P3bt3Izs7G/v378fdd98NmUyGGTNmdOu9EJF1qdAbcKpACwAY3ddP5Go6xlkmxQ1XhsFOX+bDGURdSdQAdPjwYcTGxiI2NhYAkJycjNjYWCxatAgAUFhYeNUTXFqtFl999VWrvT/5+fmYMWMGoqKicP/998PX1xcHDhyAv79/994MEVmV/RdLIQDo6++OIJXtTiAeaAlAWj4NRtSFRH0K7JZbbrnmN/TatWuvOqdSqVBT03pX8MaNG7uiNCKyYYZGE47kmldRHt3X9ub+/Fb/QA84SSWoqGmARldn02GOyJrY5BwgIqJrOVlQiboGE7xdndEvsOXlL2yF3ElquQcOgxF1HQYgIrI7B7PKAQAjI3whtfJtL9pi0JVhsDMMQERdhgGIiOxKQUUt8itqIZNKMKy3t9jldIkBQR6QSgCNrg5l1fVil0NkFxiAiMiuHMwqAwAMDvaEu8JmF7tvxlXuhAg/NwDAmUL2AhF1BQYgIrIbtQYjjl9ZNTkuwrYnP/9e0+PwZzVVIldCZB8YgIjIbhzLq0CDUUCgpwK9fV3FLqdLDVCbA1BOmR61BqPI1RDZPgYgIrILgiBYJj/HRfhCYgeTn3/Lx00Ofw8FTAJwoZi9QESdxQBERHYhq1SPkqp6yGVSxIR6iV1Otxhw5XH4cxwGI+o0BiAisgtNvT/RoV5QOstErqZ7RKmvBKCiKm6OStRJDEBEZPOq6hpw+rJ536+4CB+Rq+k+vX3doHSWosZgRH5FrdjlENk0BiAisnnHcithEoBQbxcEe9nvVhEyqQT9ApqGwfg4PFFnMAARkU0TBAGHc8z7fg0Pt9/enyaWYTDOAyLqFAYgIrJpueU1KK2uh7NMgiEhKrHL6Xb9AtwBAJe1daiubxS5GiLbxQBERDatqfdnSIj9Tn7+LQ+lM4JUSgBAJh+HJ+owBiAisln1DUaczDdPfraXfb/aoqkX6EJRtciVENkuBiAislknC7QwGE3wc5cj3M5Wfr6WflfWA8osrobAx+GJOoQBiIhsVtPw17DePna38vO19PZxhbNMgqr6Rmh0dWKXQ2STGICIyCYVV9Uht7wGUgkQG+Yldjk9ykkmRR8/8zBYZjGHwYg6ggGIiGzSkSu9P/0DPeCpdBa5mp7XL5DzgIg6gwGIiGyO0STgaG4lAGC4A01+/q2+VyZCZ5fp0WA0iVwNke1hACIim3NOUwV9fSPcFU6IUnuKXY4o/N0V8FQ6odEkIKesRuxyiGwOAxAR2ZwjOeaNT2PDvCCTOs7k59+SSCTo42/uBbpUymEwovZiACIim1Jd34hzReYFAG8Mc8zhryaR/m4AgEslepErIbI9DEBEZFNO5Js3Pg3xckGgp1LsckTV9CRYfkUN6huNIldDZFsYgIjIpqTnVQJwvEffW+LtJoe3qzNMAjgPiKidGICIyGYU6+qQX1ELqQQY2stL7HKsQlMv0KUSzgMiag8GICKyGceu9P70D/SAu8JJ3GKsRJ+meUClnAdE1B4MQERkE0yC8JvhL8ee/PxbTU+CFVTUoq6B84CI2ooBiIhsQlapHtraBiidpRig9hC7HKuhcnGGr5scAsz/jYiobRiAiMgmHLuy8vOQEBWcZfzo+i3LekCcB0TUZvwUISKrZ2g04dRlLQAgNpTDX78XyXlARO0magDas2cPJk+ejODgYEgkEmzevPma7VNTUyGRSK46NBpNs3YrVqxAeHg4lEol4uLicOjQoW68CyLqbmcKdTA0muDt6ozevq5il2N1IvzMAahQW4ea+kaRqyGyDaIGIL1ej+joaKxYsaJd7zt37hwKCwstR0BAgOW1zz//HMnJyVi8eDGOHj2K6OhoJCYmori4uKvLJ6IecizXvPN7bJg3JBLH3PriWjyUzgjwUABgLxBRW4n6HGlSUhKSkpLa/b6AgAB4eXm1+Nrbb7+Nxx57DHPmzAEArFy5Et999x1Wr16NBQsWdKZcIhKBrq4BmcXmuS2xoV7iFmPF+vi7obiqHpdK9RgcohK7HCKrZ5NzgGJiYhAUFITbb78d+/bts5w3GAw4cuQIEhISLOekUikSEhKQlpbW6vXq6+uh0+maHURkHY7nVUIAEObjCl93hdjlWC0uiEjUPjYVgIKCgrBy5Up89dVX+OqrrxAaGopbbrkFR48eBQCUlpbCaDQiMDCw2fsCAwOvmif0W0uXLoVKpbIcoaGh3XofRNR2TU9/ceuLa+tzZR5QcVU9quoaRK6GyPrZ1FKqUVFRiIqKsvx51KhRuHjxIv71r3/hk08+6fB1Fy5ciOTkZMufdTodQxCRFSjU1kKjq4NMKsEQDutck6vCCUEqJQq1dcgq1XOrEKLrsKkeoJaMHDkSmZmZAAA/Pz/IZDIUFRU1a1NUVAS1Wt3qNRQKBTw9PZsdRCS+pt6fAWoPuMpt6vc1UTT1Al0q4URoouux+QCUnp6OoKAgAIBcLsewYcOQkpJied1kMiElJQXx8fFilUhEHWA0CTjetPUF1/5pk/ArASi7jAGI6HpE/ZWqurra0nsDAFlZWUhPT4ePjw/CwsKwcOFCFBQUYP369QCA5cuXIyIiAoMGDUJdXR0+/vhj7Nq1Czt27LBcIzk5GbNmzcLw4cMxcuRILF++HHq93vJUGBHZhosl1aiqb4SrXIb+anexy7EJvX1/nQdUU98IV24YS9QqUb87Dh8+jPHjx1v+3DQPZ9asWVi7di0KCwuRm5tred1gMOC5555DQUEBXF1dMXToUPz444/NrjF9+nSUlJRg0aJF0Gg0iImJwfbt26+aGE1E1q1p49OhvVRwktp8Z3WPcFc4wd9dgZLqeuSU1+CGIA7nE7VGIgiCIHYR1kan00GlUkGr1XI+EFEP23AwF4ZGE17blgGD0YQnxkUizIerP7fVpqP5OJxTgbH9/JA0OKjT13swLqwLqiLqGe35+c1fq4jI6mRodDAYzVtfhHq7iF2OTbHMA+KK0ETXxABERFanafJzdKgXt75op/Ar84AuV9bB0GgSuRoi68UARERWpaa+EeeLqgAA0VzLpt28XZ3hqXSCURCQX1EjdjlEVosBiIisyqnLOpgEIEilRKCnUuxybI5EIrE8DZZdxgBE1BoGICKyKsfzKwGw96czwn3Nk8ZzuB4QUasYgIjIalyurLVM3h3ai1tfdFTTROic8hoYTXzQl6glDEBEZDW2nrgMAeYeDC9Xudjl2KxATyUUTlIYGk3Q6OrELofIKjEAEZHV+Cb9MgDz01/UcVKJBL2vDIPxcXiiljEAEZFVyCyuwunLOkglwOBgDn91Vrgv9wUjuhYGICKyCluu9P70C/CAG/ew6rSmJ8FyymrABf+JrsYARESiEwQB3xzn8FdX6uXtAplUgur6RpTpDWKXQ2R1GICISHTH87XIKauBi7MMNwR5iF2OXXCWSdHLy7yNCB+HJ7oaAxARie6b9AIAwO0DA6Fwkolcjf34dV8wLohI9HsMQEQkKqNJwLfHCwEAU2KCRa7GvjQtiMiJ0ERXYwAiIlGlXSxDaXU9vFydMbafv9jl2JUwHzdIAJTpDaiqaxC7HCKrwgBERKJqGv6aOCQIcid+JHUlF7nMsp9abjmHwYh+i582RCSaugYjtp/SAACmRHP4qzuE+ZiHwXK5MSpRMwxARCSa1HPFqKpvRJBKiRHhPmKXY5eaAlAOe4CImmEAIiLRNG19cVd0MKRSicjV2KewKxOhCypr0Wg0iVwNkfVgACIiUejqGpBythgAcBef/uo2vm5yuMplMJoEXK6sFbscIqvBAEREovjhlAaGRhP6BrhjYJCn2OXYLYlEgt5N84A4DEZkwQBERKLYcmXriynRwZBIOPzVncKa9gVjACKyYAAioh5XXFWHfZmlADj81RN++yQYN0YlMmMAIqIe992JQpgEICbUy7JrOXWfXt4ukEqAqvpGVNZwQUQigAGIiETQ9PQXt77oGc4yKYKbNkblMBgRAAYgIuphOWV6pOdVQioBJg0NErsch/HrRGjuC0YEMAARUQ/bcqX3Z3RfPwR4KEWuxnE0TYTmitBEZgxARNRjBEHA5it7f93FrS96VNNE6EJtHeobjSJXQyQ+BiAi6jFnCnW4WKKH3EmKxMFqsctxKCoXZ6hcnCEAyK/ggohEDEBE1GOahr9uGxAAT6WzyNU4Hsu+YBwGI2IAIqKeYTIJvy5+yKe/RNH7yr5geXwSjEjcALRnzx5MnjwZwcHmlWA3b958zfabNm3C7bffDn9/f3h6eiI+Ph4//PBDszYvv/wyJBJJs2PAgAHdeBdE1Ba/ZJejUFsHD4UTbokKELschxT2my0xTFwQkRycqAFIr9cjOjoaK1asaFP7PXv24Pbbb8e2bdtw5MgRjB8/HpMnT8axY8eatRs0aBAKCwstx969e7ujfCJqh2+u9P5MGKyG0lkmcjWOKUjlAmeZBLUNRpRW1YtdDpGonMT84klJSUhKSmpz++XLlzf782uvvYZvvvkG3377LWJjYy3nnZycoFZzgiWRtTA0mrDtZCEAYEpMiMjVOC6ZVIJe3q7IKtUjt7wGAZ5choAcl03PATKZTKiqqoKPj0+z8xcuXEBwcDD69OmDhx56CLm5ude8Tn19PXQ6XbODiLrOzxdKUFnTAD93BeIjfcUux6FZJkJzHhA5OJsOQG+99Raqq6tx//33W87FxcVh7dq12L59Oz744ANkZWVh7NixqKqqavU6S5cuhUqlshyhoaE9UT6Rw2ja+mJydBBkUu78Lqbev9kYlciRdSgAXbp0qavraLcNGzbglVdewRdffIGAgF8nVCYlJWHatGkYOnQoEhMTsW3bNlRWVuKLL75o9VoLFy6EVqu1HHl5eT1xC0QOQV/fiJ1nigBw+MsahF4JQCXV9aipbxS5GiLxdCgA9e3bF+PHj8d///tf1NXVdXVN17Vx40Y8+uij+OKLL5CQkHDNtl5eXujfvz8yMzNbbaNQKODp6dnsIKKu8WNGEWobjOjt64roXiqxy3F4bgon+LkrAAC5FewFIsfVoQB09OhRDB06FMnJyVCr1fjTn/6EQ4cOdXVtLfrss88wZ84cfPbZZ5g0adJ121dXV+PixYsICuKmi0RisOz8Hm1e7oLEx2Ewog4GoJiYGLzzzju4fPkyVq9ejcLCQowZMwaDBw/G22+/jZKSkjZdp7q6Gunp6UhPTwcAZGVlIT093TJpeeHChZg5c6al/YYNGzBz5kwsW7YMcXFx0Gg00Gg00Gq1ljbz58/H7t27kZ2djf379+Puu++GTCbDjBkzOnKrRNQJ5XoD9pw3fx7cxcUPrUaYLydCE3VqErSTkxPuuecefPnll3jjjTeQmZmJ+fPnIzQ0FDNnzkRhYeE133/48GHExsZaHmFPTk5GbGwsFi1aBAAoLCxs9gTXhx9+iMbGRsydOxdBQUGW4+mnn7a0yc/Px4wZMxAVFYX7778fvr6+OHDgAPz9/Ttzq0TUAdtOFqLRJGBQsCf6BniIXQ5d0fQkWH5FDYwmLohIjqlT6wAdPnwYq1evxsaNG+Hm5ob58+fjkUceQX5+Pl555RVMmTLlmkNjt9xyC4RrrEa6du3aZn9OTU29bk0bN25sa/lE1M2a9v7i1hfWxd9DAaWzFHUNJmh0dQjxchG7JKIe16EA9Pbbb2PNmjU4d+4cJk6ciPXr12PixImQSs0dShEREVi7di3Cw8O7slYisiEFlbU4lF0OiQSYHM0AZE2kEgnCfFxxvqgauWV6BiBySB0KQB988AH++Mc/Yvbs2a1OLg4ICMCqVas6VRwR2a6m3p+R4T4IUvEHrLVpCkA55TWIjxS7GqKe16EAtHPnToSFhVl6fJoIgoC8vDyEhYVBLpdj1qxZXVIkEdmeb9ILAABTY7n2jzUK83EDYN4YlcgRdWgSdGRkJEpLS686X15ejoiIiE4XRUS27ZymCmc1VXCWSZA0mPvyWaNQbxdIAFTWNEBb2yB2OUQ9rkMBqLWJy9XV1VAqubkekaNr6v25JSoAXq5ykauhliicZVCrzJ/X7AUiR9SuIbDk5GQAgEQiwaJFi+Dq6mp5zWg04uDBg4iJienSAonItphMwq+LH/LpL6sW5uOKQm0dcsv0GBLCVbrJsbQrAB07dgyAuQfo5MmTkMt//c1OLpcjOjoa8+fP79oKicimHM2tQEFlLdzkMiTcECh2OXQNvX1dcTCrnD1A5JDaFYB++uknAMCcOXPwzjvvcM8sIrrK5ivDX4mD1VA6y0Suhq6laSL05co6NBhNcJZ1am1cIpvSoX/ta9asYfghoqs0GE347oR5Bfip3Pnd6nm7OsND4QSjIKCgolbscoh6VJt7gO655x6sXbsWnp6euOeee67ZdtOmTZ0ujIhsz88XSlBR0wA/dwVGRfqKXQ5dh0QiQaiPK84U6pBbXoNwPzexSyLqMW0OQCqVyrKTs0rFyXJEdLXNx8yTn+8cGgQnDqfYhN6+vwYgIkfS5gC0Zs2aFv8/EREA6OsbsfNMEQAufmhLmjZGzSmvgSAIll90iexdh35Fq62tRU3Nr78t5OTkYPny5dixY0eXFUZEtmXnmSLUNhjR29cV0b3YS2wrgr1cIJNKoK9vRLneIHY5RD2mQwFoypQpWL9+PQCgsrISI0eOxLJlyzBlyhR88MEHXVogEdmGpsUPp8SEsBfBhjjLpJbNUHM4DEYOpEMB6OjRoxg7diwA4H//+x/UajVycnKwfv16vPvuu11aIBFZv7Lqeuy5YN4eh4sf2p7eTcNgZQxA5Dg6FIBqamrg4eEBANixYwfuueceSKVS3HTTTcjJyenSAonI+m07WQijScCQEBUi/d3FLofaKczXHIByy/UiV0LUczoUgPr27YvNmzcjLy8PP/zwA+644w4AQHFxMdcHInJAm7n1hU1rmghdrKtHrcEocjVEPaNDAWjRokWYP38+wsPDERcXh/j4eADm3qDY2NguLZCIrFteeQ2O5FRAIgEmRzMA2SIPpTN83eQQwI1RyXG0ayuMJvfddx/GjBmDwsJCREdHW87fdtttuPvuu7usOCKyfluOm3t/RkX6ItBTKXI11FFhPq4o0xuQW65HlNpD7HKIul2HAhAAqNVqqNXqZudGjhzZ6YKIyHYIgoDNx648/RXNtX9sWW9fNxzLq+REaHIYHQpAer0er7/+OlJSUlBcXAyTydTs9UuXLnVJcURk3TIKq3ChuBpyJykmDFFf/w1ktXpfmQidV1EDo0mATMqlDMi+dSgAPfroo9i9ezcefvhhBAUFcc0PIgfVtPbPrVEB8FQ6i1wNdYa/hwJKZynqGkzQaOsQ4u0idklE3apDAej777/Hd999h9GjR3d1PURkI0wmwTL/Z2osJz/bOqlEgjAfV5wvqkZOuZ4BiOxeh54C8/b2ho+PT1fXQkQ25FB2OQq1dfBQOuGWqACxy6Eu0NvXvBs85wGRI+hQAHr11VexaNGiZvuBEZFj+ebK2j9Jg9VQOstEroa6QtN6QHwUnhxBh4bAli1bhosXLyIwMBDh4eFwdm4+9n/06NEuKY6IrJOh0YRtJwsBAFNj+PSXvQj1doVUAmhrG1BZY4CXq1zskoi6TYcC0NSpU7u4DCLqrA0Hc3vsa2UU6qCtbYCH0gmXSvXI5pCJXZA7SRGkckFBZS1yymoYgMiudSgALV68uKvrICIbciy3AgAwNEQFKZ8CtSthvq7mAFReg+hQL7HLIeo2HZoDBACVlZX4+OOPsXDhQpSXlwMwD30VFBR0WXFEZH1qDUac1VQBAGLDvEWuhrpa087wuWXcGJXsW4d6gE6cOIGEhASoVCpkZ2fjscceg4+PDzZt2oTc3FysX7++q+skIitxqkCLRpOAQE8FglTc+sLeND0JVqitQ30jN0Yl+9WhHqDk5GTMnj0bFy5cgFL56wfgxIkTsWfPni4rjoisz7E88/BXbKg3F0G1QyoXZ3i5OEMAkFdeK3Y5RN2mQwHol19+wZ/+9KerzoeEhECj0bT5Onv27MHkyZMRHBwMiUSCzZs3X/c9qampuPHGG6FQKNC3b1+sXbv2qjYrVqxAeHg4lEol4uLicOjQoTbXREStq9AbkF1WAwnA+SF2LOzKthg55RwGI/vVoQCkUCig0+muOn/+/Hn4+/u3+Tp6vR7R0dFYsWJFm9pnZWVh0qRJGD9+PNLT0/HMM8/g0UcfxQ8//GBp8/nnnyM5ORmLFy/G0aNHER0djcTERBQXF7e5LiJq2bG8SgBAH383qFy49YW9ahoGy+XTfWTHOhSA7rrrLvzjH/9AQ0MDAEAikSA3Nxd/+9vfcO+997b5OklJSViyZAnuvvvuNrVfuXIlIiIisGzZMtxwww2YN28e7rvvPvzrX/+ytHn77bfx2GOPYc6cORg4cCBWrlwJV1dXrF69un03SUTNCIKA9N8Mf5H9Crf0ANWg0Wi6Tmsi29ShALRs2TJUV1fD398ftbW1GDduHPr27QsPDw/885//7OoaLdLS0pCQkNDsXGJiItLS0gAABoMBR44cadZGKpUiISHB0qYl9fX10Ol0zQ4iai6/ohal1QY4yyQYFOwpdjnUjQI9lVA6S2FoNOFMIT8PyT516CkwlUqFnTt3Yt++fTh+/Diqq6tx4403XhVOuppGo0FgYGCzc4GBgdDpdKitrUVFRQWMRmOLbc6ePdvqdZcuXYpXXnmlW2omshdNw18Dgzyh4NYXdk0qkaC3jxvOFVXhUFY5hvbyErskoi7X7gBkMpmwdu1abNq0CdnZ2ZBIJIiIiIBarYYgCDb5VMjChQuRnJxs+bNOp0NoaKiIFRFZl0aTCSfyKwFw7R9HEe5nDkC/ZJfj0bF9xC6HqMu1KwAJgoC77roL27ZtQ3R0NIYMGQJBEJCRkYHZs2dj06ZNbXqSq6PUajWKioqanSsqKoKnpydcXFwgk8kgk8labKNWq1u9rkKhgEKh6JaaiezBhaJq1BiMcFc4IdLfXexyqAdEXJkH9Et2hc3+ckt0Le2aA7R27Vrs2bMHKSkpOHbsGD777DNs3LgRx48fx48//ohdu3Z16yKI8fHxSElJaXZu586diI+PBwDI5XIMGzasWRuTyYSUlBRLGyJqv6atL6J7qSCT8gehIwj2doGzTIJyvQEXS6rFLoeoy7UrAH322Wd44YUXMH78+Kteu/XWW7FgwQJ8+umnbb5edXU10tPTkZ6eDsD8mHt6ejpyc82bOi5cuBAzZ860tH/iiSdw6dIlPP/88zh79iz+/e9/44svvsCzzz5raZOcnIyPPvoI69atQ0ZGBp588kno9XrMmTOnPbdKRFdw6wvH5CSVope3uRfoUFaFyNUQdb12BaATJ05gwoQJrb6elJSE48ePt/l6hw8fRmxsLGJjYwGYw0tsbCwWLVoEACgsLLSEIQCIiIjAd999h507dyI6OhrLli3Dxx9/jMTEREub6dOn46233sKiRYsQExOD9PR0bN++/aqJ0UTUNk1bXwR4cOsLRxPhZ14P6JfscpErIep6EkEQhLY2lsvlyMnJQVBQUIuvX758GREREaivr++yAsWg0+mgUqmg1Wrh6cnHfck2bDiYe/1GHfDhnovILqtB4iA1xvVv+0KnZPsyi6uxel8WQrxcsG/BrWKXQ3Rd7fn53a4eIKPRCCen1udNy2QyNDY2tueSRGTFfrv1RQy3vnA4oT4ukEklKKisRUEl9wUj+9Lup8Bmz57d6hNTtt7zQ0TNcesLx6ZwkmFwiArH8yrxS1Y5QmJDxC6JqMu0KwDNmjXrum1+O2mZiGwXt74gABgZ7o3jeZU4mFWOqQxAZEfaFYDWrFnTXXUQkZXh1hcEACPCffDRz1mcCE12p0N7gRGR/TtyZe2fQcEqbn3hwEaE+wAwT4guq+Y0B7IfDEBEdJUG469bX9zItX8cmrebHP0Dzat//5LN9YDIfjAAEdFVzlzWoa7BBC9XZ/TxdxO7HBJZUy8Qh8HInjAAEdFVmoa/bgzzhpR7QDm8kREMQGR/GICIqJnKGgMuFpv3fuLwFwG/BqBTBVpU13OtN7IPDEBE1MzR3EoIMG+D4OMmF7scsgJBKhf08naBSQAOsxeI7AQDEBFZCIKAo1eGv4b1Zu8P/Sq+jy8AIO1SmciVEHUNBiAissguq0G53gCFkxSDg1Vil0NWZFTfKwHoIgMQ2QcGICKyOJJj7v0ZEqKC3IkfD/Sr+D5+AMzzgLS1DSJXQ9R5/IQjIgBAfaMRpwq0ADj5ma6mVinRx98NJgE4lMV5QGT7GICICABwqkAHg9EEXzc5evu6il0OWaFRkeZhsP0XS0WuhKjzGICICMCvw1/DentDwrV/qAVNw2CcB0T2gAGIiFBWXY/sMj0kAGI5/EWtuKmPeT2gs5oqlHJfMLJxDEBEZHn0vW+AO1QuziJXQ9bK112BAWoPAMABPg5PNo4BiMjBmQQBR3MrAXDtH7q+UZEcBiP7wABE5OAullRDW9sApbMUNwR5il0OWbmmidAMQGTrGICIHFzT5OfoXl5wlvEjga5tZB8fSCXApVI9CrW1YpdD1GH8tCNyYLUGI85c1gHg8Be1jafSGUNCzKuEsxeIbBkDEJEDS8+rQKNJgNpTiRAvF7HLIRsRf2Ue0H4GILJhDEBEDkoQBPySbR7+GhHhw7V/qM1+Ow9IEASRqyHqGAYgIgeVV1ELja4OzjIJYnp5iV0O2ZDh4d5wlklQUFmL3PIascsh6hAGICIH9cuV/ZyGhKjgIpeJXA3ZEle5E2JDzXPGOA+IbBUDEJEDqmsw4kRBJQBgRLiPuMWQTYq/Mgy2jwGIbBQDEJEDSs+rRINRQICHAmE+3PiU2s+yMWpmKUwmzgMi28MARORgzJOfzcNfI8I5+Zk6JjbMG25yGcr0Bpwp1IldDlG7MQAROZiCyloUauvgJJUgNsxL7HLIRsmdpJbH4XefLxG5GqL2YwAicjBNvT+DQ1RwlTuJXA3ZsnH9zQHo5wsMQGR7rCIArVixAuHh4VAqlYiLi8OhQ4dabXvLLbdAIpFcdUyaNMnSZvbs2Ve9PmHChJ64FSKrVt9gxPE8LQBOfqbOG9vPH4B5OxV9faPI1RC1j+gB6PPPP0dycjIWL16Mo0ePIjo6GomJiSguLm6x/aZNm1BYWGg5Tp06BZlMhmnTpjVrN2HChGbtPvvss564HSKrdjxfC4PRBD93BcJ9OfmZOifczw1hPq5oMAo4cIlPg5FtET0Avf3223jssccwZ84cDBw4ECtXroSrqytWr17dYnsfHx+o1WrLsXPnTri6ul4VgBQKRbN23t6t73NUX18PnU7X7CCyN4Ig4GCW+YfUiHBvTn6mLjG2n3kYbA/nAZGNETUAGQwGHDlyBAkJCZZzUqkUCQkJSEtLa9M1Vq1ahQceeABubm7NzqempiIgIABRUVF48sknUVbW+m8nS5cuhUqlshyhoaEduyEiK5ZbXmOZ/MyNT6mr3NzfPAz284VSkSshah9RA1BpaSmMRiMCAwObnQ8MDIRGo7nu+w8dOoRTp07h0UcfbXZ+woQJWL9+PVJSUvDGG29g9+7dSEpKgtFobPE6CxcuhFartRx5eXkdvykiK9U0RBHdy4uTn6nLxEf6wkkqwaVSPXLLuC0G2Q6b/hRctWoVhgwZgpEjRzY7/8ADD1j+/5AhQzB06FBERkYiNTUVt91221XXUSgUUCgU3V4vkViq6hpwqsA8tHtTH1+RqyF74ql0xvBwbxy4VI6fzhVj1qhwsUsiahNRe4D8/Pwgk8lQVFTU7HxRURHUavU136vX67Fx40Y88sgj1/06ffr0gZ+fHzIzMztVL5GtOpxTAaMgINTbBSHeLmKXQ3ZmfFQAAGDX2ZYfXiGyRqIGILlcjmHDhiElJcVyzmQyISUlBfHx8dd875dffon6+nr84Q9/uO7Xyc/PR1lZGYKCgjpdM5GtMZoEHLqy8Sl7f6g73DrAHIDSLpWhxsDH4ck2iP4UWHJyMj766COsW7cOGRkZePLJJ6HX6zFnzhwAwMyZM7Fw4cKr3rdq1SpMnToVvr7NP9Crq6vx17/+FQcOHEB2djZSUlIwZcoU9O3bF4mJiT1yT0TWJKNQB21tA1zlMgwOUYldDtmhvgHuCPFygaHRxN3hyWaIPgdo+vTpKCkpwaJFi6DRaBATE4Pt27dbJkbn5uZCKm2e086dO4e9e/dix44dV11PJpPhxIkTWLduHSorKxEcHIw77rgDr776Kuf5kEM6YHn03QfOMtF/5yE7JJFIcOuAAHxyIAe7zhbjthsCr/8mIpGJHoAAYN68eZg3b16Lr6Wmpl51LioqCoLQ8u7DLi4u+OGHH7qyPCKbVayrw6USPSQARkZw5WfqPuMH+OOTAzlIPVcCQRC4zhRZPf46SGTHDlyZ+zNA7QFvV7nI1ZA9i+/jB4WTFAWVtThfVC12OUTXxQBEZKfqG4w4llsBgJOfqfu5yGUYFWn+d/ZjRtF1WhOJjwGIyE4dya1AfaMJfu5yRAa4i10OOYCEgea5PzvOMACR9WMAIrJDJkHAvkzz1gSj+/pByvkY1ANuvzL5+XheJYp0dSJXQ3RtDEBEdujMZR0qahrg4ixDbCj3/aKeEeCpREyoFwAOg5H1YwAiskNNvT9xfXwgd+K3OfWc25uGwU4zAJF14ycjkZ3JK69BTnkNZBIJJz9Tj0scZA5AaRfLUF3PVaHJejEAEdmZvVd6f6JDVfBUOotcDTmaSH93RPi5wWA0Yfe5ErHLIWoVAxCRHamoMeD0ZS0A8+Rnop4mkUgsw2DbT2tEroaodQxARHYk7WIZTAIQ6e+GIBV3fSdxTBisBgDsyihCXYNR5GqIWsYARGQn6hqM+CXbvPLzGPb+kIhiQ70QrFJCbzBiz3kOg5F1YgAishOHc8wLH/q7K9Av0EPscsiBSSQSTBgcBADYdrJQ5GqIWsYARGQH6huNlkffx3DhQ7ICk4aah8F+zChGfSOHwcj6MAAR2YFNRwugrW2Ap9IJsWFeYpdDhNhQb6g9laiub8TP50vFLofoKgxARDau0WjCB6kXAQBj+/nDScZvaxKfVCqxTIbmMBhZI35SEtm4b09cRm55DVzlMowI9xG7HCKLSUPN84B2nOHTYGR9GICIbJjJJGDFT+benzF9/bjtBVmVYWHeCFaZh8FSMorFLoeoGX5aEtmwH05rkFlcDQ+lE7e9IKsjlUpwV0wIAGBzeoHI1RA1xwBEZKMEQcD7P2UCAGaPCofSWSZyRURXmxobDABIPVeMyhqDyNUQ/YoBiMhGpZ4vwenLOrjKZZgzOkLscohaNEDtiQFqDzQYBXx/iltjkPVgACKyQYIg4P1d5t6fh+LC4OMmF7kiotZNjb0yDHaMw2BkPRiAiGzQ3sxSHMmpgNxJisfG9hG7HKJruis6GBIJcDCrHPkVNWKXQwSAAYjI5giCgDe3nwMAPDgyDAGeSpErIrq2YC8XxF+ZpP/VEfYCkXVgACKyMd+f0uBkgRZuchnm3dpX7HKI2mT6iFAAwJdH8mAyCSJXQ8QARGRTGo0mvLXD3PvzyNg+8HNXiFwRUdskDlLDQ+mE/IpapF0qE7scIgYgIlvy1dF8XCrRw9vVGY+N5ZNfZDuUzjJMiTE/Ev/F4TyRqyFiACKyGXUNRiz/8QIAYO74vvBQOotcEVH73D/cPAz2/SkNtDUNIldDjo4BiMhGfJKWg0JtHYJVSvzhpt5il0PUbkNCVBig9oCh0cSVoUl0DEBENkBX14B/p5rX/XkmoT9XfSabJJFIMGNkGADgkwM5EAROhibxMAAR2YCP9lxCRU0DIv3dcM+NIWKXQ9Rh99wYAle5DJnF1ZwMTaJiACKycgWVtfhwzyUAwF8To+Ak47ct2S4PpTPuvrIy9CdpOSJXQ47MKj5JV6xYgfDwcCiVSsTFxeHQoUOttl27di0kEkmzQ6lsvhCcIAhYtGgRgoKC4OLigoSEBFy4cKG7b4OoW7z+/VnUN5owMsIHiYPUYpdD1Gkz48MBADvOFEGjrRO3GHJYogegzz//HMnJyVi8eDGOHj2K6OhoJCYmori4uNX3eHp6orCw0HLk5DT/LeLNN9/Eu+++i5UrV+LgwYNwc3NDYmIi6ur4jUa25XB2Ob49fhkSCbDozoGQSCRil0TUaVFqD4yM8IHRJGDDQfYCkThED0Bvv/02HnvsMcyZMwcDBw7EypUr4erqitWrV7f6HolEArVabTkCAwMtrwmCgOXLl+PFF1/ElClTMHToUKxfvx6XL1/G5s2bW7xefX09dDpds4NIbEaTgFe+PQMAmD48FINDVCJXRNR1Zl3pBfrvwVzUGoziFkMOSdQAZDAYcOTIESQkJFjOSaVSJCQkIC0trdX3VVdXo3fv3ggNDcWUKVNw+vRpy2tZWVnQaDTNrqlSqRAXF9fqNZcuXQqVSmU5QkNDu+DuiDpnw6FcnCzQwkPhhOfuiBK7HKIulTgoEL28XVCuN+B/R/PFLocckKgBqLS0FEajsVkPDgAEBgZCo9G0+J6oqCisXr0a33zzDf773//CZDJh1KhRyM83fwM1va8911y4cCG0Wq3lyMvjKqUkrpKqery5/SwAYH5iFPw9uOUF2RcnmRSPjjGvZr7q50swcn8w6mGiD4G1V3x8PGbOnImYmBiMGzcOmzZtgr+/P/7zn/90+JoKhQKenp7NDiIxLd2Wgaq6RgwO8eSih2S3pg0PhcrFGdllNdh5pkjscsjBiBqA/Pz8IJPJUFTU/B9+UVER1Oq2Pe3i7OyM2NhYZGaaF4lrel9nrkkkpv2Zpdh0rAASCbBk6hDIpJz4TPbJTeGEP9xkXhjxP3sucmFE6lGiBiC5XI5hw4YhJSXFcs5kMiElJQXx8fFtuobRaMTJkycRFBQEAIiIiIBarW52TZ1Oh4MHD7b5mkRiqTE04m+bTgAA/hDXGzGhXuIWRNTNZo0Kh8JJimO5ldibWSp2OeRARB8CS05OxkcffYR169YhIyMDTz75JPR6PebMmQMAmDlzJhYuXGhp/49//AM7duzApUuXcPToUfzhD39ATk4OHn30UQDmJ8SeeeYZLFmyBFu2bMHJkycxc+ZMBAcHY+rUqWLcIlGbvfXDeeSV1yJYpcTzEzjxmexfgIfSsj3GOz9eYC8Q9RgnsQuYPn06SkpKsGjRImg0GsTExGD79u2WScy5ubmQSn/NaRUVFXjssceg0Wjg7e2NYcOGYf/+/Rg4cKClzfPPPw+9Xo/HH38clZWVGDNmDLZv337VgolE1uRITgXW7M8CAPzzniHc7Z0cxpO3RGLDoVwczqnA/otlGN3XT+ySyAFIBMbtq+h0OqhUKmi1Wk6Iph5RY2jExHd+RnZZDe6JDcHb02PafY0NB3O7vjByeA/GhfXI13l5y2ms3Z+NEeHe+OJP8Vz0kzqkPT+/RR8CIyJgyXcZyC6rQZBKicWTB4ldDlGPe2JcJOROUvySXYHd50vELoccAAMQkch2nS2y9N68NS0aKlcOfZHjUauUmHllyYfXvz/LdYGo2zEAEYlIo63D/C/NT309MiaCcx/Ioc0d3xceSiec1VRh87ECscshO8cARCSSRqMJf/nsGMr1BgwM8sRfE/nUFzk2bzc55o7vCwBYtuMc6hq4Rxh1HwYgIpEs//ECDmWXw00uw4qHboTSWSZ2SUSimz0qHMEqJS5r6/Dxz5fELofsGAMQkQh2nNbg/Z/Mq5cvvXcoIvzcRK6IyDoonWV4fsIAAMD7P2Uiv6JG5IrIXjEAEfWwC0VVePbzdADArPjeuCs6WNyCiKzMlJhgjIzwQV2DCUu2ZohdDtkpBiCiHlRZY8Bj6w9DbzDipj4+ePHOgdd/E5GDkUgkeHXKYMikEmw/rUHquWKxSyI7xABE1EPqG414/JMjyC6rQYiXC1Y8eCOcZfwWJGpJlNoDs0eFAwBe3HwK+vpGcQsiu8NPX6IeYDIJ+OuXJ3AoqxweCiesmj0cvu4KscsismrP3t4fIV4uyK+oxZvbz4pdDtkZBiCibiYIAl7ffhZbjl+Gk1SCD/4wDAPU3GKF6HrcFU54/d4hAIB1aTk4eKlM5IrInjAAEXWz93dl4sM95sd5X793KMb042KHRG01tp8/HhgRCgB4/qsTqOZQGHURBiCibrRqbxaW7TwPAHjpzoG4b1gvkSsisj0vTLoBIV4uyCmrwaLNp8Quh+wEAxBRN/lozyW8uvUMACD59v54ZEyEyBUR2SZPpTOWPxADqQTYdKwAm47mi10S2QEGIKJusOKnTPxzm3n9knnj++KpW/uKXBGRbRsR7oNnEvoDAF7afAqZxdUiV0S2jgGIqAuZTAKWbD2D//vhHABzz8/8xChIJBKRKyOyfXPH98VNfXygNxjx+CeHUVXXIHZJZMMYgIi6iKHRhOQv0vHx3iwAwAsTB+Avt/UTuSoi+yGTSvDejBsRpFLiUokez35+HCaTIHZZZKMkgiDwX8/v6HQ6qFQqaLVaeHrycWV7tuFgbpdcR1/fiE8P5iK7TA+pBLj3xl6IDfPukmsTUXP5FTX4cM8lNJoE3NLfH3cMUrfpfQ/GhXVzZSS29vz8Zg8QUScV6erwwe6LyC7TQ+Ekxcz4cIYfom7Uy9sVU2NDAACp50vwS1a5yBWRLXISuwAiW3Y0pwLfHC9Ag1GAt6szZsaHI9BTKXZZRHbvxjBvlOsN2HW2GN8cL4CnizOi1B5il0U2hD1ARB1gaDThqyP5+N/RfDQYBfT1d8eTt/Rl+CHqQbcNCEBsqBdMArDhUA6ySvVil0Q2hAGIqJ2KdXX4d2omjuRWQAIg4YZAzB4dDncFO1SJepJEIsHdN4YgKtADDUYB69OykV9RI3ZZZCMYgIjayCQI2H+xFCtSM1FcVQ8PhRP+OCYCtw4IgJSPuROJwkkqxYNxYYjwc0N9owmr92Uht5whiK6PAYioDcr1Bqzam4WtJwrRYBQQ6e+Gebf2RaS/u9ilETk8Z5kUM2/qjTAfV9Q1mLB6bxYulnChRLo2BiCiazAJAg5cKsO7KReQVaqHs0yCu6KDMWd0BDyUzmKXR0RXKJxlmDM6HH393WEwmrBufzYyCnVil0VWjAGIqBUaXR0+/jkLW45fhsFoQoSfG56+rT9u6uPLIS8iK6RwkuHh+N4YGOSJRpOATw/mID2vUuyyyEpx1ibR79Q3GrHrbDH2ZZbCJADOMgkSB6kZfIhsgLNMihkjw7DpaD6O5VXiy8N50Nc3YlSkr9ilkZVhACK6QhAEnL6sw3cnC6GtNe8xNDDIE3cODYKXq1zk6oiorWRSCe4d1gtyJykOZpXju5OFKKmux/0jQuEs48AHmTEAEQEoq67Htycu43yReeKkt6szJkcHY4CaW6EQ2SKpxDxfz9tVjh9Oa3Aoqxyz1xzCvx8cBpUr5+8RAxA5uAajCT9fKEHquRI0mgTIpBLc3M8P4/oHQO7E3xSJbJlEIsHN/f3h76HA57/kYV9mGe7+9z6smj0CEX5uYpdHIrOKT/gVK1YgPDwcSqUScXFxOHToUKttP/roI4wdOxbe3t7w9vZGQkLCVe1nz54NiUTS7JgwYUJ33wbZmD3nS/BuygX8mFGMRpN5Nee/3NoPtw9UM/wQ2ZEbgjzxp3F9EKxS4lKpHlPe34uUjCKxyyKRif4p//nnnyM5ORmLFy/G0aNHER0djcTERBQXF7fYPjU1FTNmzMBPP/2EtLQ0hIaG4o477kBBQUGzdhMmTEBhYaHl+Oyzz3ridsgGaLR1mLvhKGauPoQyvQEeSic8MCIUc0aHw99DIXZ5RNQNglQu2DxvNG4M84KurhGPrDuM//vhLIwmQezSSCQSQRBE/duPi4vDiBEj8P777wMATCYTQkND8dRTT2HBggXXfb/RaIS3tzfef/99zJw5E4C5B6iyshKbN2/uUE06nQ4qlQparRaenpwDYi+MJvNS+ct2nEd1fSOkEiC+jy9uuyEQSmeZ2OURUTd7MC4MhkYTXtuWgbX7swEAo/v64p0HYuHnzl9+7EF7fn6L2gNkMBhw5MgRJCQkWM5JpVIkJCQgLS2tTdeoqalBQ0MDfHx8mp1PTU1FQEAAoqKi8OSTT6KsrKzVa9TX10On0zU7yL6czNdi6op9eOXbM6iub0RsmBe+fWoMJg0NZvghciByJylevmsQ3p0RC1e5DPsyy3Dnu3txJKdc7NKoh4kagEpLS2E0GhEYGNjsfGBgIDQaTZuu8be//Q3BwcHNQtSECROwfv16pKSk4I033sDu3buRlJQEo9HY4jWWLl0KlUplOUJDQzt+U2RVqusb8cq3pzFlxV6cLNDCU+mEf949GF89MQqDglVil0dEIrkrOhjfzB2NSH83aHR1mP6fA1i9NwsiD4pQD7Lpp8Bef/11bNy4EampqVAqlZbzDzzwgOX/DxkyBEOHDkVkZCRSU1Nx2223XXWdhQsXIjk52fJnnU7HEGTjBEHAD6c1eHnLGWh0dQCAKTHBeHHSQM7zISIAQL9AD3wzbwwWfHUCW08U4h9bz+BwTjlev3coPLnVjd0TNQD5+flBJpOhqKj5bPyioiKo1eprvvett97C66+/jh9//BFDhw69Zts+ffrAz88PmZmZLQYghUIBhYI/FO1Fsa4Of998CjvPmP9d9fZ1xatTBuPm/v4iV0ZE1sZd4YT3ZsRieG9vLPkuA9tOanCqQIf3ZsQiOtRL7PKoG4k6BCaXyzFs2DCkpKRYzplMJqSkpCA+Pr7V97355pt49dVXsX37dgwfPvy6Xyc/Px9lZWUICgrqkrrJOgmCgM3HCnD7v/Zg55kiOMskmDe+L3545maGHyJqlUQiwezREfjyiXj08nZBbnkN7lu5H6s4JGbXRH8MPjk5GR999BHWrVuHjIwMPPnkk9Dr9ZgzZw4AYObMmVi4cKGl/RtvvIGXXnoJq1evRnh4ODQaDTQaDaqrzSv4VldX469//SsOHDiA7OxspKSkYMqUKejbty8SExNFuUfqfsW6Ojy2/gie+Twd2toGDA7xxLdPjcH8xChOciaiNokN88Z3fxmLCYPUaDAKeHXrGTy2/ggqawxil0bdQPQ5QNOnT0dJSQkWLVoEjUaDmJgYbN++3TIxOjc3F1Lprzntgw8+gMFgwH333dfsOosXL8bLL78MmUyGEydOYN26daisrERwcDDuuOMOvPrqqxzmskOCIOCb9MtYvOU0tLUNcJZJ8PRt/fCncZHc84eI2k3l4owP/nAj/nsgB69uzcCPGUWY+M7PeHdGLIaH+1z/AmQzRF8HyBpxHSDbUFxVhxc2ncKPV1Z0HRziibemRbdr/64NB3O7qzwisjIPxoW1q/2pAi2e+uwYskr1kEkleO6O/nji5khIpZJuqpA6y2bWASLqqJSMIiQt/xk/Zpjn+sy/oz++/vNobl5KRF1mcIgK3z41BlNigmE0CXhz+znMWnMIpdX1YpdGXYABiGxKXYMRi745hUfWHUaZ3oAbgsxzfebd2o9DXkTU5dwVTlg+PQZv3jsUSmcpfr5Qionv/Iy0i60vrku2gT8xyGZkFOpw1/t7sT4tBwDw6JgIbJ47ir0+RNStJBIJ7h8Rii3zxqBfgDuKq+rx0McHsPzH89xLzIYxAJHVEwQBa/ZlYcqKfThfVA1/DwXW/3EkXrxzIBROfMKLiHpG/0APbJk3BtOHh8IkAMt/vICHPj6AoiuLrZJtYQAiq1ZSVY85a3/BK9+egaHRhNsGBGD702O5rg8RicJFLsMb9w3F8ukxcJPLcOBSOSa+8zN2ny8RuzRqJwYgslo/nS1G0jt7kHquBAonKf4xZRA+njUcvty1mYhENjU2BN8+NQYDgzxRpjdg1upDeP37s2gwmsQujdqIAYisTl2DES9vOY05a39BabUBA9Qe+PapMZgZHw6JhI+fEpF16OPvjk1/HoWZ8b0BACt3X8T0/6ShoLJW5MqoLRiAyKqc01Rhyvv7sHZ/NgBgzuhwbJ47Gv0DPcQtjIioBUpnGf4xZTA+eOhGeCidcDS3EhPf+Rk7TmvELo2ugwGIrIIgCFi3PxuT39+Lc0VV8HOXY82cEVg8eRC3siAiq5c0JAjb/jIW0aFe0NY24PFPjuCVb0+jvtEodmnUCgYgEl1pdT0eWXcYi7echqHRhFui/PH90zdjfFSA2KUREbVZqI8rvvxTPB4bGwEAWLMvG/d9kIacMr3IlVFLGIBIVD+dLcaE5Xuw62wx5E5SvDx5INbMHgF/D050JiLbI3eS4u+TBmL17OHwdnXGyQItJr27F1tPXBa7NPodBiASRa3BiJc2n7JMdI4K9MCWeaMxe3QEJzoTkc27dUAgtj09FiPDfVBd34h5G47h+f8dR3V9o9il0RUMQNTjTl/WYvL7e/HJAfOKzn8cHYFv5nEfLyKyL0EqF2x4LA7zxveFRAJ8cTgfE9/5GUdyysUujcAARD3IZBLwn90XMXXFPmQW/7qi86LJAznRmYjskpNMivmJUdj42E0I8XJBbnkNpq1Mw//9cBaGRq4ZJCYGIOoReeU1eOjjg1j6/Vk0GAXcMTAQPzxzM1d0JiKHENfHF98/Mxb33BgCkwCs+Oki7vlgHzKLq8QuzWExAFG3MpkEfHIgB4nL9yDtUhlcnGV4/Z4h+M/Dw+DjJhe7PCKiHuOpdMbb98fg3w/dCC9XZ5wq0GHSu3uxdl8WTNxUtcc5iV0A2a/8ihr87asT2JdZBgAYGe6DN+8binA/N5ErIyISz8QhQRjW2xvzvzyOny+U4uVvz2DbKQ3euHcoIvj52GPYA0RdzmgyL2qY+K892JdZBqWzFIsnD8TGx29i+CEiAhDoqcT6P47EK3cNgouzDIeyyjFh+R6s3H0RjdxPrEewB4i61KkCLV74+iRO5GsBACPCvfF/90Uz+BAR/Y5EIsGsUeG4dUAAXvj6JH6+UIrXvz+LrScu4/V7hmJwiErsEu0aAxB1iaq6BizbcR7r07JhEgAPpROenzAAD44Mg0zKdX2IiFoT6uOK9X8cia+OFuDVrWdwqkCHu97fi4fieuO5O/rDy5XzJbsDAxB1itEk4Kuj+Xjrh3MorqoHAEyODsZLd96AAA+lyNUREdkGiUSC+4b1ws39/fDq1gx8e/wyPjmQg60nLmN+YhQeGMFfJrsaAxB12P7MUiz5LgNnCnUAgN6+rnh1ymA+2k5E1EEBHkq8NyMWD44Mw8tbTuNcURX+/vUpfHYoFy8k3YBRff3ELtFuMABRu50vqsKb28/hx4wiAObhrqdu7YtZo8KhcOKChkREnRUf6Yvv/jIGnxzIwds7z+NUgQ4PfnwQY/v54a+JURjay0vsEm0eAxC12TlNFd5NuYBtpwohCIBMKsEf4sLwdEJ/rulDRNTFnGRSzBkdgcnRwXgv5QI2HMrFzxdK8fOFUiQNVuO5O/qjb4CH2GXaLIkgCFx96Xd0Oh1UKhW0Wi08Pbk/VUahDu/tuoBtJzWWc+Zvvij0DXAXsbLO23AwV+wSiKiHPBgXJnYJnZJXXoN/7TyPr9ML0PST+/aBgXhiXCSG9fYWtzgr0Z6f3+wBohYZTQJSMoqwdn829l8ss5yfNCQIT93WlxuXEhH1sFAfV7w9PQZ/GheJt3eeww+ni7DzjPkYEe6NJ8ZFYnxUAKScLN0mDEDUTIXegP8dyce6tGzkV9QCAKQS88qlT93aD1FqdrcSEYkpSu2B/zw8HJnF1fhozyVsOpaPX7Ir8Ev2YfTydsH04aGYNjwUahWfxL0WDoG1wNGGwOoajNh1thibjhYg9VwxGq/sSePl6owZI8Pwh5t6I8TLReQquweHwIgch60PgbWmSFeH1fuy8NnBXOjqGgGYf3G9dUAApg0Pxbj+/lA6O8YDKu35+c0A1AJHCEC1BiP2ZZZi55kibDtViKor3zQAMDjEEw/f1BtTYkLs/puGAYjIcdhrAGpS12DEtpOF2HgoD4eyyy3n3eQy3HZDICYOUeOWqAC7/lznHCC6iiAIyCuvxc+ZJUjJKMa+zFLUN/6630ywSokpsSG4JzYE/QI5zEVEZGuUzjLcc2Mv3HNjL2QWV+OLw3nYevwyLmvrsOX4ZWw5fhkuzjLER/piTF8/jO3nh74B7pBIHHPOEHuAWmAPPUCNRhMyS6rxS3YFDmWV41BWGYp09c3ahHi5IOGGACQOVuOmCF+HnDjHHiAix2HvPUAtEQQB6XmV2HayENtOalBQWdvsdbWnEvGRvogJ9UJMqBduCPKE3Ml290m3uSGwFStW4P/+7/+g0WgQHR2N9957DyNHjmy1/ZdffomXXnoJ2dnZ6NevH9544w1MnDjR8rogCFi8eDE++ugjVFZWYvTo0fjggw/Qr1+/NtVjSwFIEASUVNcjq0SPC8XVOH1ZhzOXtTirqWrWwwMAzjIJont5YfyAANx2QwCiAj0cNvk3YQAichyOGIB+SxAEnCnUYe+FUuzNLMWhrPKrfk7IZVIMDPbEDUEe6B9oPvoFusPfXWETPy9sagjs888/R3JyMlauXIm4uDgsX74ciYmJOHfuHAICAq5qv3//fsyYMQNLly7FnXfeiQ0bNmDq1Kk4evQoBg8eDAB488038e6772LdunWIiIjASy+9hMTERJw5cwZKpW3Niq81GFFRY0BJVT0KtbW4XFkHja4OBZW1yCnTI7u0BtX1jS2+100uQ0yYF0aG+2JkhA9iw7zseuyXiIhaJ5FIMChYhUHBKvxpXCTqGow4nF2BwznlSM+rxPG8SlTUNCA9rxLpeZXN3uuhdEKotytCfVwQ6u2KXt4uCPRUws9DAV83Ofw8FPBQONlESGoieg9QXFwcRowYgffffx8AYDKZEBoaiqeeegoLFiy4qv306dOh1+uxdetWy7mbbroJMTExWLlyJQRBQHBwMJ577jnMnz8fAKDVahEYGIi1a9figQceuG5N3dUDdKmkGuc0VdAbjKg1NEJvMKKm/sr/GhpRVdeIypoGlOsNqKwxoLzGgLoG03WvK5UAId4u6OPnjkHBnhgUrMLAYE/09nF1yGGt9mAPEJHjcPQeoOsRBAE5ZTU4UaDFeU0VzhdV4UJxNXLK9DC1ISkonKTwc1fA110OT6Uz3BVOcFc6wV3hBA+l+XBTOMHFWQYXZxn6Brh3+ZxTm+kBMhgMOHLkCBYuXGg5J5VKkZCQgLS0tBbfk5aWhuTk5GbnEhMTsXnzZgBAVlYWNBoNEhISLK+rVCrExcUhLS2txQBUX1+P+vpf58dotVoA5v+QXemrAxfx3q7Mdr/PWSaBt6scapUSak8FAlUuUHsq0MvbFeF+rujl7drCHlxGVFdXdU3hdqxGz/9GRI6iqz/T7ZGPHLglwh23RLgDCAJgfrosv6IG+RW1KKioQX5lHS5X1qC0yvyLell1PWoMJtTWA3n6auQVte1rzRkTjuduj+rS+pv+jtvStyNqACotLYXRaERgYGCz84GBgTh79myL79FoNC2212g0ltebzrXW5veWLl2KV1555arzoaGhbbsRIiKyeo+JXQA184/lwD+66dpVVVVQqVTXbCP6HCBrsHDhwma9SiaTCeXl5fD19bWp8czW6HQ6hIaGIi8vz+ondXeUvd8j78/22fs98v5sm73cnyAIqKqqQnBw8HXbihqA/Pz8IJPJUFTUvL+sqKgIarW6xfeo1eprtm/636KiIgQFBTVrExMT0+I1FQoFFApFs3NeXl7tuRWb4OnpadP/sNvC3u+R92f77P0eeX+2zR7u73o9P01EfdhfLpdj2LBhSElJsZwzmUxISUlBfHx8i++Jj49v1h4Adu7caWkfEREBtVrdrI1Op8PBgwdbvSYRERE5FtGHwJKTkzFr1iwMHz4cI0eOxPLly6HX6zFnzhwAwMyZMxESEoKlS5cCAJ5++mmMGzcOy5Ytw6RJk7Bx40YcPnwYH374IQDzY37PPPMMlixZgn79+lkegw8ODsbUqVPFuk0iIiKyIqIHoOnTp6OkpASLFi2CRqNBTEwMtm/fbpnEnJubC6n0146qUaNGYcOGDXjxxRfxwgsvoF+/fti8ebNlDSAAeP7556HX6/H444+jsrISY8aMwfbt221uDaCuolAosHjx4quG+eyJvd8j78/22fs98v5sm73fX0tEXweIiIiIqKfZ7oYfRERERB3EAEREREQOhwGIiIiIHA4DEBERETkcBiA7VV5ejoceegienp7w8vLCI488gurq6ja9VxAEJCUlQSKRWPZYszbtvb/y8nI89dRTiIqKgouLC8LCwvCXv/zFsu+bNVixYgXCw8OhVCoRFxeHQ4cOXbP9l19+iQEDBkCpVGLIkCHYtm1bD1XaMe25v48++ghjx46Ft7c3vL29kZCQcN3/HmJr799fk40bN0IikdjEMh3tvcfKykrMnTsXQUFBUCgU6N+/v1X/O23v/S1fvtzymRIaGopnn30WdXV1PVRt++zZsweTJ09GcHBwmz/bU1NTceONN0KhUKBv375Yu3Ztt9fZowSySxMmTBCio6OFAwcOCD///LPQt29fYcaMGW1679tvvy0kJSUJAISvv/66ewvtoPbe38mTJ4V77rlH2LJli5CZmSmkpKQI/fr1E+69994erLp1GzduFORyubB69Wrh9OnTwmOPPSZ4eXkJRUVFLbbft2+fIJPJhDfffFM4c+aM8OKLLwrOzs7CyZMne7jytmnv/T344IPCihUrhGPHjgkZGRnC7NmzBZVKJeTn5/dw5W3T3vtrkpWVJYSEhAhjx44VpkyZ0jPFdlB777G+vl4YPny4MHHiRGHv3r1CVlaWkJqaKqSnp/dw5W3T3vv79NNPBYVCIXz66adCVlaW8MMPPwhBQUHCs88+28OVt822bduEv//978KmTZva9Nl+6dIlwdXVVUhOThbOnDkjvPfee4JMJhO2b9/eMwX3AAYgO3TmzBkBgPDLL79Yzn3//feCRCIRCgoKrvneY8eOCSEhIUJhYaHVBqDO3N9vffHFF4JcLhcaGhq6o8x2GTlypDB37lzLn41GoxAcHCwsXbq0xfb333+/MGnSpGbn4uLihD/96U/dWmdHtff+fq+xsVHw8PAQ1q1b110ldkpH7q+xsVEYNWqU8PHHHwuzZs2y+gDU3nv84IMPhD59+ggGg6GnSuyU9t7f3LlzhVtvvbXZueTkZGH06NHdWmdXaMtn+/PPPy8MGjSo2bnp06cLiYmJ3VhZz+IQmB1KS0uDl5cXhg8fbjmXkJAAqVSKgwcPtvq+mpoaPPjgg1ixYkWre7FZg47e3+9ptVp4enrCyUnc9UANBgOOHDmChIQEyzmpVIqEhASkpaW1+J60tLRm7QEgMTGx1fZi6sj9/V5NTQ0aGhrg4+PTXWV2WEfv7x//+AcCAgLwyCOP9ESZndKRe9yyZQvi4+Mxd+5cBAYGYvDgwXjttddgNBp7quw268j9jRo1CkeOHLEMk126dAnbtm3DxIkTe6Tm7mZLnzEdJfpK0NT1NBoNAgICmp1zcnKCj48PNBpNq+979tlnMWrUKEyZMqW7S+yUjt7fb5WWluLVV1/F448/3h0ltktpaSmMRqNl9fMmgYGBOHv2bIvv0Wg0LbZv6/33pI7c3+/97W9/Q3Bw8FUfyNagI/e3d+9erFq1Cunp6T1QYed15B4vXbqEXbt24aGHHsK2bduQmZmJP//5z2hoaMDixYt7ouw268j9PfjggygtLcWYMWMgCAIaGxvxxBNP4IUXXuiJkrtda58xOp0OtbW1cHFxEamyrsMeIBuyYMECSCSSax5t/YHye1u2bMGuXbuwfPnyri26Hbrz/n5Lp9Nh0qRJGDhwIF5++eXOF07d6vXXX8fGjRvx9ddf28V2NlVVVXj44Yfx0Ucfwc/PT+xyuo3JZEJAQAA+/PBDDBs2DNOnT8ff//53rFy5UuzSukRqaipee+01/Pvf/8bRo0exadMmfPfdd3j11VfFLo3aiD1ANuS5557D7Nmzr9mmT58+UKvVKC4ubna+sbER5eXlrQ5t7dq1CxcvXoSXl1ez8/feey/Gjh2L1NTUTlTeNt15f02qqqowYcIEeHh44Ouvv4azs3Nny+40Pz8/yGQyFBUVNTtfVFTU6v2o1ep2tRdTR+6vyVtvvYXXX38dP/74I4YOHdqdZXZYe+/v4sWLyM7OxuTJky3nTCYTAHNP5rlz5xAZGdm9RbdTR/4Og4KC4OzsDJlMZjl3ww03QKPRwGAwQC6Xd2vN7dGR+3vppZfw8MMP49FHHwUADBkyxLIH5d///vdme1jaotY+Yzw9Pe2i9wdgD5BN8ff3x4ABA655yOVyxMfHo7KyEkeOHLG8d9euXTCZTIiLi2vx2gsWLMCJEyeQnp5uOQDgX//6F9asWdMTt9et9weYe37uuOMOyOVybNmyxWp6E+RyOYYNG4aUlBTLOZPJhJSUFMTHx7f4nvj4+GbtAWDnzp2tthdTR+4PAN588028+uqr2L59e7P5Xtamvfc3YMAAnDx5stn32l133YXx48cjPT0doaGhPVl+m3Tk73D06NHIzMy0hDsAOH/+PIKCgqwq/AAdu7+ampqrQk5T2BPsYItNW/qM6TCxZ2FT95gwYYIQGxsrHDx4UNi7d6/Qr1+/Zo+J5+fnC1FRUcLBgwdbvQas9CkwQWj//Wm1WiEuLk4YMmSIkJmZKRQWFlqOxsZGsW7DYuPGjYJCoRDWrl0rnDlzRnj88ccFLy8vQaPRCIIgCA8//LCwYMECS/t9+/YJTk5OwltvvSVkZGQIixcvtvrH4Ntzf6+//rogl8uF//3vf83+rqqqqsS6hWtq7/39ni08Bdbee8zNzRU8PDyEefPmCefOnRO2bt0qBAQECEuWLBHrFq6pvfe3ePFiwcPDQ/jss8+ES5cuCTt27BAiIyOF+++/X6xbuKaqqirh2LFjwrFjxwQAwttvvy0cO3ZMyMnJEQRBEBYsWCA8/PDDlvZNj8H/9a9/FTIyMoQVK1bwMXiyDWVlZcKMGTMEd3d3wdPTU5gzZ06zHx5ZWVkCAOGnn35q9RrWHIDae38//fSTAKDFIysrS5yb+J333ntPCAsLE+RyuTBy5EjhwIEDltfGjRsnzJo1q1n7L774Qujfv78gl8uFQYMGCd99910PV9w+7bm/3r17t/h3tXjx4p4vvI3a+/f3W7YQgASh/fe4f/9+IS4uTlAoFEKfPn2Ef/7zn1bxC0dr2nN/DQ0NwssvvyxERkYKSqVSCA0NFf785z8LFRUVPV94G7T2Gdh0T7NmzRLGjRt31XtiYmIEuVwu9OnTR1izZk2P192dJIJgB311RERERO3AOUBERETkcBiAiIiIyOEwABEREZHDYQAiIiIih8MARERERA6HAYiIiIgcDgMQERERORwGICIiInI4DEBERETUI/bs2YPJkycjODgYEokEmzdvbtf7X375ZUgkkqsONze3dtfCAEREREQ9Qq/XIzo6GitWrOjQ++fPn4/CwsJmx8CBAzFt2rR2X4sBiIiIiHpEUlISlixZgrvvvrvF1+vr6zF//nyEhITAzc0NcXFxSE1Ntbzu7u4OtVptOYqKinDmzBk88sgj7a6FAYiIiIiswrx585CWloaNGzfixIkTmDZtGiZMmIALFy602P7jjz9G//79MXbs2HZ/LQYgIiIiEl1ubi7WrFmDL7/8EmPHjkVkZCTmz5+PMWPGYM2aNVe1r6urw6efftqh3h8AcOpswURERESddfLkSRiNRvTv37/Z+fr6evj6+l7V/uuvv0ZVVRVmzZrVoa/HAERERESiq66uhkwmw5EjRyCTyZq95u7uflX7jz/+GHfeeScCAwM79PUYgIiIiEh0sbGxMBqNKC4uvu6cnqysLPz000/YsmVLh78eAxARERH1iOrqamRmZlr+nJWVhfT0dPj4+KB///546KGHMHPmTCxbtgyxsbEoKSlBSkoKhg4dikmTJlnet3r1agQFBSEpKanDtUgEQRA6dTdEREREbZCamorx48dfdX7WrFlYu3YtGhoasGTJEqxfvx4FBQXw8/PDTTfdhFdeeQVDhgwBAJhMJvTu3RszZ87EP//5zw7XwgBEREREDoePwRMREZHDYQAiIiIih8MARERERA6HAYiIiIgcDgMQERERORwGICIiInI4DEBERETkcBiAiIiIyOEwABEREZHDYQAiIiIih8MARERERA7n/wGeKob+FCXIuAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if the prediction distribution are far from normal distribution\n",
    "# then the model is not probably good enough\n",
    "# distplot is deprecating in future pandas-version\n",
    "# unfortunately, there's no exact alternative to do this plot at the moment\n",
    "sns.distplot((y_test - test_predictions))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Lets' try the model in practice</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['area', 'bathrooms', 'stories', 'guestroom', 'basement',\n",
       "       'hotwaterheating', 'airconditioning', 'parking', 'prefarea',\n",
       "       'furnishing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bathrooms  stories  guestroom  basement  hotwaterheating  \\\n",
       "0  13300000  7420          2        3          0         0                0   \n",
       "1  12250000  8960          4        4          0         0                0   \n",
       "2  12250000  9960          2        2          0         1                0   \n",
       "3  12215000  7500          2        2          0         1                0   \n",
       "4  11410000  7420          1        2          1         1                0   \n",
       "\n",
       "   airconditioning  parking  prefarea  furnishing  \n",
       "0                1        2         1           1  \n",
       "1                1        3         0           1  \n",
       "2                0        2         1           1  \n",
       "3                1        3         1           1  \n",
       "4                1        2         0           1  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try with some new imaginary data\n",
    "# this example uses the student performance index score dataset\n",
    "# modify this as needed regarding your own dataset\n",
    "tester_row = {\n",
    "    'area': 8500,\n",
    "    'bedrooms': 4, \n",
    "    'bathrooms': 3, \n",
    "    'stories': 2,\n",
    "    'mainroad': 1, \n",
    "    'guestroom': 1,\n",
    "    'basement': 0, \n",
    "    'hotwaterheating': 1, \n",
    "    'airconditioning': 1, \n",
    "    'parking': 2, \n",
    "    'prefarea': 0,\n",
    "    'furnishingstatus_furnished': 0, \n",
    "    'furnishingstatus_semi-furnished': 0\n",
    "}\n",
    "\n",
    "# convert to pandas-format\n",
    "tester_row = pd.DataFrame([tester_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_6_1/batch_normalization_6_1/batchnorm/mul_1 defined at (most recent call last):\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/var/folders/19/0ldx1bc54jx5tvjkrsbcv4040000gn/T/ipykernel_23057/572768723.py\", line 1, in <module>\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 512, in predict\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 208, in one_step_on_data_distributed\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 198, in one_step_on_data\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 96, in predict_step\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 901, in __call__\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/models/sequential.py\", line 212, in call\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/models/functional.py\", line 175, in call\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/models/functional.py\", line 560, in call\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 901, in __call__\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/layers/normalization/batch_normalization.py\", line 268, in call\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/ops/nn.py\", line 1800, in batch_normalization\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py\", line 797, in batch_normalization\n\nIncompatible shapes: [1,13] vs. [10]\n\t [[{{node sequential_6_1/batch_normalization_6_1/batchnorm/mul_1}}]] [Op:__inference_one_step_on_data_distributed_591193]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[210], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtester_row\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimated price for this house:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_6_1/batch_normalization_6_1/batchnorm/mul_1 defined at (most recent call last):\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/var/folders/19/0ldx1bc54jx5tvjkrsbcv4040000gn/T/ipykernel_23057/572768723.py\", line 1, in <module>\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 512, in predict\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 208, in one_step_on_data_distributed\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 198, in one_step_on_data\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 96, in predict_step\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 901, in __call__\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/models/sequential.py\", line 212, in call\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/models/functional.py\", line 175, in call\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/models/functional.py\", line 560, in call\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 901, in __call__\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/layers/normalization/batch_normalization.py\", line 268, in call\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/ops/nn.py\", line 1800, in batch_normalization\n\n  File \"/Users/kirillsobolev/Documents/GitHub/Deep-Learning/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py\", line 797, in batch_normalization\n\nIncompatible shapes: [1,13] vs. [10]\n\t [[{{node sequential_6_1/batch_normalization_6_1/batchnorm/mul_1}}]] [Op:__inference_one_step_on_data_distributed_591193]"
     ]
    }
   ],
   "source": [
    "result = model.predict(tester_row)[0]\n",
    "\n",
    "print()\n",
    "print(f\"Estimated price for this house:\")\n",
    "print(f\"{round(float(result[0]), 2)} $\")\n",
    "print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
