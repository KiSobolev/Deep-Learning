{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('car_price_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Price</th>\n",
       "      <th>Levy</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Prod. year</th>\n",
       "      <th>Category</th>\n",
       "      <th>Leather interior</th>\n",
       "      <th>Fuel type</th>\n",
       "      <th>Engine volume</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Gear box type</th>\n",
       "      <th>Drive wheels</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Wheel</th>\n",
       "      <th>Color</th>\n",
       "      <th>Airbags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45654403</td>\n",
       "      <td>13328</td>\n",
       "      <td>1399</td>\n",
       "      <td>LEXUS</td>\n",
       "      <td>RX 450</td>\n",
       "      <td>2010</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>3.5</td>\n",
       "      <td>186005 km</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>4x4</td>\n",
       "      <td>04-May</td>\n",
       "      <td>Left wheel</td>\n",
       "      <td>Silver</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44731507</td>\n",
       "      <td>16621</td>\n",
       "      <td>1018</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>Equinox</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>No</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>3</td>\n",
       "      <td>192000 km</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Tiptronic</td>\n",
       "      <td>4x4</td>\n",
       "      <td>04-May</td>\n",
       "      <td>Left wheel</td>\n",
       "      <td>Black</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45774419</td>\n",
       "      <td>8467</td>\n",
       "      <td>-</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>FIT</td>\n",
       "      <td>2006</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>No</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>1.3</td>\n",
       "      <td>200000 km</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Variator</td>\n",
       "      <td>Front</td>\n",
       "      <td>04-May</td>\n",
       "      <td>Right-hand drive</td>\n",
       "      <td>Black</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45769185</td>\n",
       "      <td>3607</td>\n",
       "      <td>862</td>\n",
       "      <td>FORD</td>\n",
       "      <td>Escape</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>2.5</td>\n",
       "      <td>168966 km</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>4x4</td>\n",
       "      <td>04-May</td>\n",
       "      <td>Left wheel</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45809263</td>\n",
       "      <td>11726</td>\n",
       "      <td>446</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>FIT</td>\n",
       "      <td>2014</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>1.3</td>\n",
       "      <td>91901 km</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Front</td>\n",
       "      <td>04-May</td>\n",
       "      <td>Left wheel</td>\n",
       "      <td>Silver</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Price  Levy Manufacturer    Model  Prod. year   Category  \\\n",
       "0  45654403  13328  1399        LEXUS   RX 450        2010       Jeep   \n",
       "1  44731507  16621  1018    CHEVROLET  Equinox        2011       Jeep   \n",
       "2  45774419   8467     -        HONDA      FIT        2006  Hatchback   \n",
       "3  45769185   3607   862         FORD   Escape        2011       Jeep   \n",
       "4  45809263  11726   446        HONDA      FIT        2014  Hatchback   \n",
       "\n",
       "  Leather interior Fuel type Engine volume    Mileage  Cylinders  \\\n",
       "0              Yes    Hybrid           3.5  186005 km        6.0   \n",
       "1               No    Petrol             3  192000 km        6.0   \n",
       "2               No    Petrol           1.3  200000 km        4.0   \n",
       "3              Yes    Hybrid           2.5  168966 km        4.0   \n",
       "4              Yes    Petrol           1.3   91901 km        4.0   \n",
       "\n",
       "  Gear box type Drive wheels   Doors             Wheel   Color  Airbags  \n",
       "0     Automatic          4x4  04-May        Left wheel  Silver       12  \n",
       "1     Tiptronic          4x4  04-May        Left wheel   Black        8  \n",
       "2      Variator        Front  04-May  Right-hand drive   Black        2  \n",
       "3     Automatic          4x4  04-May        Left wheel   White        0  \n",
       "4     Automatic        Front  04-May        Left wheel  Silver        4  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check for NaN values and duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                  0\n",
       "Price               0\n",
       "Levy                0\n",
       "Manufacturer        0\n",
       "Model               0\n",
       "Prod. year          0\n",
       "Category            0\n",
       "Leather interior    0\n",
       "Fuel type           0\n",
       "Engine volume       0\n",
       "Mileage             0\n",
       "Cylinders           0\n",
       "Gear box type       0\n",
       "Drive wheels        0\n",
       "Doors               0\n",
       "Wheel               0\n",
       "Color               0\n",
       "Airbags             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out NaN values in each column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print amount of duplicate rows\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detele all duplicate rows\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete ID column, there is no any information there, only identificator\n",
    "df.drop(\"ID\", inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Levy</h2>\n",
    "Levy in auto dealeship language could mean any additional fees, such as taxes and etc.\n",
    "\n",
    "This column has \"-\" value in 30% of dataset, so I assume these mean not the NaN values, but the fact that there are no fees. So, I'll change them to zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/19/0ldx1bc54jx5tvjkrsbcv4040000gn/T/ipykernel_11989/2061335554.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Levy\"].replace(\"-\", \"0\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df[\"Levy\"].replace(\"-\", \"0\", inplace=True)\n",
    "# change data type of column to numeric\n",
    "df[\"Levy\"] = pd.to_numeric(df[\"Levy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Manufacturer, model</h2>\n",
    "Manufacturer column has 65 distinct values. My first thought was to leave only let's say 10 mostly popular ones and bucket up everything else in \"other\" category. But then I had an idea to divide them into countries of origin, let's see if it works. \n",
    "\n",
    "I believe that it might work because most of the car brands in average consumer mind are related to country of origin and e.g. all korean or japanese cars are consider as reliable, or german cars well engineered. However I might loose some brands from premium or \"very poor\" segment. On the other hand they would possibly be outliers anyways, so...\n",
    "\n",
    "ChatGPT was very usefull in this. Also I joined minority countries such as Georgia, Spain and Czech Republic into temporary \"other\" category which should be deleted afterwards. Model will automatically understand that if the car is not in any category, then it is \"other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LEXUS', 'CHEVROLET', 'HONDA', 'FORD', 'HYUNDAI', 'TOYOTA',\n",
       "       'MERCEDES-BENZ', 'OPEL', 'PORSCHE', 'BMW', 'JEEP', 'VOLKSWAGEN',\n",
       "       'AUDI', 'RENAULT', 'NISSAN', 'SUBARU', 'DAEWOO', 'KIA',\n",
       "       'MITSUBISHI', 'SSANGYONG', 'MAZDA', 'GMC', 'FIAT', 'INFINITI',\n",
       "       'ALFA ROMEO', 'SUZUKI', 'ACURA', 'LINCOLN', 'VAZ', 'GAZ',\n",
       "       'CITROEN', 'LAND ROVER', 'MINI', 'DODGE', 'CHRYSLER', 'JAGUAR',\n",
       "       'ISUZU', 'SKODA', 'DAIHATSU', 'BUICK', 'TESLA', 'CADILLAC',\n",
       "       'PEUGEOT', 'BENTLEY', 'VOLVO', 'სხვა', 'HAVAL', 'HUMMER', 'SCION',\n",
       "       'UAZ', 'MERCURY', 'ZAZ', 'ROVER', 'SEAT', 'LANCIA', 'MOSKVICH',\n",
       "       'MASERATI', 'FERRARI', 'SAAB', 'LAMBORGHINI', 'ROLLS-ROYCE',\n",
       "       'PONTIAC', 'SATURN', 'ASTON MARTIN', 'GREATWALL'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Manufacturer\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary with manufacters and origin countries according to ChatGPT\n",
    "car_manufacturers = {\n",
    "    \"Japan\": ['LEXUS', 'HONDA', 'TOYOTA', 'NISSAN', 'SUBARU', 'MITSUBISHI', 'MAZDA', 'SUZUKI', 'ACURA', 'ISUZU', 'DAIHATSU', 'INFINITI', 'SCION'],\n",
    "    \"USA\": ['CHEVROLET', 'FORD', 'JEEP', 'GMC', 'LINCOLN', 'DODGE', 'CHRYSLER', 'TESLA', 'BUICK', 'CADILLAC', 'HUMMER', 'MERCURY', 'PONTIAC', 'SATURN'],\n",
    "    \"South Korea\": ['HYUNDAI', 'KIA', 'DAEWOO', 'SSANGYONG'],\n",
    "    \"Germany\": ['MERCEDES-BENZ', 'OPEL', 'PORSCHE', 'BMW', 'VOLKSWAGEN', 'AUDI'],\n",
    "    \"France\": ['RENAULT', 'CITROEN', 'PEUGEOT'],\n",
    "    \"UK\": ['LAND ROVER', 'MINI', 'JAGUAR', 'BENTLEY', 'ROLLS-ROYCE', 'ROVER', 'ASTON MARTIN', 'MG'],\n",
    "    \"Italy\": ['FIAT', 'ALFA ROMEO', 'LANCIA', 'MASERATI', 'FERRARI', 'LAMBORGHINI'],\n",
    "    \"Sweden\": ['VOLVO', 'SAAB'],\n",
    "    \"Russia\": ['VAZ', 'GAZ', 'UAZ', 'MOSKVICH', 'ZAZ'],\n",
    "    \"China\": ['HAVAL', 'GREATWALL'],\n",
    "    \"Other\": ['SKODA', 'სხვა', 'SEAT']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LEXUS': 'Japan', 'HONDA': 'Japan', 'TOYOTA': 'Japan', 'NISSAN': 'Japan', 'SUBARU': 'Japan', 'MITSUBISHI': 'Japan', 'MAZDA': 'Japan', 'SUZUKI': 'Japan', 'ACURA': 'Japan', 'ISUZU': 'Japan', 'DAIHATSU': 'Japan', 'INFINITI': 'Japan', 'SCION': 'Japan', 'CHEVROLET': 'USA', 'FORD': 'USA', 'JEEP': 'USA', 'GMC': 'USA', 'LINCOLN': 'USA', 'DODGE': 'USA', 'CHRYSLER': 'USA', 'TESLA': 'USA', 'BUICK': 'USA', 'CADILLAC': 'USA', 'HUMMER': 'USA', 'MERCURY': 'USA', 'PONTIAC': 'USA', 'SATURN': 'USA', 'HYUNDAI': 'South Korea', 'KIA': 'South Korea', 'DAEWOO': 'South Korea', 'SSANGYONG': 'South Korea', 'MERCEDES-BENZ': 'Germany', 'OPEL': 'Germany', 'PORSCHE': 'Germany', 'BMW': 'Germany', 'VOLKSWAGEN': 'Germany', 'AUDI': 'Germany', 'RENAULT': 'France', 'CITROEN': 'France', 'PEUGEOT': 'France', 'LAND ROVER': 'UK', 'MINI': 'UK', 'JAGUAR': 'UK', 'BENTLEY': 'UK', 'ROLLS-ROYCE': 'UK', 'ROVER': 'UK', 'ASTON MARTIN': 'UK', 'MG': 'UK', 'FIAT': 'Italy', 'ALFA ROMEO': 'Italy', 'LANCIA': 'Italy', 'MASERATI': 'Italy', 'FERRARI': 'Italy', 'LAMBORGHINI': 'Italy', 'VOLVO': 'Sweden', 'SAAB': 'Sweden', 'VAZ': 'Russia', 'GAZ': 'Russia', 'UAZ': 'Russia', 'MOSKVICH': 'Russia', 'ZAZ': 'Russia', 'HAVAL': 'China', 'GREATWALL': 'China', 'SKODA': 'Other', 'სხვა': 'Other', 'SEAT': 'Other'}\n"
     ]
    }
   ],
   "source": [
    "# Now map a country to each manufacturer\n",
    "\n",
    "# empty dictionary to store the mappings\n",
    "manufacturer_to_country = {}\n",
    "\n",
    "# Loop over each country and its list of manufacturers\n",
    "for country, manufacturers in car_manufacturers.items():\n",
    "    # For each manufacturer in the list, assign the country as the value\n",
    "    for manufacturer in manufacturers:\n",
    "        manufacturer_to_country[manufacturer] = country\n",
    "\n",
    "# Now, 'manufacturer_to_country' maps each manufacturer to its corresponding country\n",
    "print(manufacturer_to_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for country of origin and map it based on manufacturer\n",
    "df['Country'] = df['Manufacturer'].map(manufacturer_to_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical column into seperate features\n",
    "variable = 'Country'\n",
    "dummies = pd.get_dummies(df[variable]).astype(int)\n",
    "df = pd.concat([df, dummies], axis=1).drop(columns=variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally drop the manufacturer column, model, \"other\".\n",
    "# Model column has almost 1600 distinct values and is basically just a name for the car, pretty similar to ID column\n",
    "# I think there is no way to get any information out of model\n",
    "\n",
    "df.drop([\"Manufacturer\", \"Model\", \"Other\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Category</h2>\n",
    "\n",
    "Here I would like to join the cabriolet and coupe categories because cabriolet is basically coupe without roof.\n",
    "Limousine category will be deleted before encoding for the same reason as \"other\" column previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "Sedan          8600\n",
       "Jeep           5378\n",
       "Hatchback      2799\n",
       "Minivan         633\n",
       "Coupe           528\n",
       "Universal       361\n",
       "Microbus        299\n",
       "Goods wagon     229\n",
       "Pickup           51\n",
       "Cabriolet        35\n",
       "Limousine        11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/19/0ldx1bc54jx5tvjkrsbcv4040000gn/T/ipykernel_11989/487454773.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Category\"].replace(\"Cabriolet\", \"Coupe\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace cabriolet to coupe\n",
    "df[\"Category\"].replace(\"Cabriolet\", \"Coupe\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical column into seperate features\n",
    "variable = 'Category'\n",
    "dummies = pd.get_dummies(df[variable]).astype(int)\n",
    "df = pd.concat([df, dummies], axis=1).drop(columns=variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop limousine to decrease multidimensionality\n",
    "df.drop(\"Limousine\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Leather interior</h2>\n",
    "This one is simple, it's yes or no column so just encode it to binary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'Leather interior'\n",
    "\n",
    "# NOTE: factorize can mix up the order of the values\n",
    "values1, names1 = pd.factorize(df[variable], sort=False)\n",
    "df[variable] = values1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Fuel type</h2>\n",
    "I think about joining the plug in hybrid and hybrid into one category, they are slightly different but however\n",
    "Also I think I'll delete row with hydrogen fuel type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fuel type\n",
       "Petrol            9944\n",
       "Diesel            4001\n",
       "Hybrid            3539\n",
       "LPG                885\n",
       "CNG                469\n",
       "Plug-in Hybrid      85\n",
       "Hydrogen             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Fuel type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for the index of the row with fuel type hydrogen\n",
    "i = df[df[\"Fuel type\"] == \"Hydrogen\"].index\n",
    "# Drop the hydrogen\n",
    "df.drop(i, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join hybrids\n",
    "df.replace(\"Plug-in Hybrid\", \"Hybrid\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode column and drop CNG to decrease column amount\n",
    "variable = 'Fuel type'\n",
    "dummies = pd.get_dummies(df[variable]).astype(int)\n",
    "df = pd.concat([df, dummies], axis=1).drop(columns=variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"CNG\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Engine volume</h2>\n",
    "\n",
    "Engine volume consist of float number indicating volume and sometimes also mention if it is turbo or not. \n",
    "\n",
    "I can extract volume and seperate turbo feature to different column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate number and Turbo\n",
    "def process_engine(engine_value):\n",
    "    # Extract the numeric part using regex\n",
    "    # \\d means any number between 0-9\n",
    "    number = re.search(r'\\d+\\.\\d+|\\d+', engine_value)\n",
    "    # save our extracted float\n",
    "    number = float(number.group())\n",
    "\n",
    "    # Check if \"Turbo\" is in the string\n",
    "    turbo = 1 if \"Turbo\" in engine_value else 0\n",
    "\n",
    "    return number, turbo\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df[['Engine volume int', 'Turbo']] = df['Engine volume'].apply(lambda x: pd.Series(process_engine(x)))\n",
    "\n",
    "# Drop the old Engine column\n",
    "df.drop('Engine volume', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mileage</h2>\n",
    "Mileage values are strings and contain \"km\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/19/0ldx1bc54jx5tvjkrsbcv4040000gn/T/ipykernel_11989/3909022585.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Mileage'].replace(r'[^0-9]+', '', regex=True, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# using regex exctract only numeric values\n",
    "df['Mileage'].replace(r'[^0-9]+', '', regex=True, inplace=True)\n",
    "# change data type of column to numeric\n",
    "df[\"Mileage\"] = pd.to_numeric(df[\"Mileage\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Gear box type</h2>\n",
    "Same as other categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode column and drop last feature to decrease column amount\n",
    "variable = 'Gear box type'\n",
    "dummies = pd.get_dummies(df[variable]).astype(int)\n",
    "df = pd.concat([df, dummies], axis=1).drop(columns=variable)\n",
    "\n",
    "df.drop(\"Tiptronic\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Drive wheels</h2>\n",
    "Same as previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode column and drop last feature to decrease column amount\n",
    "variable = 'Drive wheels'\n",
    "dummies = pd.get_dummies(df[variable]).astype(int)\n",
    "df = pd.concat([df, dummies], axis=1).drop(columns=variable)\n",
    "\n",
    "df.drop(\"Rear\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Doors</h2>\n",
    "Column is in wrong format, I assume the real meaning is 4-5 (May is 5th month) for the most part of the cars, 2-3 (March is 3rd) for coupes and >5 for cars with more than 5 doors. \n",
    "\n",
    "However, basically amount of doors is same thing as type of car, most of the cars are sedans, universals or hatchabacks and they all have 4 to 5 doors. Cabriolets, coupes, pickups and good wagons have 2 to 3 doors. Buses have more than 5.\n",
    "\n",
    "Another problem is that this column is very unbalanced, since owerhelming amount of cars have 4-5 doors.\n",
    "\n",
    "\n",
    "So in this case I assume that is better to drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Doors\n",
       "04-May    18031\n",
       "02-Mar      768\n",
       ">5          124\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Doors\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Doors\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Wheel</h2>\n",
    "Defines if the wheel is on right or left side. Binary caregory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'Wheel'\n",
    "\n",
    "# NOTE: factorize can mix up the order of the values\n",
    "values1, names1 = pd.factorize(df[variable], sort=False)\n",
    "df[variable] = values1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Color</h2>\n",
    "\n",
    "Color could be meaningfull for example for luxury cars, may be some kind of rare color combinations and so on. \n",
    "\n",
    "Also, when buying a new car in case you want any specific and dealership doesn't have it at the moment you have to wait for it.\n",
    "\n",
    "But in general I don't think that the color has some significant influence on price, especially on used car market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Color\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Splitting dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you  have more than one independent variables, list them all here\n",
    "# leave out the target variable! (dependent variable)\n",
    "X = df.drop(\"Price\", axis=1)\n",
    "\n",
    "# have only the target variable here (dependent variable)\n",
    "y = df['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 70% for training and 30% for testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Split the testing data, half for validation and half for testing\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Building model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 03m 04s]\n",
      "val_loss: 243823766186.66666\n",
      "\n",
      "Best val_loss So Far: 243720421376.0\n",
      "Total elapsed time: 00h 15m 22s\n"
     ]
    }
   ],
   "source": [
    "# pip install keras-tuner\n",
    "import keras_tuner\n",
    "\n",
    "def build_model(hp):\n",
    "    # iniatlize sequential test neural network\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # first layer, batch normalization + input shape, same as in typical neural network\n",
    "    model.add(layers.BatchNormalization(input_shape=(len(X.columns),)),)\n",
    "    \n",
    "    # add the first actual layer including the regularizer\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            # Tune number of units separately.\n",
    "            units=hp.Int(f\"units_0\", min_value=32, max_value=86, step=4),\n",
    "            activation=hp.Choice(\"activation\", [\"relu\"]),\n",
    "            kernel_regularizer=keras.regularizers.l1(l1=0.1)\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    # automate a dropout layer\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.1))\n",
    "\n",
    "    # try additional layers, 1 or 2 extra layers\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 2)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i + 1}\", min_value=4, max_value=64, step=4),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\"]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # output layer, only one node since this is regression\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    # automate learning rate tests\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "\n",
    "    # compile the test neural network\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# build the model + use RandomSearch to actually search the best options for our neural network\n",
    "build_model(keras_tuner.HyperParameters())\n",
    "\n",
    "# use val_loss as the objective, because regression tasks do not have accuracy\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    overwrite=True,\n",
    "    directory=\"optimizations\",\n",
    "    project_name=\"regression1test\",\n",
    ")\n",
    "\n",
    "# start searching\n",
    "tuner.search(X_train, y_train, epochs=250, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in optimizations/regression1test\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "units_0: 36\n",
      "activation: relu\n",
      "dropout: True\n",
      "num_layers: 2\n",
      "units_1: 40\n",
      "lr: 0.00035130677235196815\n",
      "units_2: 28\n",
      "Score: 243720421376.0\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "units_0: 84\n",
      "activation: relu\n",
      "dropout: True\n",
      "num_layers: 2\n",
      "units_1: 16\n",
      "lr: 0.0011282276362648358\n",
      "units_2: 16\n",
      "Score: 243823766186.66666\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "units_0: 64\n",
      "activation: relu\n",
      "dropout: False\n",
      "num_layers: 2\n",
      "units_1: 28\n",
      "lr: 0.00011894173793507069\n",
      "units_2: 4\n",
      "Score: 243879428096.0\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "units_0: 52\n",
      "activation: relu\n",
      "dropout: False\n",
      "num_layers: 1\n",
      "units_1: 12\n",
      "lr: 0.00017955858969577045\n",
      "units_2: 56\n",
      "Score: 243894561450.66666\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "units_0: 52\n",
      "activation: relu\n",
      "dropout: False\n",
      "num_layers: 2\n",
      "units_1: 64\n",
      "lr: 0.0007538603502895294\n",
      "units_2: 4\n",
      "Score: 244004929536.0\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirillsobolev/Documents/GitHub/.venv/lib/python3.9/site-packages/keras/src/layers/normalization/batch_normalization.py:143: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Users/kirillsobolev/Documents/GitHub/.venv/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,148</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m)             │           \u001b[38;5;34m148\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │         \u001b[38;5;34m1,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m1,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │         \u001b[38;5;34m1,148\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m29\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,173</span> (16.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,173\u001b[0m (16.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,099</span> (16.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,099\u001b[0m (16.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74</span> (296.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m74\u001b[0m (296.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirillsobolev/Documents/GitHub/.venv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,148</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m2,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │         \u001b[38;5;34m1,148\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m29\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,209</span> (24.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,209\u001b[0m (24.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,209</span> (24.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,209\u001b[0m (24.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        #layers.BatchNormalization(input_shape=(len(X.columns),)),\n",
    "        layers.Dense(64, activation=\"relu\", input_shape=(len(X.columns),)),\n",
    "        layers.Dropout(rate=0.1),\n",
    "        layers.Dense(40, activation=\"relu\"),\n",
    "        layers.Dense(28, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# optimal learning rate from keras tuner\n",
    "optimal_lr = 0.00035130677235196815\n",
    "\n",
    "# select the optimizer and loss function\n",
    "# you can try rmsprop also as optimizer, or stochastic gradient descent\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=optimal_lr), loss='mse')\n",
    "# print out the summary of your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 1459904053248.0000 - val_loss: 1305845563392.0000\n",
      "Epoch 2/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 2466057027584.0000 - val_loss: 442892582912.0000\n",
      "Epoch 3/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 2628943609856.0000 - val_loss: 648394309632.0000\n",
      "Epoch 4/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 542529257472.0000 - val_loss: 1268909211648.0000\n",
      "Epoch 5/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 1739258068992.0000 - val_loss: 1128478408704.0000\n",
      "Epoch 6/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 1343515787264.0000 - val_loss: 246919823360.0000\n",
      "Epoch 7/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 176274751488.0000 - val_loss: 244434026496.0000\n",
      "Epoch 8/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 302123057152.0000 - val_loss: 1954872426496.0000\n",
      "Epoch 9/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 1171472515072.0000 - val_loss: 254226776064.0000\n",
      "Epoch 10/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 355086958592.0000 - val_loss: 477342793728.0000\n",
      "Epoch 11/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 505013272576.0000 - val_loss: 429209387008.0000\n",
      "Epoch 12/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 653096779776.0000 - val_loss: 584945434624.0000\n",
      "Epoch 13/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 341787082752.0000 - val_loss: 253281501184.0000\n",
      "Epoch 14/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 338500288512.0000 - val_loss: 251605270528.0000\n",
      "Epoch 15/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 1800848277504.0000 - val_loss: 245518794752.0000\n",
      "Epoch 16/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 211533234176.0000 - val_loss: 295920893952.0000\n",
      "Epoch 17/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 147153436672.0000 - val_loss: 499379175424.0000\n",
      "Epoch 18/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 623481651200.0000 - val_loss: 266034331648.0000\n",
      "Epoch 19/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 115909697536.0000 - val_loss: 267890212864.0000\n",
      "Epoch 20/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 69803474944.0000 - val_loss: 280014159872.0000\n",
      "Epoch 21/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 39263346688.0000 - val_loss: 391223836672.0000\n",
      "Epoch 22/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 159396708352.0000 - val_loss: 261225431040.0000\n",
      "Epoch 23/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 112725270528.0000 - val_loss: 354238201856.0000\n",
      "Epoch 24/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 448446758912.0000 - val_loss: 259654615040.0000\n",
      "Epoch 25/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 444752855040.0000 - val_loss: 542472830976.0000\n",
      "Epoch 26/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 134697820160.0000 - val_loss: 261972033536.0000\n",
      "Epoch 27/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 82723340288.0000 - val_loss: 274490310656.0000\n",
      "Epoch 28/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 371108806656.0000 - val_loss: 261393727488.0000\n",
      "Epoch 29/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 130450120704.0000 - val_loss: 245510520832.0000\n",
      "Epoch 30/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 27319062528.0000 - val_loss: 252412051456.0000\n",
      "Epoch 31/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 60135968768.0000 - val_loss: 257088618496.0000\n",
      "Epoch 32/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 45367242752.0000 - val_loss: 249613025280.0000\n",
      "Epoch 33/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 60231852032.0000 - val_loss: 567974363136.0000\n",
      "Epoch 34/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 103090700288.0000 - val_loss: 247113187328.0000\n",
      "Epoch 35/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 35360935936.0000 - val_loss: 806916980736.0000\n",
      "Epoch 36/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 385714421760.0000 - val_loss: 246696886272.0000\n",
      "Epoch 37/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 22532728832.0000 - val_loss: 255123718144.0000\n",
      "Epoch 38/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 25446594560.0000 - val_loss: 244672987136.0000\n",
      "Epoch 39/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 59756462080.0000 - val_loss: 255047237632.0000\n",
      "Epoch 40/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 30074372096.0000 - val_loss: 243985760256.0000\n",
      "Epoch 41/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 28377495552.0000 - val_loss: 244006715392.0000\n",
      "Epoch 42/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 9108346880.0000 - val_loss: 244736311296.0000\n",
      "Epoch 43/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 24913625088.0000 - val_loss: 250081296384.0000\n",
      "Epoch 44/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - loss: 5480317440.0000 - val_loss: 277392621568.0000\n",
      "Epoch 45/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 14603292672.0000 - val_loss: 399589572608.0000\n",
      "Epoch 46/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 202454351872.0000 - val_loss: 246046523392.0000\n",
      "Epoch 47/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7873349632.0000 - val_loss: 246411526144.0000\n",
      "Epoch 48/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 17268305920.0000 - val_loss: 244765704192.0000\n",
      "Epoch 49/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 7541237760.0000 - val_loss: 250025689088.0000\n",
      "Epoch 50/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 6723597312.0000 - val_loss: 248144363520.0000\n",
      "Epoch 51/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57793236992.0000 - val_loss: 249572573184.0000\n",
      "Epoch 52/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35302625280.0000 - val_loss: 250835075072.0000\n",
      "Epoch 53/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14656966656.0000 - val_loss: 244072906752.0000\n",
      "Epoch 54/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - loss: 24116703232.0000 - val_loss: 250724204544.0000\n",
      "Epoch 55/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 10340412416.0000 - val_loss: 243779420160.0000\n",
      "Epoch 56/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 2092835712.0000 - val_loss: 247348559872.0000\n",
      "Epoch 57/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 5299593216.0000 - val_loss: 254046748672.0000\n",
      "Epoch 58/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 7316627968.0000 - val_loss: 246333505536.0000\n",
      "Epoch 59/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 2765128960.0000 - val_loss: 244053704704.0000\n",
      "Epoch 60/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 4585018880.0000 - val_loss: 249099190272.0000\n",
      "Epoch 61/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 23622850560.0000 - val_loss: 245666922496.0000\n",
      "Epoch 62/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 1548266368.0000 - val_loss: 244032094208.0000\n",
      "Epoch 63/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 1556248192.0000 - val_loss: 244400439296.0000\n",
      "Epoch 64/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 5013950976.0000 - val_loss: 255204245504.0000\n",
      "Epoch 65/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 24329349120.0000 - val_loss: 244568866816.0000\n",
      "Epoch 66/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 1475240448.0000 - val_loss: 244969930752.0000\n",
      "Epoch 67/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 1055429696.0000 - val_loss: 243803406336.0000\n",
      "Epoch 68/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 6804866560.0000 - val_loss: 243789316096.0000\n",
      "Epoch 69/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 1632208768.0000 - val_loss: 244086669312.0000\n",
      "Epoch 70/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 979796608.0000 - val_loss: 243980320768.0000\n",
      "Epoch 71/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 1203963520.0000 - val_loss: 244003520512.0000\n",
      "Epoch 72/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 2463021824.0000 - val_loss: 256511852544.0000\n",
      "Epoch 73/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 20257959936.0000 - val_loss: 246261088256.0000\n",
      "Epoch 74/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 2852939264.0000 - val_loss: 243817775104.0000\n",
      "Epoch 75/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 607349632.0000 - val_loss: 245230026752.0000\n",
      "Epoch 76/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 724874880.0000 - val_loss: 246777266176.0000\n",
      "Epoch 77/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 1524366720.0000 - val_loss: 246836445184.0000\n",
      "Epoch 78/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 2214029568.0000 - val_loss: 243829751808.0000\n",
      "Epoch 79/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 1218159488.0000 - val_loss: 243872006144.0000\n",
      "Epoch 80/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 17899390976.0000 - val_loss: 250378141696.0000\n",
      "Epoch 81/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 5423899136.0000 - val_loss: 246622683136.0000\n",
      "Epoch 82/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 1270130560.0000 - val_loss: 247066525696.0000\n",
      "Epoch 83/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 1847824128.0000 - val_loss: 245897707520.0000\n",
      "Epoch 84/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 2704840704.0000 - val_loss: 243890372608.0000\n",
      "Epoch 85/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 1216910976.0000 - val_loss: 243844923392.0000\n",
      "Epoch 86/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 2316539392.0000 - val_loss: 243804372992.0000\n",
      "Epoch 87/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 975292416.0000 - val_loss: 243821559808.0000\n",
      "Epoch 88/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 2428596224.0000 - val_loss: 244655570944.0000\n",
      "Epoch 89/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 1035117888.0000 - val_loss: 243929677824.0000\n",
      "Epoch 90/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 2184855296.0000 - val_loss: 243790184448.0000\n",
      "Epoch 91/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 4122667520.0000 - val_loss: 243772030976.0000\n",
      "Epoch 92/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 1677545472.0000 - val_loss: 243864977408.0000\n",
      "Epoch 93/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 798531264.0000 - val_loss: 248224317440.0000\n",
      "Epoch 94/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 3781831936.0000 - val_loss: 243864059904.0000\n",
      "Epoch 95/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 1834215808.0000 - val_loss: 243816644608.0000\n",
      "Epoch 96/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 1213465472.0000 - val_loss: 243962396672.0000\n",
      "Epoch 97/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 4201622272.0000 - val_loss: 243860013056.0000\n",
      "Epoch 98/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - loss: 1831928832.0000 - val_loss: 243923107840.0000\n",
      "Epoch 99/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 1289817728.0000 - val_loss: 243859898368.0000\n",
      "Epoch 100/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 995181248.0000 - val_loss: 243908182016.0000\n",
      "Epoch 101/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 1288201600.0000 - val_loss: 243792723968.0000\n",
      "Epoch 102/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 811299648.0000 - val_loss: 244112343040.0000\n",
      "Epoch 103/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 5657210880.0000 - val_loss: 243930759168.0000\n",
      "Epoch 104/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 1204266240.0000 - val_loss: 243985203200.0000\n",
      "Epoch 105/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 640645248.0000 - val_loss: 243779813376.0000\n",
      "Epoch 106/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 1394428672.0000 - val_loss: 243792248832.0000\n",
      "Epoch 107/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 527581344.0000 - val_loss: 243858210816.0000\n",
      "Epoch 108/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 5788272640.0000 - val_loss: 243799457792.0000\n",
      "Epoch 109/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 3790584064.0000 - val_loss: 244482818048.0000\n",
      "Epoch 110/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 735541056.0000 - val_loss: 243875708928.0000\n",
      "Epoch 111/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 989868288.0000 - val_loss: 243811778560.0000\n",
      "Epoch 112/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 1144601984.0000 - val_loss: 243944456192.0000\n",
      "Epoch 113/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 1098919296.0000 - val_loss: 244185038848.0000\n",
      "Epoch 114/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 971401856.0000 - val_loss: 243855900672.0000\n",
      "Epoch 115/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 722241664.0000 - val_loss: 245482569728.0000\n",
      "Epoch 116/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 823333376.0000 - val_loss: 244202438656.0000\n",
      "Epoch 117/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 581377216.0000 - val_loss: 243788152832.0000\n",
      "Epoch 118/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 1132079872.0000 - val_loss: 243907231744.0000\n",
      "Epoch 119/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 653723264.0000 - val_loss: 247547248640.0000\n",
      "Epoch 120/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 2911819776.0000 - val_loss: 244015562752.0000\n",
      "Epoch 121/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 1533444608.0000 - val_loss: 243776471040.0000\n",
      "Epoch 122/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 768218304.0000 - val_loss: 244212236288.0000\n",
      "Epoch 123/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 1116613760.0000 - val_loss: 247819501568.0000\n",
      "Epoch 124/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 2787433984.0000 - val_loss: 243802816512.0000\n",
      "Epoch 125/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 445579360.0000 - val_loss: 243954008064.0000\n",
      "Epoch 126/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 695748736.0000 - val_loss: 243808583680.0000\n",
      "Epoch 127/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 356644864.0000 - val_loss: 243804045312.0000\n",
      "Epoch 128/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 775049600.0000 - val_loss: 243791069184.0000\n",
      "Epoch 129/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 575563520.0000 - val_loss: 243777224704.0000\n",
      "Epoch 130/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 595975104.0000 - val_loss: 243771457536.0000\n",
      "Epoch 131/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 752309760.0000 - val_loss: 243775078400.0000\n",
      "Epoch 132/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 1248420224.0000 - val_loss: 244782727168.0000\n",
      "Epoch 133/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 2132455808.0000 - val_loss: 243795722240.0000\n",
      "Epoch 134/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 5902332928.0000 - val_loss: 243814023168.0000\n",
      "Epoch 135/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 383751904.0000 - val_loss: 243787202560.0000\n",
      "Epoch 136/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 1176504704.0000 - val_loss: 245528166400.0000\n",
      "Epoch 137/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 2106631168.0000 - val_loss: 243779354624.0000\n",
      "Epoch 138/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 398333280.0000 - val_loss: 243778535424.0000\n",
      "Epoch 139/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 445401600.0000 - val_loss: 243814727680.0000\n",
      "Epoch 140/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 595218752.0000 - val_loss: 243834355712.0000\n",
      "Epoch 141/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 532043008.0000 - val_loss: 243781484544.0000\n",
      "Epoch 142/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 466905888.0000 - val_loss: 243837403136.0000\n",
      "Epoch 143/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 595673216.0000 - val_loss: 243792429056.0000\n",
      "Epoch 144/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 341559328.0000 - val_loss: 243779977216.0000\n",
      "Epoch 145/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 434349792.0000 - val_loss: 243785498624.0000\n",
      "Epoch 146/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 412496640.0000 - val_loss: 243780059136.0000\n",
      "Epoch 147/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 1329255040.0000 - val_loss: 243766919168.0000\n",
      "Epoch 148/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 1063885056.0000 - val_loss: 243804110848.0000\n",
      "Epoch 149/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 483492672.0000 - val_loss: 243801489408.0000\n",
      "Epoch 150/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 504652800.0000 - val_loss: 243846283264.0000\n",
      "Epoch 151/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 446917728.0000 - val_loss: 244323090432.0000\n",
      "Epoch 152/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 2392560896.0000 - val_loss: 243782008832.0000\n",
      "Epoch 153/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 519416832.0000 - val_loss: 243802177536.0000\n",
      "Epoch 154/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 324767552.0000 - val_loss: 243776684032.0000\n",
      "Epoch 155/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 365505472.0000 - val_loss: 243795656704.0000\n",
      "Epoch 156/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 380811328.0000 - val_loss: 243790888960.0000\n",
      "Epoch 157/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 413022400.0000 - val_loss: 243772784640.0000\n",
      "Epoch 158/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 628357888.0000 - val_loss: 243857539072.0000\n",
      "Epoch 159/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 448989632.0000 - val_loss: 243782713344.0000\n",
      "Epoch 160/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 616495168.0000 - val_loss: 243761364992.0000\n",
      "Epoch 161/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 488594752.0000 - val_loss: 243789692928.0000\n",
      "Epoch 162/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 413286560.0000 - val_loss: 243776159744.0000\n",
      "Epoch 163/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 346809888.0000 - val_loss: 243762495488.0000\n",
      "Epoch 164/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 453906112.0000 - val_loss: 243813449728.0000\n",
      "Epoch 165/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 394206400.0000 - val_loss: 243731922944.0000\n",
      "Epoch 166/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 345263424.0000 - val_loss: 243786219520.0000\n",
      "Epoch 167/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 348569888.0000 - val_loss: 243739394048.0000\n",
      "Epoch 168/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 356523360.0000 - val_loss: 243776028672.0000\n",
      "Epoch 169/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 405385056.0000 - val_loss: 243890831360.0000\n",
      "Epoch 170/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 698014336.0000 - val_loss: 243785416704.0000\n",
      "Epoch 171/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - loss: 469268928.0000 - val_loss: 243762348032.0000\n",
      "Epoch 172/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 391402432.0000 - val_loss: 243777060864.0000\n",
      "Epoch 173/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 400102848.0000 - val_loss: 243769114624.0000\n",
      "Epoch 174/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 382945504.0000 - val_loss: 243796033536.0000\n",
      "Epoch 175/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - loss: 430122880.0000 - val_loss: 243737427968.0000\n",
      "Epoch 176/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 14934963200.0000 - val_loss: 243728285696.0000\n",
      "Epoch 177/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 473586144.0000 - val_loss: 243775504384.0000\n",
      "Epoch 178/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 553215168.0000 - val_loss: 243770769408.0000\n",
      "Epoch 179/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 346753344.0000 - val_loss: 243788349440.0000\n",
      "Epoch 180/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 613969728.0000 - val_loss: 243775176704.0000\n",
      "Epoch 181/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 366829152.0000 - val_loss: 243755024384.0000\n",
      "Epoch 182/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 424137728.0000 - val_loss: 243771277312.0000\n",
      "Epoch 183/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 373335744.0000 - val_loss: 243795132416.0000\n",
      "Epoch 184/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 3553075712.0000 - val_loss: 243777585152.0000\n",
      "Epoch 185/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 619911296.0000 - val_loss: 243754483712.0000\n",
      "Epoch 186/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 305055712.0000 - val_loss: 243745914880.0000\n",
      "Epoch 187/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 363897632.0000 - val_loss: 243752894464.0000\n",
      "Epoch 188/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 388876576.0000 - val_loss: 243755876352.0000\n",
      "Epoch 189/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 373841280.0000 - val_loss: 243761905664.0000\n",
      "Epoch 190/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 412031104.0000 - val_loss: 243766509568.0000\n",
      "Epoch 191/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 377049600.0000 - val_loss: 243773374464.0000\n",
      "Epoch 192/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 343546208.0000 - val_loss: 243762692096.0000\n",
      "Epoch 193/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 436658048.0000 - val_loss: 243760414720.0000\n",
      "Epoch 194/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 523449632.0000 - val_loss: 243767443456.0000\n",
      "Epoch 195/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 385053440.0000 - val_loss: 243767607296.0000\n",
      "Epoch 196/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 364678848.0000 - val_loss: 243765657600.0000\n",
      "Epoch 197/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 364063840.0000 - val_loss: 243794329600.0000\n",
      "Epoch 198/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 380607104.0000 - val_loss: 243760611328.0000\n",
      "Epoch 199/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 360442272.0000 - val_loss: 243775406080.0000\n",
      "Epoch 200/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 363774688.0000 - val_loss: 243781746688.0000\n",
      "Epoch 201/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 363960768.0000 - val_loss: 243772243968.0000\n",
      "Epoch 202/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 661073088.0000 - val_loss: 243773652992.0000\n",
      "Epoch 203/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 321301696.0000 - val_loss: 243774652416.0000\n",
      "Epoch 204/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 338412928.0000 - val_loss: 243767443456.0000\n",
      "Epoch 205/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 528482432.0000 - val_loss: 243769212928.0000\n",
      "Epoch 206/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 965907584.0000 - val_loss: 243758694400.0000\n",
      "Epoch 207/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 578612480.0000 - val_loss: 243735134208.0000\n",
      "Epoch 208/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 332009152.0000 - val_loss: 243773390848.0000\n",
      "Epoch 209/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 340567968.0000 - val_loss: 243744620544.0000\n",
      "Epoch 210/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 334303488.0000 - val_loss: 243776208896.0000\n",
      "Epoch 211/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 1457080448.0000 - val_loss: 243757793280.0000\n",
      "Epoch 212/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 488560128.0000 - val_loss: 243728629760.0000\n",
      "Epoch 213/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 810335488.0000 - val_loss: 243746226176.0000\n",
      "Epoch 214/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 373035712.0000 - val_loss: 243765231616.0000\n",
      "Epoch 215/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 349883392.0000 - val_loss: 243765116928.0000\n",
      "Epoch 216/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 446722592.0000 - val_loss: 243756089344.0000\n",
      "Epoch 217/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 346408864.0000 - val_loss: 243770294272.0000\n",
      "Epoch 218/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 323529632.0000 - val_loss: 243748044800.0000\n",
      "Epoch 219/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 402405888.0000 - val_loss: 243774488576.0000\n",
      "Epoch 220/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 381050176.0000 - val_loss: 243741884416.0000\n",
      "Epoch 221/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 466306624.0000 - val_loss: 243790168064.0000\n",
      "Epoch 222/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 2351317248.0000 - val_loss: 243756695552.0000\n",
      "Epoch 223/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 531076608.0000 - val_loss: 243750273024.0000\n",
      "Epoch 224/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 414488736.0000 - val_loss: 243766001664.0000\n",
      "Epoch 225/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 559930688.0000 - val_loss: 243757416448.0000\n",
      "Epoch 226/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 367601472.0000 - val_loss: 243778863104.0000\n",
      "Epoch 227/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 343800160.0000 - val_loss: 243749650432.0000\n",
      "Epoch 228/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 495030080.0000 - val_loss: 243746488320.0000\n",
      "Epoch 229/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 445577952.0000 - val_loss: 243733430272.0000\n",
      "Epoch 230/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 374929312.0000 - val_loss: 243768508416.0000\n",
      "Epoch 231/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 361109632.0000 - val_loss: 243757416448.0000\n",
      "Epoch 232/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 486753280.0000 - val_loss: 243749847040.0000\n",
      "Epoch 233/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 508453888.0000 - val_loss: 243770507264.0000\n",
      "Epoch 234/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 335515872.0000 - val_loss: 243719585792.0000\n",
      "Epoch 235/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 429180160.0000 - val_loss: 243753746432.0000\n",
      "Epoch 236/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 17598355456.0000 - val_loss: 243768049664.0000\n",
      "Epoch 237/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 439345024.0000 - val_loss: 243743539200.0000\n",
      "Epoch 238/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 349878752.0000 - val_loss: 243762446336.0000\n",
      "Epoch 239/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 450695744.0000 - val_loss: 243760349184.0000\n",
      "Epoch 240/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 369291872.0000 - val_loss: 243767705600.0000\n",
      "Epoch 241/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 2049031168.0000 - val_loss: 243772047360.0000\n",
      "Epoch 242/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 896906368.0000 - val_loss: 243759824896.0000\n",
      "Epoch 243/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 321926784.0000 - val_loss: 243767738368.0000\n",
      "Epoch 244/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 373923328.0000 - val_loss: 243768475648.0000\n",
      "Epoch 245/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 333916512.0000 - val_loss: 243752091648.0000\n",
      "Epoch 246/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 339643072.0000 - val_loss: 243767181312.0000\n",
      "Epoch 247/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 553014464.0000 - val_loss: 243739918336.0000\n",
      "Epoch 248/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 414128160.0000 - val_loss: 243769442304.0000\n",
      "Epoch 249/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 455082880.0000 - val_loss: 243787939840.0000\n",
      "Epoch 250/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 356411712.0000 - val_loss: 243770589184.0000\n",
      "Epoch 251/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 436826208.0000 - val_loss: 243758989312.0000\n",
      "Epoch 252/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 431402880.0000 - val_loss: 243766591488.0000\n",
      "Epoch 253/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 536100512.0000 - val_loss: 243781173248.0000\n",
      "Epoch 254/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 330587200.0000 - val_loss: 243765051392.0000\n",
      "Epoch 255/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 408196704.0000 - val_loss: 243752075264.0000\n",
      "Epoch 256/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 403277344.0000 - val_loss: 243764854784.0000\n",
      "Epoch 257/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 400697792.0000 - val_loss: 243775193088.0000\n",
      "Epoch 258/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 398780736.0000 - val_loss: 243756236800.0000\n",
      "Epoch 259/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 313619488.0000 - val_loss: 243733315584.0000\n",
      "Epoch 260/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 328359488.0000 - val_loss: 243760726016.0000\n",
      "Epoch 261/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 363504448.0000 - val_loss: 243768311808.0000\n",
      "Epoch 262/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 315417056.0000 - val_loss: 243754582016.0000\n",
      "Epoch 263/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 338027232.0000 - val_loss: 243765952512.0000\n",
      "Epoch 264/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 317669056.0000 - val_loss: 243758071808.0000\n",
      "Epoch 265/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 384407072.0000 - val_loss: 243752960000.0000\n",
      "Epoch 266/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 2409750528.0000 - val_loss: 243771457536.0000\n",
      "Epoch 267/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 985640896.0000 - val_loss: 243762397184.0000\n",
      "Epoch 268/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 532339104.0000 - val_loss: 243739656192.0000\n",
      "Epoch 269/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 335765088.0000 - val_loss: 243779993600.0000\n",
      "Epoch 270/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 330868768.0000 - val_loss: 243767623680.0000\n",
      "Epoch 271/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 333892960.0000 - val_loss: 243756105728.0000\n",
      "Epoch 272/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 6437533696.0000 - val_loss: 243752353792.0000\n",
      "Epoch 273/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 383226944.0000 - val_loss: 243763412992.0000\n",
      "Epoch 274/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 375238368.0000 - val_loss: 243768344576.0000\n",
      "Epoch 275/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 387749536.0000 - val_loss: 243766657024.0000\n",
      "Epoch 276/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 476275776.0000 - val_loss: 243770916864.0000\n",
      "Epoch 277/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - loss: 467488768.0000 - val_loss: 243783942144.0000\n",
      "Epoch 278/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 416252768.0000 - val_loss: 243769540608.0000\n",
      "Epoch 279/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 466981056.0000 - val_loss: 243783024640.0000\n",
      "Epoch 280/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 469911136.0000 - val_loss: 243772325888.0000\n",
      "Epoch 281/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 369658784.0000 - val_loss: 243770982400.0000\n",
      "Epoch 282/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 459451488.0000 - val_loss: 243766706176.0000\n",
      "Epoch 283/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - loss: 388948992.0000 - val_loss: 243761119232.0000\n",
      "Epoch 284/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 526496320.0000 - val_loss: 243745374208.0000\n",
      "Epoch 285/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 362594432.0000 - val_loss: 243763871744.0000\n",
      "Epoch 286/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 355530816.0000 - val_loss: 243719749632.0000\n",
      "Epoch 287/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 345451328.0000 - val_loss: 243756957696.0000\n",
      "Epoch 288/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 397061952.0000 - val_loss: 243771195392.0000\n",
      "Epoch 289/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 323005344.0000 - val_loss: 243766820864.0000\n",
      "Epoch 290/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 423555264.0000 - val_loss: 243785269248.0000\n",
      "Epoch 291/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 375400480.0000 - val_loss: 243770245120.0000\n",
      "Epoch 292/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 307747520.0000 - val_loss: 243753140224.0000\n",
      "Epoch 293/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 324642944.0000 - val_loss: 243762774016.0000\n",
      "Epoch 294/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 339407744.0000 - val_loss: 243768950784.0000\n",
      "Epoch 295/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 386175936.0000 - val_loss: 243741147136.0000\n",
      "Epoch 296/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 493611616.0000 - val_loss: 243767820288.0000\n",
      "Epoch 297/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 408071616.0000 - val_loss: 243743227904.0000\n",
      "Epoch 298/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 391889024.0000 - val_loss: 243743981568.0000\n",
      "Epoch 299/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 358744256.0000 - val_loss: 243741032448.0000\n",
      "Epoch 300/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 441865696.0000 - val_loss: 243759611904.0000\n",
      "Epoch 301/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 551025088.0000 - val_loss: 243782287360.0000\n",
      "Epoch 302/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 335594016.0000 - val_loss: 243749044224.0000\n",
      "Epoch 303/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 642987584.0000 - val_loss: 243768836096.0000\n",
      "Epoch 304/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 374859520.0000 - val_loss: 243780370432.0000\n",
      "Epoch 305/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 390054432.0000 - val_loss: 243760037888.0000\n",
      "Epoch 306/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 340413120.0000 - val_loss: 243760775168.0000\n",
      "Epoch 307/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 314573856.0000 - val_loss: 243790807040.0000\n",
      "Epoch 308/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 357608256.0000 - val_loss: 243758858240.0000\n",
      "Epoch 309/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - loss: 417140224.0000 - val_loss: 243763412992.0000\n",
      "Epoch 310/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 1223597312.0000 - val_loss: 243745865728.0000\n",
      "Epoch 311/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 319217504.0000 - val_loss: 243744178176.0000\n",
      "Epoch 312/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 341513280.0000 - val_loss: 243745112064.0000\n",
      "Epoch 313/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 372852480.0000 - val_loss: 243764101120.0000\n",
      "Epoch 314/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 611226368.0000 - val_loss: 243751698432.0000\n",
      "Epoch 315/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 355355328.0000 - val_loss: 243763412992.0000\n",
      "Epoch 316/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 507400608.0000 - val_loss: 243775946752.0000\n",
      "Epoch 317/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 366764992.0000 - val_loss: 243758694400.0000\n",
      "Epoch 318/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 528597792.0000 - val_loss: 243761070080.0000\n",
      "Epoch 319/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 347076384.0000 - val_loss: 243769114624.0000\n",
      "Epoch 320/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 541783872.0000 - val_loss: 243748765696.0000\n",
      "Epoch 321/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 358379680.0000 - val_loss: 243772047360.0000\n",
      "Epoch 322/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 396309760.0000 - val_loss: 243751567360.0000\n",
      "Epoch 323/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 353100288.0000 - val_loss: 243763298304.0000\n",
      "Epoch 324/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 368311520.0000 - val_loss: 243772948480.0000\n",
      "Epoch 325/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 384605824.0000 - val_loss: 243755450368.0000\n",
      "Epoch 326/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 460242400.0000 - val_loss: 243775143936.0000\n",
      "Epoch 327/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 335451136.0000 - val_loss: 243741474816.0000\n",
      "Epoch 328/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 1131318144.0000 - val_loss: 243755679744.0000\n",
      "Epoch 329/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 438198688.0000 - val_loss: 243781435392.0000\n",
      "Epoch 330/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 314504640.0000 - val_loss: 243710574592.0000\n",
      "Epoch 331/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 380024896.0000 - val_loss: 243702743040.0000\n",
      "Epoch 332/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 333291328.0000 - val_loss: 243762642944.0000\n",
      "Epoch 333/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 365036384.0000 - val_loss: 243752796160.0000\n",
      "Epoch 334/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 313745472.0000 - val_loss: 243768131584.0000\n",
      "Epoch 335/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 341504544.0000 - val_loss: 243726893056.0000\n",
      "Epoch 336/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 369645632.0000 - val_loss: 243731070976.0000\n",
      "Epoch 337/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 425897472.0000 - val_loss: 243735461888.0000\n",
      "Epoch 338/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 318054976.0000 - val_loss: 243782270976.0000\n",
      "Epoch 339/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 353014976.0000 - val_loss: 243766444032.0000\n",
      "Epoch 340/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 597048896.0000 - val_loss: 243770327040.0000\n",
      "Epoch 341/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 359807648.0000 - val_loss: 243753009152.0000\n",
      "Epoch 342/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 409356800.0000 - val_loss: 243742605312.0000\n",
      "Epoch 343/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 417144832.0000 - val_loss: 243776782336.0000\n",
      "Epoch 344/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 361138368.0000 - val_loss: 243756679168.0000\n",
      "Epoch 345/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 373037152.0000 - val_loss: 243730481152.0000\n",
      "Epoch 346/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 314953184.0000 - val_loss: 243735281664.0000\n",
      "Epoch 347/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 367208192.0000 - val_loss: 243771228160.0000\n",
      "Epoch 348/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 539405568.0000 - val_loss: 243737886720.0000\n",
      "Epoch 349/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 428677216.0000 - val_loss: 243771080704.0000\n",
      "Epoch 350/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 425575712.0000 - val_loss: 243765444608.0000\n",
      "Epoch 351/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 317457696.0000 - val_loss: 243739656192.0000\n",
      "Epoch 352/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 511652352.0000 - val_loss: 243795345408.0000\n",
      "Epoch 353/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 399518176.0000 - val_loss: 243729793024.0000\n",
      "Epoch 354/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 390545024.0000 - val_loss: 243730415616.0000\n",
      "Epoch 355/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 370759008.0000 - val_loss: 243733200896.0000\n",
      "Epoch 356/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 409633632.0000 - val_loss: 243734478848.0000\n",
      "Epoch 357/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 324386496.0000 - val_loss: 243734478848.0000\n",
      "Epoch 358/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 357608320.0000 - val_loss: 243745046528.0000\n",
      "Epoch 359/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 1317489536.0000 - val_loss: 243926433792.0000\n",
      "Epoch 360/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 396642816.0000 - val_loss: 243757531136.0000\n",
      "Epoch 361/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 403501728.0000 - val_loss: 243766427648.0000\n",
      "Epoch 362/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 466615360.0000 - val_loss: 243738492928.0000\n",
      "Epoch 363/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 2151713024.0000 - val_loss: 243760300032.0000\n",
      "Epoch 364/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 317581024.0000 - val_loss: 243754811392.0000\n",
      "Epoch 365/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 564444288.0000 - val_loss: 243742736384.0000\n",
      "Epoch 366/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 378058848.0000 - val_loss: 243734593536.0000\n",
      "Epoch 367/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 422032192.0000 - val_loss: 243752042496.0000\n",
      "Epoch 368/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 415989824.0000 - val_loss: 243757645824.0000\n",
      "Epoch 369/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 322020160.0000 - val_loss: 243722371072.0000\n",
      "Epoch 370/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 367194208.0000 - val_loss: 243746635776.0000\n",
      "Epoch 371/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 420859072.0000 - val_loss: 243746045952.0000\n",
      "Epoch 372/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 342026432.0000 - val_loss: 243715883008.0000\n",
      "Epoch 373/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 363297024.0000 - val_loss: 243721879552.0000\n",
      "Epoch 374/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 639157696.0000 - val_loss: 243757154304.0000\n",
      "Epoch 375/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 355202144.0000 - val_loss: 243710754816.0000\n",
      "Epoch 376/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 325719968.0000 - val_loss: 243739246592.0000\n",
      "Epoch 377/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 314526880.0000 - val_loss: 243768983552.0000\n",
      "Epoch 378/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 1777364992.0000 - val_loss: 243737149440.0000\n",
      "Epoch 379/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 344927232.0000 - val_loss: 243832815616.0000\n",
      "Epoch 380/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 405771456.0000 - val_loss: 243759284224.0000\n",
      "Epoch 381/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 378442880.0000 - val_loss: 243737034752.0000\n",
      "Epoch 382/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 507136096.0000 - val_loss: 243732791296.0000\n",
      "Epoch 383/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 302435744.0000 - val_loss: 243758972928.0000\n",
      "Epoch 384/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 417783584.0000 - val_loss: 243742343168.0000\n",
      "Epoch 385/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 366173024.0000 - val_loss: 243724845056.0000\n",
      "Epoch 386/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 309748960.0000 - val_loss: 243739820032.0000\n",
      "Epoch 387/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 377061792.0000 - val_loss: 243731611648.0000\n",
      "Epoch 388/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 399134304.0000 - val_loss: 243725467648.0000\n",
      "Epoch 389/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 376444992.0000 - val_loss: 243771867136.0000\n",
      "Epoch 390/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 401923424.0000 - val_loss: 243748306944.0000\n",
      "Epoch 391/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 427778848.0000 - val_loss: 243740639232.0000\n",
      "Epoch 392/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 379938688.0000 - val_loss: 243725959168.0000\n",
      "Epoch 393/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 338355040.0000 - val_loss: 243722698752.0000\n",
      "Epoch 394/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 403207648.0000 - val_loss: 243738263552.0000\n",
      "Epoch 395/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 315635424.0000 - val_loss: 243741048832.0000\n",
      "Epoch 396/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 321941856.0000 - val_loss: 243765657600.0000\n",
      "Epoch 397/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 341603552.0000 - val_loss: 243754647552.0000\n",
      "Epoch 398/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 408651264.0000 - val_loss: 243746652160.0000\n",
      "Epoch 399/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - loss: 390701824.0000 - val_loss: 243758874624.0000\n",
      "Epoch 400/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 322752544.0000 - val_loss: 243723337728.0000\n",
      "Epoch 401/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 493503424.0000 - val_loss: 243735003136.0000\n",
      "Epoch 402/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 346834688.0000 - val_loss: 243734609920.0000\n",
      "Epoch 403/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 327049184.0000 - val_loss: 243737100288.0000\n",
      "Epoch 404/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 347934720.0000 - val_loss: 243735674880.0000\n",
      "Epoch 405/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 376720032.0000 - val_loss: 243837403136.0000\n",
      "Epoch 406/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 309414720.0000 - val_loss: 243732676608.0000\n",
      "Epoch 407/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 14699551744.0000 - val_loss: 243770425344.0000\n",
      "Epoch 408/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 524165664.0000 - val_loss: 243745161216.0000\n",
      "Epoch 409/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 748845760.0000 - val_loss: 243733217280.0000\n",
      "Epoch 410/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 419838528.0000 - val_loss: 243736936448.0000\n",
      "Epoch 411/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 6900865536.0000 - val_loss: 243698810880.0000\n",
      "Epoch 412/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 348205152.0000 - val_loss: 243728515072.0000\n",
      "Epoch 413/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 17076866048.0000 - val_loss: 243731398656.0000\n",
      "Epoch 414/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 331237568.0000 - val_loss: 243722420224.0000\n",
      "Epoch 415/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 506107904.0000 - val_loss: 243718750208.0000\n",
      "Epoch 416/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 438671936.0000 - val_loss: 243724288000.0000\n",
      "Epoch 417/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 334249664.0000 - val_loss: 243746979840.0000\n",
      "Epoch 418/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 412197856.0000 - val_loss: 243740639232.0000\n",
      "Epoch 419/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 360491008.0000 - val_loss: 243741196288.0000\n",
      "Epoch 420/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 351834176.0000 - val_loss: 243729694720.0000\n",
      "Epoch 421/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 326178624.0000 - val_loss: 243717423104.0000\n",
      "Epoch 422/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 940782976.0000 - val_loss: 243708706816.0000\n",
      "Epoch 423/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 339348512.0000 - val_loss: 243716980736.0000\n",
      "Epoch 424/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 319890144.0000 - val_loss: 243700875264.0000\n",
      "Epoch 425/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 295891328.0000 - val_loss: 243726057472.0000\n",
      "Epoch 426/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 296481152.0000 - val_loss: 243739033600.0000\n",
      "Epoch 427/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 356312640.0000 - val_loss: 243738853376.0000\n",
      "Epoch 428/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 371268224.0000 - val_loss: 243718340608.0000\n",
      "Epoch 429/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 484341824.0000 - val_loss: 243749109760.0000\n",
      "Epoch 430/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 316692608.0000 - val_loss: 243745275904.0000\n",
      "Epoch 431/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 329424672.0000 - val_loss: 243722256384.0000\n",
      "Epoch 432/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 356863392.0000 - val_loss: 243745439744.0000\n",
      "Epoch 433/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 356425440.0000 - val_loss: 243746799616.0000\n",
      "Epoch 434/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 366260704.0000 - val_loss: 243726286848.0000\n",
      "Epoch 435/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 495124032.0000 - val_loss: 243768360960.0000\n",
      "Epoch 436/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 387989664.0000 - val_loss: 243717963776.0000\n",
      "Epoch 437/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 344049152.0000 - val_loss: 243730530304.0000\n",
      "Epoch 438/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 335666240.0000 - val_loss: 243742048256.0000\n",
      "Epoch 439/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 332427712.0000 - val_loss: 243744407552.0000\n",
      "Epoch 440/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 325280640.0000 - val_loss: 243730694144.0000\n",
      "Epoch 441/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 556352768.0000 - val_loss: 243730169856.0000\n",
      "Epoch 442/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 417959584.0000 - val_loss: 243743326208.0000\n",
      "Epoch 443/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 336558016.0000 - val_loss: 243743440896.0000\n",
      "Epoch 444/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 415490432.0000 - val_loss: 243708493824.0000\n",
      "Epoch 445/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 383499744.0000 - val_loss: 243724238848.0000\n",
      "Epoch 446/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 328865472.0000 - val_loss: 243732955136.0000\n",
      "Epoch 447/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 380327232.0000 - val_loss: 243747143680.0000\n",
      "Epoch 448/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 352124000.0000 - val_loss: 243737542656.0000\n",
      "Epoch 449/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 340193408.0000 - val_loss: 243733643264.0000\n",
      "Epoch 450/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 580560320.0000 - val_loss: 243755712512.0000\n",
      "Epoch 451/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 378636256.0000 - val_loss: 243710754816.0000\n",
      "Epoch 452/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 451283104.0000 - val_loss: 243738689536.0000\n",
      "Epoch 453/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 350747968.0000 - val_loss: 243723321344.0000\n",
      "Epoch 454/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 324252704.0000 - val_loss: 243731480576.0000\n",
      "Epoch 455/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 339959616.0000 - val_loss: 243746275328.0000\n",
      "Epoch 456/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 381569888.0000 - val_loss: 243762479104.0000\n",
      "Epoch 457/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 702345664.0000 - val_loss: 243707379712.0000\n",
      "Epoch 458/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 341058272.0000 - val_loss: 243697893376.0000\n",
      "Epoch 459/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 349054880.0000 - val_loss: 243708116992.0000\n",
      "Epoch 460/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 343933760.0000 - val_loss: 243705724928.0000\n",
      "Epoch 461/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 329963520.0000 - val_loss: 243727548416.0000\n",
      "Epoch 462/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 291764704.0000 - val_loss: 243718225920.0000\n",
      "Epoch 463/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 380973728.0000 - val_loss: 243699499008.0000\n",
      "Epoch 464/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 454204256.0000 - val_loss: 243720470528.0000\n",
      "Epoch 465/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 389805376.0000 - val_loss: 243716554752.0000\n",
      "Epoch 466/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 478790976.0000 - val_loss: 243729940480.0000\n",
      "Epoch 467/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 327881568.0000 - val_loss: 243720601600.0000\n",
      "Epoch 468/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 349875936.0000 - val_loss: 243746390016.0000\n",
      "Epoch 469/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 403663840.0000 - val_loss: 243739443200.0000\n",
      "Epoch 470/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 558498752.0000 - val_loss: 243762266112.0000\n",
      "Epoch 471/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 368224128.0000 - val_loss: 243739181056.0000\n",
      "Epoch 472/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 380268256.0000 - val_loss: 243753304064.0000\n",
      "Epoch 473/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 350037024.0000 - val_loss: 243744980992.0000\n",
      "Epoch 474/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 307023200.0000 - val_loss: 243756236800.0000\n",
      "Epoch 475/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 305828352.0000 - val_loss: 243723616256.0000\n",
      "Epoch 476/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 370701120.0000 - val_loss: 243747078144.0000\n",
      "Epoch 477/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 351773600.0000 - val_loss: 243703529472.0000\n",
      "Epoch 478/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 469956416.0000 - val_loss: 243717029888.0000\n",
      "Epoch 479/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 343008000.0000 - val_loss: 243679526912.0000\n",
      "Epoch 480/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 321925408.0000 - val_loss: 243690700800.0000\n",
      "Epoch 481/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 362114240.0000 - val_loss: 243751862272.0000\n",
      "Epoch 482/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 331909280.0000 - val_loss: 243693158400.0000\n",
      "Epoch 483/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 370352064.0000 - val_loss: 243739705344.0000\n",
      "Epoch 484/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 549810240.0000 - val_loss: 243730120704.0000\n",
      "Epoch 485/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 456886080.0000 - val_loss: 243714064384.0000\n",
      "Epoch 486/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 823179136.0000 - val_loss: 243731890176.0000\n",
      "Epoch 487/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 327758240.0000 - val_loss: 243741671424.0000\n",
      "Epoch 488/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 381264640.0000 - val_loss: 243719225344.0000\n",
      "Epoch 489/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 400506176.0000 - val_loss: 243721895936.0000\n",
      "Epoch 490/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 313542592.0000 - val_loss: 243736772608.0000\n",
      "Epoch 491/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 456963808.0000 - val_loss: 243693076480.0000\n",
      "Epoch 492/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 386042304.0000 - val_loss: 243735887872.0000\n",
      "Epoch 493/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 439683808.0000 - val_loss: 243752960000.0000\n",
      "Epoch 494/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 334889344.0000 - val_loss: 243725008896.0000\n",
      "Epoch 495/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 336506304.0000 - val_loss: 243722551296.0000\n",
      "Epoch 496/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 395678176.0000 - val_loss: 243738345472.0000\n",
      "Epoch 497/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 415309568.0000 - val_loss: 243747143680.0000\n",
      "Epoch 498/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 332796160.0000 - val_loss: 243762528256.0000\n",
      "Epoch 499/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 439553696.0000 - val_loss: 243736182784.0000\n",
      "Epoch 500/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 449028512.0000 - val_loss: 243719864320.0000\n",
      "Epoch 501/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 387832128.0000 - val_loss: 243735494656.0000\n",
      "Epoch 502/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 357923904.0000 - val_loss: 243711000576.0000\n",
      "Epoch 503/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 314580096.0000 - val_loss: 243727499264.0000\n",
      "Epoch 504/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 353095136.0000 - val_loss: 243733381120.0000\n",
      "Epoch 505/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 618469824.0000 - val_loss: 243691225088.0000\n",
      "Epoch 506/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 324900320.0000 - val_loss: 243703431168.0000\n",
      "Epoch 507/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 349545568.0000 - val_loss: 243747176448.0000\n",
      "Epoch 508/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 332473984.0000 - val_loss: 243777536000.0000\n",
      "Epoch 509/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 496328960.0000 - val_loss: 243747995648.0000\n",
      "Epoch 510/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 337860608.0000 - val_loss: 243824099328.0000\n",
      "Epoch 511/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 386191296.0000 - val_loss: 243777634304.0000\n",
      "Epoch 512/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 346940576.0000 - val_loss: 243705217024.0000\n",
      "Epoch 513/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 347440032.0000 - val_loss: 243752157184.0000\n",
      "Epoch 514/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 399737984.0000 - val_loss: 243721306112.0000\n",
      "Epoch 515/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 392257184.0000 - val_loss: 243750338560.0000\n",
      "Epoch 516/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 363525248.0000 - val_loss: 243748143104.0000\n",
      "Epoch 517/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 366157856.0000 - val_loss: 243707592704.0000\n",
      "Epoch 518/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 486366592.0000 - val_loss: 243720945664.0000\n",
      "Epoch 519/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 455527264.0000 - val_loss: 243704872960.0000\n",
      "Epoch 520/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 386434144.0000 - val_loss: 243738476544.0000\n",
      "Epoch 521/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 478605312.0000 - val_loss: 243685425152.0000\n",
      "Epoch 522/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 390675008.0000 - val_loss: 243697106944.0000\n",
      "Epoch 523/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 374438400.0000 - val_loss: 243681525760.0000\n",
      "Epoch 524/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 310226272.0000 - val_loss: 243750436864.0000\n",
      "Epoch 525/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 320300608.0000 - val_loss: 243730333696.0000\n",
      "Epoch 526/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 370793984.0000 - val_loss: 243731513344.0000\n",
      "Epoch 527/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 302005760.0000 - val_loss: 243711655936.0000\n",
      "Epoch 528/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 332714400.0000 - val_loss: 243640926208.0000\n",
      "Epoch 529/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 384072128.0000 - val_loss: 243685097472.0000\n",
      "Epoch 530/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 318261664.0000 - val_loss: 243749191680.0000\n",
      "Epoch 531/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 345823936.0000 - val_loss: 243707543552.0000\n",
      "Epoch 532/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 472950624.0000 - val_loss: 243668320256.0000\n",
      "Epoch 533/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 326451552.0000 - val_loss: 243754483712.0000\n",
      "Epoch 534/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 401847104.0000 - val_loss: 243717029888.0000\n",
      "Epoch 535/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 318684192.0000 - val_loss: 243676610560.0000\n",
      "Epoch 536/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - loss: 338043008.0000 - val_loss: 243698597888.0000\n",
      "Epoch 537/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 534188448.0000 - val_loss: 243776536576.0000\n",
      "Epoch 538/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 982097024.0000 - val_loss: 243691585536.0000\n",
      "Epoch 539/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 344150208.0000 - val_loss: 243742556160.0000\n",
      "Epoch 540/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 372696992.0000 - val_loss: 243698810880.0000\n",
      "Epoch 541/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 295725312.0000 - val_loss: 243691929600.0000\n",
      "Epoch 542/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 394899008.0000 - val_loss: 243773259776.0000\n",
      "Epoch 543/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 655620800.0000 - val_loss: 243697041408.0000\n",
      "Epoch 544/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 299450816.0000 - val_loss: 243711541248.0000\n",
      "Epoch 545/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 401431520.0000 - val_loss: 243693535232.0000\n",
      "Epoch 546/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 608493184.0000 - val_loss: 243746390016.0000\n",
      "Epoch 547/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 334070336.0000 - val_loss: 243754713088.0000\n",
      "Epoch 548/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 327492192.0000 - val_loss: 243749093376.0000\n",
      "Epoch 549/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 326605760.0000 - val_loss: 243695321088.0000\n",
      "Epoch 550/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 419444320.0000 - val_loss: 243752091648.0000\n",
      "Epoch 551/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 375073056.0000 - val_loss: 243759382528.0000\n",
      "Epoch 552/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 291449824.0000 - val_loss: 243743145984.0000\n",
      "Epoch 553/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 398477632.0000 - val_loss: 243747291136.0000\n",
      "Epoch 554/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 291927200.0000 - val_loss: 243714523136.0000\n",
      "Epoch 555/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 313031712.0000 - val_loss: 243704119296.0000\n",
      "Epoch 556/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 356221920.0000 - val_loss: 243715588096.0000\n",
      "Epoch 557/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 355175776.0000 - val_loss: 243741704192.0000\n",
      "Epoch 558/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 370067968.0000 - val_loss: 243706970112.0000\n",
      "Epoch 559/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 307566720.0000 - val_loss: 243664650240.0000\n",
      "Epoch 560/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 320682240.0000 - val_loss: 243724042240.0000\n",
      "Epoch 561/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 353080864.0000 - val_loss: 243975929856.0000\n",
      "Epoch 562/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 378666720.0000 - val_loss: 243705135104.0000\n",
      "Epoch 563/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 312115136.0000 - val_loss: 243722272768.0000\n",
      "Epoch 564/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 327445824.0000 - val_loss: 243678724096.0000\n",
      "Epoch 565/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 323782560.0000 - val_loss: 243659587584.0000\n",
      "Epoch 566/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 411758336.0000 - val_loss: 243677413376.0000\n",
      "Epoch 567/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 419037888.0000 - val_loss: 243730956288.0000\n",
      "Epoch 568/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 358315232.0000 - val_loss: 243687915520.0000\n",
      "Epoch 569/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 540815488.0000 - val_loss: 243695026176.0000\n",
      "Epoch 570/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 306304384.0000 - val_loss: 243703742464.0000\n",
      "Epoch 571/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 398904352.0000 - val_loss: 243684327424.0000\n",
      "Epoch 572/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 543546880.0000 - val_loss: 243730972672.0000\n",
      "Epoch 573/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 340620512.0000 - val_loss: 243765592064.0000\n",
      "Epoch 574/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - loss: 2982600960.0000 - val_loss: 243754336256.0000\n",
      "Epoch 575/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 315620032.0000 - val_loss: 243724075008.0000\n",
      "Epoch 576/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 339552672.0000 - val_loss: 243734953984.0000\n",
      "Epoch 577/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 309725664.0000 - val_loss: 243703595008.0000\n",
      "Epoch 578/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 417806880.0000 - val_loss: 243718340608.0000\n",
      "Epoch 579/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 330950720.0000 - val_loss: 243744571392.0000\n",
      "Epoch 580/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 385929120.0000 - val_loss: 243730595840.0000\n",
      "Epoch 581/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 376137856.0000 - val_loss: 243670351872.0000\n",
      "Epoch 582/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 393871520.0000 - val_loss: 243685818368.0000\n",
      "Epoch 583/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 385460800.0000 - val_loss: 243674529792.0000\n",
      "Epoch 584/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 340825952.0000 - val_loss: 243736018944.0000\n",
      "Epoch 585/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 317187360.0000 - val_loss: 243678953472.0000\n",
      "Epoch 586/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 314074016.0000 - val_loss: 243666157568.0000\n",
      "Epoch 587/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 333867744.0000 - val_loss: 243675152384.0000\n",
      "Epoch 588/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 275144704.0000 - val_loss: 243734233088.0000\n",
      "Epoch 589/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 323807456.0000 - val_loss: 243748880384.0000\n",
      "Epoch 590/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 322574272.0000 - val_loss: 243704463360.0000\n",
      "Epoch 591/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 403632928.0000 - val_loss: 243696353280.0000\n",
      "Epoch 592/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 307758112.0000 - val_loss: 243702005760.0000\n",
      "Epoch 593/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 317426144.0000 - val_loss: 243697041408.0000\n",
      "Epoch 594/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 286755680.0000 - val_loss: 243711426560.0000\n",
      "Epoch 595/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 2043939328.0000 - val_loss: 243670089728.0000\n",
      "Epoch 596/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 343511360.0000 - val_loss: 243707166720.0000\n",
      "Epoch 597/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 300823872.0000 - val_loss: 243690061824.0000\n",
      "Epoch 598/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 17631799296.0000 - val_loss: 243717259264.0000\n",
      "Epoch 599/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 302795520.0000 - val_loss: 243694682112.0000\n",
      "Epoch 600/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 302959744.0000 - val_loss: 243758055424.0000\n",
      "Epoch 601/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 352852352.0000 - val_loss: 243707609088.0000\n",
      "Epoch 602/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 368950496.0000 - val_loss: 243643252736.0000\n",
      "Epoch 603/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 306958080.0000 - val_loss: 243659538432.0000\n",
      "Epoch 604/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 366991904.0000 - val_loss: 243685670912.0000\n",
      "Epoch 605/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 4667216896.0000 - val_loss: 243729907712.0000\n",
      "Epoch 606/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 1470097664.0000 - val_loss: 243699875840.0000\n",
      "Epoch 607/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 334239424.0000 - val_loss: 243716718592.0000\n",
      "Epoch 608/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 372495936.0000 - val_loss: 243717799936.0000\n",
      "Epoch 609/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 305393280.0000 - val_loss: 243735281664.0000\n",
      "Epoch 610/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 443098944.0000 - val_loss: 243703906304.0000\n",
      "Epoch 611/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 296559552.0000 - val_loss: 243685195776.0000\n",
      "Epoch 612/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 358538944.0000 - val_loss: 243747864576.0000\n",
      "Epoch 613/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 394937280.0000 - val_loss: 243736821760.0000\n",
      "Epoch 614/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 331032192.0000 - val_loss: 243684327424.0000\n",
      "Epoch 615/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 356662720.0000 - val_loss: 243734118400.0000\n",
      "Epoch 616/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 341627424.0000 - val_loss: 243748618240.0000\n",
      "Epoch 617/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 432131104.0000 - val_loss: 243726794752.0000\n",
      "Epoch 618/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 387971552.0000 - val_loss: 243739017216.0000\n",
      "Epoch 619/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - loss: 425788256.0000 - val_loss: 243689340928.0000\n",
      "Epoch 620/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 398509504.0000 - val_loss: 243721207808.0000\n",
      "Epoch 621/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 332293728.0000 - val_loss: 243712409600.0000\n",
      "Epoch 622/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 340716480.0000 - val_loss: 243724337152.0000\n",
      "Epoch 623/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 348107168.0000 - val_loss: 243744833536.0000\n",
      "Epoch 624/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 540416192.0000 - val_loss: 243735887872.0000\n",
      "Epoch 625/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 396342144.0000 - val_loss: 243748552704.0000\n",
      "Epoch 626/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 405665696.0000 - val_loss: 243657129984.0000\n",
      "Epoch 627/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 356691840.0000 - val_loss: 243692273664.0000\n",
      "Epoch 628/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 308117088.0000 - val_loss: 243669549056.0000\n",
      "Epoch 629/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 322520000.0000 - val_loss: 243673939968.0000\n",
      "Epoch 630/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 405077024.0000 - val_loss: 243712311296.0000\n",
      "Epoch 631/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 288153440.0000 - val_loss: 243661733888.0000\n",
      "Epoch 632/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 332332352.0000 - val_loss: 243738771456.0000\n",
      "Epoch 633/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 327698752.0000 - val_loss: 243688783872.0000\n",
      "Epoch 634/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 365285280.0000 - val_loss: 243709247488.0000\n",
      "Epoch 635/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 308122464.0000 - val_loss: 243658571776.0000\n",
      "Epoch 636/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 301728992.0000 - val_loss: 243688701952.0000\n",
      "Epoch 637/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 348681792.0000 - val_loss: 243680772096.0000\n",
      "Epoch 638/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 304085088.0000 - val_loss: 243720339456.0000\n",
      "Epoch 639/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 385583424.0000 - val_loss: 243712704512.0000\n",
      "Epoch 640/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 306336992.0000 - val_loss: 243639533568.0000\n",
      "Epoch 641/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 505595936.0000 - val_loss: 243743621120.0000\n",
      "Epoch 642/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - loss: 333739968.0000 - val_loss: 243699613696.0000\n",
      "Epoch 643/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 327857952.0000 - val_loss: 243693780992.0000\n",
      "Epoch 644/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 274163488.0000 - val_loss: 243683606528.0000\n",
      "Epoch 645/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 1072640256.0000 - val_loss: 243725828096.0000\n",
      "Epoch 646/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 280520000.0000 - val_loss: 243672137728.0000\n",
      "Epoch 647/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 321739008.0000 - val_loss: 243730415616.0000\n",
      "Epoch 648/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 340498432.0000 - val_loss: 243698597888.0000\n",
      "Epoch 649/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 297960704.0000 - val_loss: 243683098624.0000\n",
      "Epoch 650/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 288259680.0000 - val_loss: 243650560000.0000\n",
      "Epoch 651/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 258340080.0000 - val_loss: 243646251008.0000\n",
      "Epoch 652/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 312131872.0000 - val_loss: 243700350976.0000\n",
      "Epoch 653/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - loss: 348492416.0000 - val_loss: 243659735040.0000\n",
      "Epoch 654/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 263380960.0000 - val_loss: 243666747392.0000\n",
      "Epoch 655/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 339715968.0000 - val_loss: 243648217088.0000\n",
      "Epoch 656/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 298354720.0000 - val_loss: 243730022400.0000\n",
      "Epoch 657/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 288991744.0000 - val_loss: 243658588160.0000\n",
      "Epoch 658/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 273040064.0000 - val_loss: 243664158720.0000\n",
      "Epoch 659/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 764573376.0000 - val_loss: 243757727744.0000\n",
      "Epoch 660/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 318581824.0000 - val_loss: 243658407936.0000\n",
      "Epoch 661/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 356556864.0000 - val_loss: 243719536640.0000\n",
      "Epoch 662/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 302054816.0000 - val_loss: 243693846528.0000\n",
      "Epoch 663/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 382562528.0000 - val_loss: 243668287488.0000\n",
      "Epoch 664/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 318925408.0000 - val_loss: 243663372288.0000\n",
      "Epoch 665/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 310489856.0000 - val_loss: 243757367296.0000\n",
      "Epoch 666/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 340481856.0000 - val_loss: 243733741568.0000\n",
      "Epoch 667/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 331333376.0000 - val_loss: 243713851392.0000\n",
      "Epoch 668/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 347379584.0000 - val_loss: 243675234304.0000\n",
      "Epoch 669/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 298740288.0000 - val_loss: 243643695104.0000\n",
      "Epoch 670/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 250589680.0000 - val_loss: 243697565696.0000\n",
      "Epoch 671/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 297199424.0000 - val_loss: 243715375104.0000\n",
      "Epoch 672/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 305386336.0000 - val_loss: 243688669184.0000\n",
      "Epoch 673/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 291599584.0000 - val_loss: 243643432960.0000\n",
      "Epoch 674/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 333814912.0000 - val_loss: 243681083392.0000\n",
      "Epoch 675/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 329659840.0000 - val_loss: 243710001152.0000\n",
      "Epoch 676/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 341575136.0000 - val_loss: 243633029120.0000\n",
      "Epoch 677/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 297731840.0000 - val_loss: 243690749952.0000\n",
      "Epoch 678/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 307944832.0000 - val_loss: 243704184832.0000\n",
      "Epoch 679/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 318213024.0000 - val_loss: 243715506176.0000\n",
      "Epoch 680/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 317233056.0000 - val_loss: 243737755648.0000\n",
      "Epoch 681/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 307723904.0000 - val_loss: 243656818688.0000\n",
      "Epoch 682/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 289299040.0000 - val_loss: 243728941056.0000\n",
      "Epoch 683/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 282048256.0000 - val_loss: 243673677824.0000\n",
      "Epoch 684/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 338027872.0000 - val_loss: 243756580864.0000\n",
      "Epoch 685/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 933253376.0000 - val_loss: 243756564480.0000\n",
      "Epoch 686/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 448954592.0000 - val_loss: 243780321280.0000\n",
      "Epoch 687/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 331325472.0000 - val_loss: 243695435776.0000\n",
      "Epoch 688/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 299420960.0000 - val_loss: 243824279552.0000\n",
      "Epoch 689/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 360244544.0000 - val_loss: 243740884992.0000\n",
      "Epoch 690/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 363224896.0000 - val_loss: 243766558720.0000\n",
      "Epoch 691/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 312377408.0000 - val_loss: 243726204928.0000\n",
      "Epoch 692/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 318352192.0000 - val_loss: 243715719168.0000\n",
      "Epoch 693/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 321424256.0000 - val_loss: 243672940544.0000\n",
      "Epoch 694/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 311693152.0000 - val_loss: 243709689856.0000\n",
      "Epoch 695/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 415076480.0000 - val_loss: 243767279616.0000\n",
      "Epoch 696/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 416088640.0000 - val_loss: 243718389760.0000\n",
      "Epoch 697/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 326737248.0000 - val_loss: 243702104064.0000\n",
      "Epoch 698/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 337349152.0000 - val_loss: 243816890368.0000\n",
      "Epoch 699/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 284249632.0000 - val_loss: 243773898752.0000\n",
      "Epoch 700/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 281239392.0000 - val_loss: 243698515968.0000\n",
      "Epoch 701/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 342180096.0000 - val_loss: 243787890688.0000\n",
      "Epoch 702/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 316119616.0000 - val_loss: 243684655104.0000\n",
      "Epoch 703/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 282298688.0000 - val_loss: 243701956608.0000\n",
      "Epoch 704/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 546798528.0000 - val_loss: 243698483200.0000\n",
      "Epoch 705/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 275467488.0000 - val_loss: 243666305024.0000\n",
      "Epoch 706/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 300333152.0000 - val_loss: 243744260096.0000\n",
      "Epoch 707/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 324696992.0000 - val_loss: 243762823168.0000\n",
      "Epoch 708/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 282815968.0000 - val_loss: 243634733056.0000\n",
      "Epoch 709/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 299782464.0000 - val_loss: 243686359040.0000\n",
      "Epoch 710/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 272081536.0000 - val_loss: 243702546432.0000\n",
      "Epoch 711/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 353365056.0000 - val_loss: 243736477696.0000\n",
      "Epoch 712/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 285256480.0000 - val_loss: 243749437440.0000\n",
      "Epoch 713/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 392927648.0000 - val_loss: 243729203200.0000\n",
      "Epoch 714/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 364056384.0000 - val_loss: 243677577216.0000\n",
      "Epoch 715/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 370317984.0000 - val_loss: 243761643520.0000\n",
      "Epoch 716/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 296394144.0000 - val_loss: 243630145536.0000\n",
      "Epoch 717/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 292638144.0000 - val_loss: 243796328448.0000\n",
      "Epoch 718/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 342416672.0000 - val_loss: 243652968448.0000\n",
      "Epoch 719/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 314245216.0000 - val_loss: 243810861056.0000\n",
      "Epoch 720/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 352191584.0000 - val_loss: 243840172032.0000\n",
      "Epoch 721/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 350878688.0000 - val_loss: 243738640384.0000\n",
      "Epoch 722/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 320965952.0000 - val_loss: 243753107456.0000\n",
      "Epoch 723/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 288655264.0000 - val_loss: 243659948032.0000\n",
      "Epoch 724/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 288497984.0000 - val_loss: 243785482240.0000\n",
      "Epoch 725/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - loss: 292921600.0000 - val_loss: 243683803136.0000\n",
      "Epoch 726/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 286863520.0000 - val_loss: 243755122688.0000\n",
      "Epoch 727/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - loss: 281489408.0000 - val_loss: 243747291136.0000\n",
      "Epoch 728/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 262820720.0000 - val_loss: 243656392704.0000\n",
      "Epoch 729/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 280087296.0000 - val_loss: 243662258176.0000\n",
      "Epoch 730/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - loss: 292852704.0000 - val_loss: 243750797312.0000\n",
      "Epoch 731/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - loss: 312695264.0000 - val_loss: 243747061760.0000\n",
      "Epoch 732/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 318502624.0000 - val_loss: 243768770560.0000\n",
      "Epoch 733/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 398679168.0000 - val_loss: 243702546432.0000\n",
      "Epoch 734/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 325247872.0000 - val_loss: 243757547520.0000\n",
      "Epoch 735/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 294547712.0000 - val_loss: 243747864576.0000\n",
      "Epoch 736/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - loss: 292336352.0000 - val_loss: 243748880384.0000\n",
      "Epoch 737/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - loss: 343854112.0000 - val_loss: 243685130240.0000\n",
      "Epoch 738/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 316480416.0000 - val_loss: 243666796544.0000\n",
      "Epoch 739/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 334663680.0000 - val_loss: 243742556160.0000\n",
      "Epoch 740/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 246631216.0000 - val_loss: 243701940224.0000\n",
      "Epoch 741/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 317314720.0000 - val_loss: 243746439168.0000\n",
      "Epoch 742/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 302202080.0000 - val_loss: 243701399552.0000\n",
      "Epoch 743/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - loss: 309572128.0000 - val_loss: 243775258624.0000\n",
      "Epoch 744/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 296524256.0000 - val_loss: 243795509248.0000\n",
      "Epoch 745/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 306055296.0000 - val_loss: 243737034752.0000\n",
      "Epoch 746/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 339918560.0000 - val_loss: 243780190208.0000\n",
      "Epoch 747/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 341114112.0000 - val_loss: 243789545472.0000\n",
      "Epoch 748/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 358340704.0000 - val_loss: 243805913088.0000\n",
      "Epoch 749/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 288312512.0000 - val_loss: 243734446080.0000\n",
      "Epoch 750/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 320187360.0000 - val_loss: 243744129024.0000\n",
      "Epoch 751/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 307979936.0000 - val_loss: 243759759360.0000\n",
      "Epoch 752/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 300129536.0000 - val_loss: 243699744768.0000\n",
      "Epoch 753/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 282599584.0000 - val_loss: 243746160640.0000\n",
      "Epoch 754/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 416101152.0000 - val_loss: 243766444032.0000\n",
      "Epoch 755/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - loss: 341175680.0000 - val_loss: 243805044736.0000\n",
      "Epoch 756/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 332934464.0000 - val_loss: 243777257472.0000\n",
      "Epoch 757/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 396115776.0000 - val_loss: 243742425088.0000\n",
      "Epoch 758/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 298509440.0000 - val_loss: 243732873216.0000\n",
      "Epoch 759/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 414207456.0000 - val_loss: 243746586624.0000\n",
      "Epoch 760/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 276012448.0000 - val_loss: 243763970048.0000\n",
      "Epoch 761/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 372617568.0000 - val_loss: 243747782656.0000\n",
      "Epoch 762/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 258148320.0000 - val_loss: 243787988992.0000\n",
      "Epoch 763/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 388359072.0000 - val_loss: 243722747904.0000\n",
      "Epoch 764/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 296081184.0000 - val_loss: 243741491200.0000\n",
      "Epoch 765/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 277050272.0000 - val_loss: 243743080448.0000\n",
      "Epoch 766/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 310631360.0000 - val_loss: 243771654144.0000\n",
      "Epoch 767/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 310946368.0000 - val_loss: 243893829632.0000\n",
      "Epoch 768/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 342693664.0000 - val_loss: 243872694272.0000\n",
      "Epoch 769/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 270476192.0000 - val_loss: 243697106944.0000\n",
      "Epoch 770/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 352171712.0000 - val_loss: 243903217664.0000\n",
      "Epoch 771/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 278511136.0000 - val_loss: 243664175104.0000\n",
      "Epoch 772/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 294964320.0000 - val_loss: 243672940544.0000\n",
      "Epoch 773/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 263225728.0000 - val_loss: 243698974720.0000\n",
      "Epoch 774/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - loss: 334309344.0000 - val_loss: 243767033856.0000\n",
      "Epoch 775/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 285197984.0000 - val_loss: 243742703616.0000\n",
      "Epoch 776/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 390627072.0000 - val_loss: 243781910528.0000\n",
      "Epoch 777/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 275793280.0000 - val_loss: 243740835840.0000\n",
      "Epoch 778/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 336344928.0000 - val_loss: 243822133248.0000\n",
      "Epoch 779/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 373558272.0000 - val_loss: 243807420416.0000\n",
      "Epoch 780/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 319179040.0000 - val_loss: 243772784640.0000\n",
      "Epoch 781/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 294341056.0000 - val_loss: 243768000512.0000\n",
      "Epoch 782/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 362628800.0000 - val_loss: 243687047168.0000\n",
      "Epoch 783/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 379394432.0000 - val_loss: 243783630848.0000\n",
      "Epoch 784/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 283847968.0000 - val_loss: 243756302336.0000\n",
      "Epoch 785/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 308927424.0000 - val_loss: 243749650432.0000\n",
      "Epoch 786/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 297236576.0000 - val_loss: 243788742656.0000\n",
      "Epoch 787/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 275700704.0000 - val_loss: 243738738688.0000\n",
      "Epoch 788/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - loss: 310780768.0000 - val_loss: 243752468480.0000\n",
      "Epoch 789/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 281520480.0000 - val_loss: 243826507776.0000\n",
      "Epoch 790/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - loss: 342394688.0000 - val_loss: 243707052032.0000\n",
      "Epoch 791/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 311130592.0000 - val_loss: 243766263808.0000\n",
      "Epoch 792/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 278996736.0000 - val_loss: 243757514752.0000\n",
      "Epoch 793/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 262601296.0000 - val_loss: 243840335872.0000\n",
      "Epoch 794/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 308753504.0000 - val_loss: 243837763584.0000\n",
      "Epoch 795/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 306404992.0000 - val_loss: 243726909440.0000\n",
      "Epoch 796/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 276203616.0000 - val_loss: 243855753216.0000\n",
      "Epoch 797/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 290834944.0000 - val_loss: 243758907392.0000\n",
      "Epoch 798/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 317467968.0000 - val_loss: 243748831232.0000\n",
      "Epoch 799/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 14714482688.0000 - val_loss: 243751944192.0000\n",
      "Epoch 800/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 1159016576.0000 - val_loss: 243932921856.0000\n",
      "Epoch 801/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 381470208.0000 - val_loss: 243830996992.0000\n",
      "Epoch 802/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 377129504.0000 - val_loss: 243781124096.0000\n",
      "Epoch 803/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 300691872.0000 - val_loss: 243781648384.0000\n",
      "Epoch 804/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 343621120.0000 - val_loss: 243802193920.0000\n",
      "Epoch 805/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 281812832.0000 - val_loss: 243736363008.0000\n",
      "Epoch 806/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 280233760.0000 - val_loss: 243704037376.0000\n",
      "Epoch 807/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 291185632.0000 - val_loss: 243789742080.0000\n",
      "Epoch 808/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 319067328.0000 - val_loss: 243761627136.0000\n",
      "Epoch 809/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 306870752.0000 - val_loss: 243723714560.0000\n",
      "Epoch 810/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 308360320.0000 - val_loss: 243715031040.0000\n",
      "Epoch 811/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 286659680.0000 - val_loss: 243777585152.0000\n",
      "Epoch 812/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 333477632.0000 - val_loss: 243713507328.0000\n",
      "Epoch 813/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 365068608.0000 - val_loss: 243763544064.0000\n",
      "Epoch 814/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 287598528.0000 - val_loss: 243734659072.0000\n",
      "Epoch 815/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 296797472.0000 - val_loss: 243724042240.0000\n",
      "Epoch 816/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 352564352.0000 - val_loss: 243698122752.0000\n",
      "Epoch 817/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 286602080.0000 - val_loss: 243762741248.0000\n",
      "Epoch 818/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 265226128.0000 - val_loss: 243687276544.0000\n",
      "Epoch 819/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 252631952.0000 - val_loss: 243684458496.0000\n",
      "Epoch 820/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 290796480.0000 - val_loss: 243760021504.0000\n",
      "Epoch 821/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 280511328.0000 - val_loss: 243640582144.0000\n",
      "Epoch 822/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 285790208.0000 - val_loss: 243778224128.0000\n",
      "Epoch 823/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 325943264.0000 - val_loss: 243726548992.0000\n",
      "Epoch 824/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 254773872.0000 - val_loss: 243786825728.0000\n",
      "Epoch 825/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 279587808.0000 - val_loss: 243755073536.0000\n",
      "Epoch 826/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 275122528.0000 - val_loss: 243730268160.0000\n",
      "Epoch 827/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 401020576.0000 - val_loss: 243724075008.0000\n",
      "Epoch 828/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 44130553856.0000 - val_loss: 243854049280.0000\n",
      "Epoch 829/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 10356503552.0000 - val_loss: 243791462400.0000\n",
      "Epoch 830/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 5039012864.0000 - val_loss: 243672940544.0000\n",
      "Epoch 831/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 342458816.0000 - val_loss: 243742343168.0000\n",
      "Epoch 832/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 330960320.0000 - val_loss: 243708919808.0000\n",
      "Epoch 833/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 335174176.0000 - val_loss: 243709050880.0000\n",
      "Epoch 834/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 43670863872.0000 - val_loss: 243715981312.0000\n",
      "Epoch 835/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 554662080.0000 - val_loss: 243712720896.0000\n",
      "Epoch 836/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - loss: 472057824.0000 - val_loss: 243687538688.0000\n",
      "Epoch 837/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 321522048.0000 - val_loss: 243695976448.0000\n",
      "Epoch 838/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 301154624.0000 - val_loss: 243691274240.0000\n",
      "Epoch 839/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 839821248.0000 - val_loss: 243694911488.0000\n",
      "Epoch 840/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 364133824.0000 - val_loss: 243734691840.0000\n",
      "Epoch 841/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 311143232.0000 - val_loss: 243744669696.0000\n",
      "Epoch 842/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 388205024.0000 - val_loss: 243732316160.0000\n",
      "Epoch 843/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 358652704.0000 - val_loss: 243730104320.0000\n",
      "Epoch 844/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - loss: 324980640.0000 - val_loss: 243708346368.0000\n",
      "Epoch 845/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 301166112.0000 - val_loss: 243748618240.0000\n",
      "Epoch 846/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 335205760.0000 - val_loss: 243737460736.0000\n",
      "Epoch 847/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 292253728.0000 - val_loss: 243704922112.0000\n",
      "Epoch 848/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 345885696.0000 - val_loss: 243721568256.0000\n",
      "Epoch 849/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 308617152.0000 - val_loss: 243721732096.0000\n",
      "Epoch 850/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - loss: 341954944.0000 - val_loss: 243748519936.0000\n",
      "Epoch 851/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 291887040.0000 - val_loss: 243714375680.0000\n",
      "Epoch 852/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 299127424.0000 - val_loss: 243716554752.0000\n",
      "Epoch 853/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 340350816.0000 - val_loss: 243775029248.0000\n",
      "Epoch 854/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 345479200.0000 - val_loss: 243750813696.0000\n",
      "Epoch 855/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 325051904.0000 - val_loss: 243744604160.0000\n",
      "Epoch 856/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 312841376.0000 - val_loss: 243755024384.0000\n",
      "Epoch 857/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 301996352.0000 - val_loss: 243727220736.0000\n",
      "Epoch 858/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 312146208.0000 - val_loss: 243768098816.0000\n",
      "Epoch 859/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 301291456.0000 - val_loss: 243732447232.0000\n",
      "Epoch 860/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - loss: 308788352.0000 - val_loss: 243777683456.0000\n",
      "Epoch 861/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 308462464.0000 - val_loss: 243712983040.0000\n",
      "Epoch 862/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 336306016.0000 - val_loss: 243743653888.0000\n",
      "Epoch 863/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 298509824.0000 - val_loss: 243725221888.0000\n",
      "Epoch 864/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 324071872.0000 - val_loss: 243757531136.0000\n",
      "Epoch 865/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 336290784.0000 - val_loss: 243748192256.0000\n",
      "Epoch 866/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 293130432.0000 - val_loss: 243724075008.0000\n",
      "Epoch 867/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 300029792.0000 - val_loss: 243743752192.0000\n",
      "Epoch 868/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 277493824.0000 - val_loss: 243688292352.0000\n",
      "Epoch 869/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 292258688.0000 - val_loss: 243727695872.0000\n",
      "Epoch 870/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 264054736.0000 - val_loss: 243711016960.0000\n",
      "Epoch 871/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 271508288.0000 - val_loss: 243772948480.0000\n",
      "Epoch 872/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 281515936.0000 - val_loss: 243739934720.0000\n",
      "Epoch 873/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 284333952.0000 - val_loss: 243760644096.0000\n",
      "Epoch 874/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 251289136.0000 - val_loss: 243754483712.0000\n",
      "Epoch 875/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 284861632.0000 - val_loss: 243724042240.0000\n",
      "Epoch 876/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 294567936.0000 - val_loss: 243805601792.0000\n",
      "Epoch 877/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 341256256.0000 - val_loss: 243620397056.0000\n",
      "Epoch 878/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 354369280.0000 - val_loss: 243771392000.0000\n",
      "Epoch 879/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 286814592.0000 - val_loss: 243823050752.0000\n",
      "Epoch 880/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 298732864.0000 - val_loss: 243768262656.0000\n",
      "Epoch 881/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 241352480.0000 - val_loss: 243769409536.0000\n",
      "Epoch 882/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 312902624.0000 - val_loss: 243802750976.0000\n",
      "Epoch 883/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 526423072.0000 - val_loss: 243784859648.0000\n",
      "Epoch 884/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 281626272.0000 - val_loss: 243755286528.0000\n",
      "Epoch 885/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 277297856.0000 - val_loss: 243756040192.0000\n",
      "Epoch 886/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 268867200.0000 - val_loss: 243708395520.0000\n",
      "Epoch 887/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - loss: 317318400.0000 - val_loss: 243770507264.0000\n",
      "Epoch 888/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 306893344.0000 - val_loss: 243757907968.0000\n",
      "Epoch 889/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 316531232.0000 - val_loss: 243747487744.0000\n",
      "Epoch 890/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 302992640.0000 - val_loss: 243772407808.0000\n",
      "Epoch 891/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 290499936.0000 - val_loss: 243776143360.0000\n",
      "Epoch 892/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 283533248.0000 - val_loss: 243755712512.0000\n",
      "Epoch 893/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 381293472.0000 - val_loss: 243817021440.0000\n",
      "Epoch 894/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - loss: 311001952.0000 - val_loss: 243785744384.0000\n",
      "Epoch 895/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 274814912.0000 - val_loss: 243783630848.0000\n",
      "Epoch 896/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 273753792.0000 - val_loss: 243838976000.0000\n",
      "Epoch 897/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 311435008.0000 - val_loss: 243702104064.0000\n",
      "Epoch 898/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 280386656.0000 - val_loss: 243829424128.0000\n",
      "Epoch 899/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 271081440.0000 - val_loss: 243741474816.0000\n",
      "Epoch 900/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 261355248.0000 - val_loss: 243846348800.0000\n",
      "Epoch 901/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 321545376.0000 - val_loss: 243800571904.0000\n",
      "Epoch 902/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 341630752.0000 - val_loss: 243803668480.0000\n",
      "Epoch 903/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 270401728.0000 - val_loss: 243822706688.0000\n",
      "Epoch 904/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 251160000.0000 - val_loss: 243835027456.0000\n",
      "Epoch 905/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 297910656.0000 - val_loss: 243797688320.0000\n",
      "Epoch 906/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 260971472.0000 - val_loss: 243788431360.0000\n",
      "Epoch 907/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 265802912.0000 - val_loss: 243675103232.0000\n",
      "Epoch 908/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 269013696.0000 - val_loss: 243861078016.0000\n",
      "Epoch 909/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 307439168.0000 - val_loss: 243809959936.0000\n",
      "Epoch 910/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 297746944.0000 - val_loss: 243808813056.0000\n",
      "Epoch 911/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 255829136.0000 - val_loss: 243837976576.0000\n",
      "Epoch 912/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 311473504.0000 - val_loss: 243832373248.0000\n",
      "Epoch 913/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 268769408.0000 - val_loss: 243732348928.0000\n",
      "Epoch 914/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 260296928.0000 - val_loss: 243790168064.0000\n",
      "Epoch 915/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 289417472.0000 - val_loss: 243762167808.0000\n",
      "Epoch 916/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 295861600.0000 - val_loss: 243754876928.0000\n",
      "Epoch 917/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 276027264.0000 - val_loss: 243743752192.0000\n",
      "Epoch 918/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 295732064.0000 - val_loss: 243836387328.0000\n",
      "Epoch 919/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 258990096.0000 - val_loss: 243720077312.0000\n",
      "Epoch 920/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 275860864.0000 - val_loss: 243732529152.0000\n",
      "Epoch 921/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 281666656.0000 - val_loss: 243817906176.0000\n",
      "Epoch 922/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - loss: 250680880.0000 - val_loss: 243871088640.0000\n",
      "Epoch 923/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 261007232.0000 - val_loss: 243790987264.0000\n",
      "Epoch 924/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 279983136.0000 - val_loss: 243830784000.0000\n",
      "Epoch 925/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 471130272.0000 - val_loss: 243717357568.0000\n",
      "Epoch 926/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 266540320.0000 - val_loss: 243825115136.0000\n",
      "Epoch 927/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 294676416.0000 - val_loss: 243798605824.0000\n",
      "Epoch 928/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 257900608.0000 - val_loss: 243788431360.0000\n",
      "Epoch 929/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 239580192.0000 - val_loss: 243776159744.0000\n",
      "Epoch 930/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 255455904.0000 - val_loss: 243739820032.0000\n",
      "Epoch 931/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 377053056.0000 - val_loss: 243694419968.0000\n",
      "Epoch 932/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 316145280.0000 - val_loss: 243803521024.0000\n",
      "Epoch 933/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 278800384.0000 - val_loss: 243858096128.0000\n",
      "Epoch 934/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - loss: 272457472.0000 - val_loss: 243784007680.0000\n",
      "Epoch 935/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 268183536.0000 - val_loss: 243879198720.0000\n",
      "Epoch 936/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - loss: 267138192.0000 - val_loss: 243767443456.0000\n",
      "Epoch 937/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 281242208.0000 - val_loss: 243767607296.0000\n",
      "Epoch 938/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - loss: 325298528.0000 - val_loss: 243790446592.0000\n",
      "Epoch 939/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 295738016.0000 - val_loss: 243725647872.0000\n",
      "Epoch 940/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 265300960.0000 - val_loss: 243874136064.0000\n",
      "Epoch 941/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 260289120.0000 - val_loss: 243850838016.0000\n",
      "Epoch 942/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 266958256.0000 - val_loss: 243761971200.0000\n",
      "Epoch 943/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - loss: 379976672.0000 - val_loss: 243790659584.0000\n",
      "Epoch 944/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 354680576.0000 - val_loss: 243746865152.0000\n",
      "Epoch 945/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 271789408.0000 - val_loss: 243752960000.0000\n",
      "Epoch 946/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 270864576.0000 - val_loss: 243713130496.0000\n",
      "Epoch 947/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 288841792.0000 - val_loss: 243747241984.0000\n",
      "Epoch 948/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 340674240.0000 - val_loss: 243720994816.0000\n",
      "Epoch 949/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 265028240.0000 - val_loss: 243711049728.0000\n",
      "Epoch 950/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 302294176.0000 - val_loss: 243698270208.0000\n",
      "Epoch 951/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 274403360.0000 - val_loss: 243759546368.0000\n",
      "Epoch 952/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 318023968.0000 - val_loss: 243773538304.0000\n",
      "Epoch 953/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 268976992.0000 - val_loss: 243843530752.0000\n",
      "Epoch 954/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 370849888.0000 - val_loss: 243801718784.0000\n",
      "Epoch 955/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - loss: 245631136.0000 - val_loss: 243828424704.0000\n",
      "Epoch 956/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 254335440.0000 - val_loss: 243854737408.0000\n",
      "Epoch 957/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - loss: 278041088.0000 - val_loss: 243825115136.0000\n",
      "Epoch 958/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 267156688.0000 - val_loss: 243813662720.0000\n",
      "Epoch 959/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 2669647104.0000 - val_loss: 243826409472.0000\n",
      "Epoch 960/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 257690576.0000 - val_loss: 243814776832.0000\n",
      "Epoch 961/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 301730912.0000 - val_loss: 243765657600.0000\n",
      "Epoch 962/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 268053024.0000 - val_loss: 243791282176.0000\n",
      "Epoch 963/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 280672672.0000 - val_loss: 243843317760.0000\n",
      "Epoch 964/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 279801536.0000 - val_loss: 243737034752.0000\n",
      "Epoch 965/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 284018720.0000 - val_loss: 243801292800.0000\n",
      "Epoch 966/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 273389408.0000 - val_loss: 243895681024.0000\n",
      "Epoch 967/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 273390720.0000 - val_loss: 243887276032.0000\n",
      "Epoch 968/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 282560704.0000 - val_loss: 243867140096.0000\n",
      "Epoch 969/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 268209392.0000 - val_loss: 243760742400.0000\n",
      "Epoch 970/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 270951808.0000 - val_loss: 243793281024.0000\n",
      "Epoch 971/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 294314080.0000 - val_loss: 243751763968.0000\n",
      "Epoch 972/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 250094640.0000 - val_loss: 243900661760.0000\n",
      "Epoch 973/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 299150496.0000 - val_loss: 243796672512.0000\n",
      "Epoch 974/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 298745536.0000 - val_loss: 243843743744.0000\n",
      "Epoch 975/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 303956288.0000 - val_loss: 243782696960.0000\n",
      "Epoch 976/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 290084096.0000 - val_loss: 243847004160.0000\n",
      "Epoch 977/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 277121856.0000 - val_loss: 243827884032.0000\n",
      "Epoch 978/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 312139104.0000 - val_loss: 243819347968.0000\n",
      "Epoch 979/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 267885632.0000 - val_loss: 243792510976.0000\n",
      "Epoch 980/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 305804800.0000 - val_loss: 243866632192.0000\n",
      "Epoch 981/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 316655552.0000 - val_loss: 243798753280.0000\n",
      "Epoch 982/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 286177792.0000 - val_loss: 243902464000.0000\n",
      "Epoch 983/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 290842816.0000 - val_loss: 243752419328.0000\n",
      "Epoch 984/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 270896032.0000 - val_loss: 243816579072.0000\n",
      "Epoch 985/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 316993280.0000 - val_loss: 243773276160.0000\n",
      "Epoch 986/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 328324544.0000 - val_loss: 243739705344.0000\n",
      "Epoch 987/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 268375008.0000 - val_loss: 243664912384.0000\n",
      "Epoch 988/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 271209216.0000 - val_loss: 243771949056.0000\n",
      "Epoch 989/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 258690944.0000 - val_loss: 243778715648.0000\n",
      "Epoch 990/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - loss: 253272704.0000 - val_loss: 243789053952.0000\n",
      "Epoch 991/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - loss: 259017520.0000 - val_loss: 243732447232.0000\n",
      "Epoch 992/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 287349216.0000 - val_loss: 243845169152.0000\n",
      "Epoch 993/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 293322880.0000 - val_loss: 243709214720.0000\n",
      "Epoch 994/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 255669504.0000 - val_loss: 243769606144.0000\n",
      "Epoch 995/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 300807648.0000 - val_loss: 243839860736.0000\n",
      "Epoch 996/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 280032832.0000 - val_loss: 243841105920.0000\n",
      "Epoch 997/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 269456320.0000 - val_loss: 243868712960.0000\n",
      "Epoch 998/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 249844176.0000 - val_loss: 243692552192.0000\n",
      "Epoch 999/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 280500352.0000 - val_loss: 243813498880.0000\n",
      "Epoch 1000/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 276615456.0000 - val_loss: 243840532480.0000\n",
      "Epoch 1001/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 574552704.0000 - val_loss: 243759808512.0000\n",
      "Epoch 1002/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 255431696.0000 - val_loss: 243831848960.0000\n",
      "Epoch 1003/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - loss: 259443248.0000 - val_loss: 243806126080.0000\n",
      "Epoch 1004/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 264269680.0000 - val_loss: 243754369024.0000\n",
      "Epoch 1005/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 290519424.0000 - val_loss: 243848593408.0000\n",
      "Epoch 1006/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 264704144.0000 - val_loss: 243779403776.0000\n",
      "Epoch 1007/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 255516944.0000 - val_loss: 243725303808.0000\n",
      "Epoch 1008/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 263764784.0000 - val_loss: 243804422144.0000\n",
      "Epoch 1009/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 249826736.0000 - val_loss: 243832815616.0000\n",
      "Epoch 1010/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 471204000.0000 - val_loss: 243723599872.0000\n",
      "Epoch 1011/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 282924224.0000 - val_loss: 243702464512.0000\n",
      "Epoch 1012/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 272956416.0000 - val_loss: 243719536640.0000\n",
      "Epoch 1013/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 263187024.0000 - val_loss: 243796000768.0000\n",
      "Epoch 1014/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 262246640.0000 - val_loss: 243679379456.0000\n",
      "Epoch 1015/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - loss: 302148480.0000 - val_loss: 243796901888.0000\n",
      "Epoch 1016/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 293611456.0000 - val_loss: 243694731264.0000\n",
      "Epoch 1017/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 302663040.0000 - val_loss: 243751337984.0000\n",
      "Epoch 1018/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 306810464.0000 - val_loss: 243822198784.0000\n",
      "Epoch 1019/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 335124320.0000 - val_loss: 243777208320.0000\n",
      "Epoch 1020/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 31820144640.0000 - val_loss: 243757203456.0000\n",
      "Epoch 1021/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 311013920.0000 - val_loss: 243700563968.0000\n",
      "Epoch 1022/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 303927648.0000 - val_loss: 243695861760.0000\n",
      "Epoch 1023/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - loss: 300271616.0000 - val_loss: 243729891328.0000\n",
      "Epoch 1024/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - loss: 300553600.0000 - val_loss: 243744079872.0000\n",
      "Epoch 1025/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 280411488.0000 - val_loss: 243723288576.0000\n",
      "Epoch 1026/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 304292192.0000 - val_loss: 243746373632.0000\n",
      "Epoch 1027/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 300094336.0000 - val_loss: 243694354432.0000\n",
      "Epoch 1028/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - loss: 292294272.0000 - val_loss: 243754549248.0000\n",
      "Epoch 1029/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 288493280.0000 - val_loss: 243756515328.0000\n",
      "Epoch 1030/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 290243264.0000 - val_loss: 243773816832.0000\n",
      "Epoch 1031/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 315490880.0000 - val_loss: 243789529088.0000\n",
      "Epoch 1032/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 294830272.0000 - val_loss: 243732496384.0000\n",
      "Epoch 1033/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 278449120.0000 - val_loss: 243781500928.0000\n",
      "Epoch 1034/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 305205056.0000 - val_loss: 243807256576.0000\n",
      "Epoch 1035/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 262176784.0000 - val_loss: 243765477376.0000\n",
      "Epoch 1036/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 259566912.0000 - val_loss: 243756744704.0000\n",
      "Epoch 1037/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 274341504.0000 - val_loss: 243649069056.0000\n",
      "Epoch 1038/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 271329184.0000 - val_loss: 243884490752.0000\n",
      "Epoch 1039/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 283244960.0000 - val_loss: 243648905216.0000\n",
      "Epoch 1040/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 308914688.0000 - val_loss: 243767574528.0000\n",
      "Epoch 1041/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 353798304.0000 - val_loss: 243773784064.0000\n",
      "Epoch 1042/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 263952176.0000 - val_loss: 243789791232.0000\n",
      "Epoch 1043/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 285724512.0000 - val_loss: 243811303424.0000\n",
      "Epoch 1044/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 261727312.0000 - val_loss: 243832799232.0000\n",
      "Epoch 1045/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 268714560.0000 - val_loss: 243878084608.0000\n",
      "Epoch 1046/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 253745472.0000 - val_loss: 243799179264.0000\n",
      "Epoch 1047/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 260240128.0000 - val_loss: 243748405248.0000\n",
      "Epoch 1048/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 254324128.0000 - val_loss: 243926466560.0000\n",
      "Epoch 1049/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 262229136.0000 - val_loss: 243776520192.0000\n",
      "Epoch 1050/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 288315392.0000 - val_loss: 243815989248.0000\n",
      "Epoch 1051/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 300483424.0000 - val_loss: 243784679424.0000\n",
      "Epoch 1052/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 263694928.0000 - val_loss: 243792101376.0000\n",
      "Epoch 1053/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 289197536.0000 - val_loss: 243832160256.0000\n",
      "Epoch 1054/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 230768000.0000 - val_loss: 243868532736.0000\n",
      "Epoch 1055/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 244715296.0000 - val_loss: 243908657152.0000\n",
      "Epoch 1056/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 250487456.0000 - val_loss: 243836125184.0000\n",
      "Epoch 1057/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 259848272.0000 - val_loss: 243828736000.0000\n",
      "Epoch 1058/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 309455776.0000 - val_loss: 243758055424.0000\n",
      "Epoch 1059/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 234985584.0000 - val_loss: 243794804736.0000\n",
      "Epoch 1060/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 255778720.0000 - val_loss: 243864928256.0000\n",
      "Epoch 1061/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 241262928.0000 - val_loss: 243777912832.0000\n",
      "Epoch 1062/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 237724320.0000 - val_loss: 243763920896.0000\n",
      "Epoch 1063/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 230120736.0000 - val_loss: 243790036992.0000\n",
      "Epoch 1064/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 310214176.0000 - val_loss: 243759611904.0000\n",
      "Epoch 1065/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 272582784.0000 - val_loss: 243828539392.0000\n",
      "Epoch 1066/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - loss: 269799040.0000 - val_loss: 243760021504.0000\n",
      "Epoch 1067/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 253894752.0000 - val_loss: 243731562496.0000\n",
      "Epoch 1068/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 260101184.0000 - val_loss: 243788906496.0000\n",
      "Epoch 1069/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 263170384.0000 - val_loss: 243805863936.0000\n",
      "Epoch 1070/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 13014675456.0000 - val_loss: 243814809600.0000\n",
      "Epoch 1071/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 482361568.0000 - val_loss: 243841695744.0000\n",
      "Epoch 1072/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 288479520.0000 - val_loss: 243748093952.0000\n",
      "Epoch 1073/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 390901984.0000 - val_loss: 243838189568.0000\n",
      "Epoch 1074/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 276333600.0000 - val_loss: 243810598912.0000\n",
      "Epoch 1075/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 248550208.0000 - val_loss: 243851149312.0000\n",
      "Epoch 1076/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 239258816.0000 - val_loss: 243868450816.0000\n",
      "Epoch 1077/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 276339296.0000 - val_loss: 243715915776.0000\n",
      "Epoch 1078/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 282595424.0000 - val_loss: 243850412032.0000\n",
      "Epoch 1079/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 240319776.0000 - val_loss: 243819888640.0000\n",
      "Epoch 1080/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 272027072.0000 - val_loss: 243655213056.0000\n",
      "Epoch 1081/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 266742112.0000 - val_loss: 243850067968.0000\n",
      "Epoch 1082/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 269910784.0000 - val_loss: 243825115136.0000\n",
      "Epoch 1083/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 238235504.0000 - val_loss: 243833487360.0000\n",
      "Epoch 1084/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 242429696.0000 - val_loss: 243742310400.0000\n",
      "Epoch 1085/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 272952032.0000 - val_loss: 243782057984.0000\n",
      "Epoch 1086/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 251000416.0000 - val_loss: 243659735040.0000\n",
      "Epoch 1087/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 256898496.0000 - val_loss: 243756269568.0000\n",
      "Epoch 1088/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 244055776.0000 - val_loss: 243777372160.0000\n",
      "Epoch 1089/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 414034336.0000 - val_loss: 243689127936.0000\n",
      "Epoch 1090/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 337213952.0000 - val_loss: 243762331648.0000\n",
      "Epoch 1091/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 345634464.0000 - val_loss: 243792117760.0000\n",
      "Epoch 1092/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - loss: 289157600.0000 - val_loss: 243760185344.0000\n",
      "Epoch 1093/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 263771872.0000 - val_loss: 243719831552.0000\n",
      "Epoch 1094/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 262209248.0000 - val_loss: 243726925824.0000\n",
      "Epoch 1095/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 265391184.0000 - val_loss: 243753484288.0000\n",
      "Epoch 1096/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 318427040.0000 - val_loss: 243680460800.0000\n",
      "Epoch 1097/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 242271824.0000 - val_loss: 243747176448.0000\n",
      "Epoch 1098/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 283736608.0000 - val_loss: 243704971264.0000\n",
      "Epoch 1099/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 272149600.0000 - val_loss: 243743883264.0000\n",
      "Epoch 1100/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 274340288.0000 - val_loss: 243820101632.0000\n",
      "Epoch 1101/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 243611872.0000 - val_loss: 243846365184.0000\n",
      "Epoch 1102/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - loss: 253101552.0000 - val_loss: 243828604928.0000\n",
      "Epoch 1103/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 258145552.0000 - val_loss: 243948847104.0000\n",
      "Epoch 1104/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - loss: 298518112.0000 - val_loss: 243776258048.0000\n",
      "Epoch 1105/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 249431888.0000 - val_loss: 243807158272.0000\n",
      "Epoch 1106/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 273477408.0000 - val_loss: 243838025728.0000\n",
      "Epoch 1107/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 271646880.0000 - val_loss: 243786858496.0000\n",
      "Epoch 1108/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - loss: 252472896.0000 - val_loss: 243800735744.0000\n",
      "Epoch 1109/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 232312224.0000 - val_loss: 243768213504.0000\n",
      "Epoch 1110/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 281403712.0000 - val_loss: 243837435904.0000\n",
      "Epoch 1111/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - loss: 446764000.0000 - val_loss: 243795345408.0000\n",
      "Epoch 1112/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 330478080.0000 - val_loss: 243823804416.0000\n",
      "Epoch 1113/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 10799891456.0000 - val_loss: 243772309504.0000\n",
      "Epoch 1114/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 268067328.0000 - val_loss: 243758284800.0000\n",
      "Epoch 1115/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 260413792.0000 - val_loss: 243835027456.0000\n",
      "Epoch 1116/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - loss: 247003936.0000 - val_loss: 243866288128.0000\n",
      "Epoch 1117/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - loss: 305993184.0000 - val_loss: 243800457216.0000\n",
      "Epoch 1118/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 277630240.0000 - val_loss: 243817594880.0000\n",
      "Epoch 1119/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 271199840.0000 - val_loss: 243737214976.0000\n",
      "Epoch 1120/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 264647104.0000 - val_loss: 243832258560.0000\n",
      "Epoch 1121/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - loss: 289044672.0000 - val_loss: 243695910912.0000\n",
      "Epoch 1122/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 298435488.0000 - val_loss: 243799359488.0000\n",
      "Epoch 1123/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - loss: 278680256.0000 - val_loss: 243682623488.0000\n",
      "Epoch 1124/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 296628832.0000 - val_loss: 243698728960.0000\n",
      "Epoch 1125/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 283742112.0000 - val_loss: 243794378752.0000\n",
      "Epoch 1126/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 256784496.0000 - val_loss: 243649495040.0000\n",
      "Epoch 1127/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 284200480.0000 - val_loss: 243724992512.0000\n",
      "Epoch 1128/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - loss: 265501552.0000 - val_loss: 243750977536.0000\n",
      "Epoch 1129/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 277545280.0000 - val_loss: 243701022720.0000\n",
      "Epoch 1130/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 270356160.0000 - val_loss: 243815055360.0000\n",
      "Epoch 1131/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 259441248.0000 - val_loss: 243728400384.0000\n",
      "Epoch 1132/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 272575136.0000 - val_loss: 243737690112.0000\n",
      "Epoch 1133/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 263433120.0000 - val_loss: 243793428480.0000\n",
      "Epoch 1134/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 300020512.0000 - val_loss: 243724763136.0000\n",
      "Epoch 1135/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - loss: 252149360.0000 - val_loss: 243651543040.0000\n",
      "Epoch 1136/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 285958176.0000 - val_loss: 243758383104.0000\n",
      "Epoch 1137/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 273714784.0000 - val_loss: 243707494400.0000\n",
      "Epoch 1138/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 269904224.0000 - val_loss: 243684343808.0000\n",
      "Epoch 1139/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - loss: 272103616.0000 - val_loss: 243757481984.0000\n",
      "Epoch 1140/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 303535744.0000 - val_loss: 243838091264.0000\n",
      "Epoch 1141/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 265320752.0000 - val_loss: 243767279616.0000\n",
      "Epoch 1142/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 248952144.0000 - val_loss: 243712786432.0000\n",
      "Epoch 1143/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 272754496.0000 - val_loss: 243717242880.0000\n",
      "Epoch 1144/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 550288896.0000 - val_loss: 243743834112.0000\n",
      "Epoch 1145/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 332206624.0000 - val_loss: 243754434560.0000\n",
      "Epoch 1146/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 267085136.0000 - val_loss: 243768410112.0000\n",
      "Epoch 1147/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 267879808.0000 - val_loss: 243729645568.0000\n",
      "Epoch 1148/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 264942576.0000 - val_loss: 243671334912.0000\n",
      "Epoch 1149/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 258698576.0000 - val_loss: 243695157248.0000\n",
      "Epoch 1150/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 261445152.0000 - val_loss: 243806486528.0000\n",
      "Epoch 1151/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 263281808.0000 - val_loss: 243669663744.0000\n",
      "Epoch 1152/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 253323504.0000 - val_loss: 243754614784.0000\n",
      "Epoch 1153/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 262050528.0000 - val_loss: 243689717760.0000\n",
      "Epoch 1154/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 281703808.0000 - val_loss: 243709460480.0000\n",
      "Epoch 1155/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - loss: 245286064.0000 - val_loss: 243706675200.0000\n",
      "Epoch 1156/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 258909104.0000 - val_loss: 243756089344.0000\n",
      "Epoch 1157/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 263886608.0000 - val_loss: 243718750208.0000\n",
      "Epoch 1158/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - loss: 272757824.0000 - val_loss: 243761070080.0000\n",
      "Epoch 1159/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - loss: 249305072.0000 - val_loss: 243763576832.0000\n",
      "Epoch 1160/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 272136672.0000 - val_loss: 243776798720.0000\n",
      "Epoch 1161/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 262862336.0000 - val_loss: 243776995328.0000\n",
      "Epoch 1162/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - loss: 276115040.0000 - val_loss: 243740147712.0000\n",
      "Epoch 1163/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 264777920.0000 - val_loss: 243780665344.0000\n",
      "Epoch 1164/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 231702416.0000 - val_loss: 243851411456.0000\n",
      "Epoch 1165/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 266156128.0000 - val_loss: 243805224960.0000\n",
      "Epoch 1166/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 236497616.0000 - val_loss: 243782057984.0000\n",
      "Epoch 1167/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - loss: 256078032.0000 - val_loss: 243806830592.0000\n",
      "Epoch 1168/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 227327344.0000 - val_loss: 243736510464.0000\n",
      "Epoch 1169/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 261406400.0000 - val_loss: 243799834624.0000\n",
      "Epoch 1170/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 257986656.0000 - val_loss: 243731267584.0000\n",
      "Epoch 1171/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 286129664.0000 - val_loss: 243755778048.0000\n",
      "Epoch 1172/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - loss: 493129984.0000 - val_loss: 243765854208.0000\n",
      "Epoch 1173/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 249808096.0000 - val_loss: 243805126656.0000\n",
      "Epoch 1174/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - loss: 317121504.0000 - val_loss: 243757629440.0000\n",
      "Epoch 1175/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 252740032.0000 - val_loss: 243770458112.0000\n",
      "Epoch 1176/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 242616944.0000 - val_loss: 243773915136.0000\n",
      "Epoch 1177/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 290241216.0000 - val_loss: 243752681472.0000\n",
      "Epoch 1178/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 229625488.0000 - val_loss: 243840466944.0000\n",
      "Epoch 1179/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 226303248.0000 - val_loss: 243837566976.0000\n",
      "Epoch 1180/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 241294896.0000 - val_loss: 243739033600.0000\n",
      "Epoch 1181/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 15761164288.0000 - val_loss: 243760021504.0000\n",
      "Epoch 1182/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 311282560.0000 - val_loss: 243766902784.0000\n",
      "Epoch 1183/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 285149312.0000 - val_loss: 243747553280.0000\n",
      "Epoch 1184/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 352472544.0000 - val_loss: 243740311552.0000\n",
      "Epoch 1185/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 258999968.0000 - val_loss: 243707494400.0000\n",
      "Epoch 1186/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 253740640.0000 - val_loss: 243738345472.0000\n",
      "Epoch 1187/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 245320480.0000 - val_loss: 243800637440.0000\n",
      "Epoch 1188/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 252982144.0000 - val_loss: 243816628224.0000\n",
      "Epoch 1189/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 266372208.0000 - val_loss: 243722371072.0000\n",
      "Epoch 1190/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 256437008.0000 - val_loss: 243731054592.0000\n",
      "Epoch 1191/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 247384272.0000 - val_loss: 243787366400.0000\n",
      "Epoch 1192/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - loss: 253791520.0000 - val_loss: 243734921216.0000\n",
      "Epoch 1193/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 282688672.0000 - val_loss: 243810304000.0000\n",
      "Epoch 1194/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 252442096.0000 - val_loss: 243730022400.0000\n",
      "Epoch 1195/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 258103312.0000 - val_loss: 243696123904.0000\n",
      "Epoch 1196/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 271008416.0000 - val_loss: 243739246592.0000\n",
      "Epoch 1197/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 265632624.0000 - val_loss: 243683753984.0000\n",
      "Epoch 1198/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 281278944.0000 - val_loss: 243774078976.0000\n",
      "Epoch 1199/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 299300736.0000 - val_loss: 243773865984.0000\n",
      "Epoch 1200/1200\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 311332448.0000 - val_loss: 243726106624.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x317261f40>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, epochs=1200, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Metrics</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try to look if the model is actually training \n",
    "# => the error is going downwards\n",
    "# if using validation data, you get two lines\n",
    "# in this case, see if the lines follow a similar trend \n",
    "# (they don't always overlap with complex data, the trend is more important)\n",
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()\n",
    "\n",
    "# other notes:\n",
    "# if your validation loss is fluctuating a lot, the test data set\n",
    "# might not be a good sample / representation of the whole dataset\n",
    "# try to get more data or try shuffling the dataset for a better sample\n",
    "# if your validation loss FLUCTUATES EXTREMELY: remember to create \n",
    "# the neural network again completely (Sequential etc.), otherwise you might fit your \n",
    "# model to your previous model version weights\n",
    "\n",
    "# we'll also study later methods on how to select the best epoch from \n",
    "# the training history\n",
    "\n",
    "# a common reason why a numeric neural network for regression might overfit\n",
    "# is that you might have too many variables but too little data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data evaluation:\n",
      "293164960.0\n",
      "\n",
      "Train data evaluation:\n",
      "256372144.0\n"
     ]
    }
   ],
   "source": [
    "# compare test error values to training error values\n",
    "# the model is often good when these error values are similar\n",
    "# even if you training metrics above didn't overlap\n",
    "# you might still get very close values in evaluation => more important\n",
    "\n",
    "# compare the final model loss/evaluation values\n",
    "print(\"Test data evaluation:\")\n",
    "print(model.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"\\nTrain data evaluation:\")\n",
    "print(model.evaluate(X_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test True Y</th>\n",
       "      <th>Model Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30784</td>\n",
       "      <td>19755.798828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17876</td>\n",
       "      <td>12713.877930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16308</td>\n",
       "      <td>11853.607422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7200</td>\n",
       "      <td>16118.701172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11604</td>\n",
       "      <td>11092.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>44724</td>\n",
       "      <td>20062.636719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>19416</td>\n",
       "      <td>14407.327148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>8500</td>\n",
       "      <td>13503.128906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>6743</td>\n",
       "      <td>11976.833008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>392</td>\n",
       "      <td>20142.123047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2839 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Test True Y  Model Predictions\n",
       "0           30784       19755.798828\n",
       "1           17876       12713.877930\n",
       "2           16308       11853.607422\n",
       "3            7200       16118.701172\n",
       "4           11604       11092.750000\n",
       "...           ...                ...\n",
       "2834        44724       20062.636719\n",
       "2835        19416       14407.327148\n",
       "2836         8500       13503.128906\n",
       "2837         6743       11976.833008\n",
       "2838          392       20142.123047\n",
       "\n",
       "[2839 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# reshape the data for easier comparison table\n",
    "test_predictions = pd.Series(test_predictions.reshape(len(y_test),))\n",
    "pred_df = pd.DataFrame(np.asarray(y_test), columns=['Test True Y'])\n",
    "pred_df = pd.concat([pred_df, test_predictions], axis=1)\n",
    "pred_df.columns = ['Test True Y', 'Model Predictions']\n",
    "\n",
    "# print the comparison table - true values vs. model predicted values\n",
    "# we can nicely see here how far off our model is in some cases\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Test True Y', ylabel='Model Predictions'>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# these values follow a linear line = good predictions\n",
    "# we basically compare the predicted values \n",
    "# to true test values and see the differences\n",
    "sns.scatterplot(x='Test True Y', y='Model Predictions', data=pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "10531.88 $\n",
      "\n",
      "MSE\n",
      "290634135.34 $^2\n",
      "\n",
      "RMSE:\n",
      "17048.0 $\n",
      "\n",
      "R-squared:\n",
      "0.22\n",
      "\n",
      "Explained variance score:\n",
      "0.22\n"
     ]
    }
   ],
   "source": [
    "# MAE - Mean average error\n",
    "print(\"MAE\")\n",
    "print(round(metrics.mean_absolute_error(y_test, test_predictions), 2), \"$\")\n",
    "\n",
    "# MSE - Mean square error\n",
    "print(\"\\nMSE\")\n",
    "print(round(metrics.mean_squared_error(y_test, test_predictions), 2), \"$^2\")\n",
    "\n",
    "# RMSE - Root mean square error\n",
    "print('\\nRMSE:')\n",
    "print(round(np.sqrt(metrics.mean_squared_error(y_test, test_predictions)), 2), \"$\")\n",
    "\n",
    "# R-squared. 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "print('\\nR-squared:')\n",
    "print(round(metrics.r2_score(y_test, test_predictions), 2))\n",
    "\n",
    "# Explained Variance Score => 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "# high variance score = model is a good fit for the data \n",
    "# low variance score = model is not a good fit for the data\n",
    "# the higher the score, the model is more able to explain the variation in the data\n",
    "# if score is low, we might need more and better data\n",
    "print(\"\\nExplained variance score:\")\n",
    "print(round(metrics.explained_variance_score(y_test, test_predictions), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/19/0ldx1bc54jx5tvjkrsbcv4040000gn/T/ipykernel_11989/3124900743.py:5: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot((y_test - test_predictions))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if the prediction distribution are far from normal distribution\n",
    "# then the model is not probably good enough\n",
    "# distplot is deprecating in future pandas-version\n",
    "# unfortunately, there's no exact alternative to do this plot at the moment\n",
    "sns.distplot((y_test - test_predictions))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
